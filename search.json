[
  {
    "objectID": "pyfixest.html#features",
    "href": "pyfixest.html#features",
    "title": "PyFixest: Fast High-Dimensional Fixed Effects Regression in Python",
    "section": "Features",
    "text": "Features\n\nOLS, WLS and IV Regression\nPoisson Regression following the pplmhdfe algorithm\nMultiple Estimation Syntax\nSeveral Robust and Cluster Robust Variance-Covariance Estimators\nWild Cluster Bootstrap Inference (via wildboottest)\nDifference-in-Differences Estimators:\n\nThe canonical Two-Way Fixed Effects Estimator\nGardner‚Äôs two-stage (‚ÄúDid2s‚Äù) estimator\nBasic Versions of the Local Projections estimator following Dube et al (2023)\n\nMultiple Hypothesis Corrections following the Procedure by Romano and Wolf and Simultaneous Confidence Intervals using a Multiplier Bootstrap\nThe Causal Cluster Variance Estimator (CCV) following Abadie et al."
  },
  {
    "objectID": "pyfixest.html#installation",
    "href": "pyfixest.html#installation",
    "title": "PyFixest: Fast High-Dimensional Fixed Effects Regression in Python",
    "section": "Installation",
    "text": "Installation\nYou can install the release version from PyPi by running\npip install -U pyfixest\nor the development version from github by running\npip install git+https://github.com/py-econometrics/pyfixest.git"
  },
  {
    "objectID": "pyfixest.html#benchmarks",
    "href": "pyfixest.html#benchmarks",
    "title": "PyFixest: Fast High-Dimensional Fixed Effects Regression in Python",
    "section": "Benchmarks",
    "text": "Benchmarks\nAll benchmarks follow the fixest benchmarks. All non-pyfixest timings are taken from the fixest benchmarks."
  },
  {
    "objectID": "pyfixest.html#quickstart",
    "href": "pyfixest.html#quickstart",
    "title": "PyFixest: Fast High-Dimensional Fixed Effects Regression in Python",
    "section": "Quickstart",
    "text": "Quickstart\nimport pyfixest as pf\n\ndata = pf.get_data()\npf.feols(\"Y ~ X1 | f1 + f2\", data=data).summary()\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -0.919 |        0.065 |   -14.057 |      0.000 | -1.053 |  -0.786 |\n---\nRMSE: 1.441   R2: 0.609   R2 Within: 0.2\n\nMultiple Estimation\nYou can estimate multiple models at once by using multiple estimation syntax:\n# OLS Estimation: estimate multiple models at once\nfit = pf.feols(\"Y + Y2 ~X1 | csw0(f1, f2)\", data = data, vcov = {'CRV1':'group_id'})\n# Print the results\nfit.etable()\n                           est1               est2               est3               est4               est5               est6\n------------  -----------------  -----------------  -----------------  -----------------  -----------------  -----------------\ndepvar                        Y                 Y2                  Y                 Y2                  Y                 Y2\n------------------------------------------------------------------------------------------------------------------------------\nIntercept      0.919*** (0.121)   1.064*** (0.232)\nX1            -1.000*** (0.117)  -1.322*** (0.211)  -0.949*** (0.087)  -1.266*** (0.212)  -0.919*** (0.069)  -1.228*** (0.194)\n------------------------------------------------------------------------------------------------------------------------------\nf2                            -                  -                  -                  -                  x                  x\nf1                            -                  -                  x                  x                  x                  x\n------------------------------------------------------------------------------------------------------------------------------\nR2                        0.123              0.037              0.437              0.115              0.609              0.168\nS.E. type          by: group_id       by: group_id       by: group_id       by: group_id       by: group_id       by: group_id\nObservations                998                999                997                998                997                998\n------------------------------------------------------------------------------------------------------------------------------\nSignificance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nFormat of coefficient cell:\nCoefficient (Std. Error)\n\n\nAdjust Standard Errors ‚Äúon-the-fly‚Äù\nStandard Errors can be adjusted after estimation, ‚Äúon-the-fly‚Äù:\nfit1 = fit.fetch_model(0)\nfit1.vcov(\"hetero\").summary()\nModel:  Y~X1\n###\n\nEstimation:  OLS\nDep. var.: Y\nInference:  hetero\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| Intercept     |      0.919 |        0.112 |     8.223 |      0.000 |  0.699 |   1.138 |\n| X1            |     -1.000 |        0.082 |   -12.134 |      0.000 | -1.162 |  -0.838 |\n---\nRMSE: 2.158   R2: 0.123\n\n\nPoisson Regression via fepois()\nYou can estimate Poisson Regressions via the fepois() function:\npoisson_data = pf.get_data(model = \"Fepois\")\npf.fepois(\"Y ~ X1 + X2 | f1 + f2\", data = poisson_data).summary()\n###\n\nEstimation:  Poisson\nDep. var.: Y, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -0.007 |        0.035 |    -0.190 |      0.850 | -0.075 |   0.062 |\n| X2            |     -0.015 |        0.010 |    -1.449 |      0.147 | -0.035 |   0.005 |\n---\nDeviance: 1068.169\n\n\nIV Estimation via three-part formulas\nLast, PyFixest also supports IV estimation via three part formula syntax:\nfit_iv = pf.feols(\"Y ~ 1 | f1 | X1 ~ Z1\", data = data)\nfit_iv.summary()\n###\n\nEstimation:  IV\nDep. var.: Y, Fixed effects: f1\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -1.025 |        0.115 |    -8.930 |      0.000 | -1.259 |  -0.790 |\n---"
  },
  {
    "objectID": "pyfixest.html#call-for-contributions",
    "href": "pyfixest.html#call-for-contributions",
    "title": "PyFixest: Fast High-Dimensional Fixed Effects Regression in Python",
    "section": "Call for Contributions",
    "text": "Call for Contributions\nThanks for showing interest in contributing to pyfixest! We appreciate all contributions and constructive feedback, whether that be reporting bugs, requesting new features, or suggesting improvements to documentation.\nIf you‚Äôd like to get involved, but are not yet sure how, please feel free to send us an email. Some familiarity with either Python or econometrics will help, but you really don‚Äôt need to be a numpy core developer or have published in Econometrica =) We‚Äôd be more than happy to invest time to help you get started!"
  },
  {
    "objectID": "pyfixest.html#contributors",
    "href": "pyfixest.html#contributors",
    "title": "PyFixest: Fast High-Dimensional Fixed Effects Regression in Python",
    "section": "Contributors ‚ú®",
    "text": "Contributors ‚ú®\nThanks goes to these wonderful people:\n\n\n\n\n\n\n\nstyfenschaerüíª\n\n\nNiall Keleherüöá üíª\n\n\nWenzhi Dingüíª\n\n\nApoorva Lalüíª üêõ\n\n\nJuan Orduzüöá üíª\n\n\nAlexander Fischerüíª üöá\n\n\naeturrell‚úÖ üìñ üì£\n\n\n\n\n\n\n\nThis project follows the all-contributors specification. Contributions of any kind welcome!"
  },
  {
    "objectID": "marginaleffects.html",
    "href": "marginaleffects.html",
    "title": "Marginal Effects and Hypothesis Tests via marginaleffects",
    "section": "",
    "text": "We can compute marginal effects and linear and non-linear hypothesis tests via the excellent marginaleffects package.\nfrom marginaleffects import hypotheses\n\nimport pyfixest as pf\n\ndata = pf.get_data()\nfit = pf.feols(\"Y ~ X1 + X2\", data=data)\n\nfit.tidy()\n\n\n            \n            \n            \n\n\n\n            \n            \n            \n\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n2.5%\n97.5%\n\n\nCoefficient\n\n\n\n\n\n\n\n\n\n\nIntercept\n0.888779\n0.108422\n8.197374\n8.881784e-16\n0.676016\n1.101542\n\n\nX1\n-0.992936\n0.082117\n-12.091650\n0.000000e+00\n-1.154079\n-0.831792\n\n\nX2\n-0.176342\n0.021766\n-8.101743\n1.554312e-15\n-0.219055\n-0.133630\nSuppose we were interested in testing the hypothesis that \\(X_{1} = X_{2}\\). Given the relatively large differences in coefficients and small standard errors, we will likely reject the null that the two parameters are equal.\nWe can run the formal test via the hypotheses function from the marginaleffects package.\nhypotheses(fit, \"X1 - X2 = 0\")\n\n\nshape: (1, 8)\n\n\n\nterm\nestimate\nstd_error\nstatistic\np_value\ns_value\nconf_low\nconf_high\n\n\nstr\nf64\nf64\nf64\nf64\nf64\nf64\nf64\n\n\n\n\n\"X1-X2=0\"\n-0.816593\n0.085179\n-9.586797\n0.0\ninf\n-0.983541\n-0.649646\nAnd indeed, we reject the null of equality of coefficients: we get a p-value of zero and a confidence interval that does not contain 0."
  },
  {
    "objectID": "marginaleffects.html#ratio-estimates",
    "href": "marginaleffects.html#ratio-estimates",
    "title": "Marginal Effects and Hypothesis Tests via marginaleffects",
    "section": "Ratio Estimates",
    "text": "Ratio Estimates\nWe can also test run-linear hypotheses, in which case marginaleffects will automatically compute correct standard errors based on the estimated covariance matrix and the Delta method. This is for example useful for computing inferential statistics for the ‚Äúrelative uplift‚Äù in an AB test.\nFor the moment, let‚Äôs assume that \\(X1\\) is a randomly assigned treatment variable. As before, \\(Y\\) is our variable / KPI of interest.\nUnder randomization, the model intercept measures the ‚Äúbaseline‚Äù, i.e.¬†the population average of \\(Y\\) in the absence of treatment. To compute a relative uplift, we might compute\n\n(fit.coef().xs(\"X1\") / fit.coef().xs(\"Intercept\") - 1) * 100\n\n-211.71906665561212\n\n\nSo we have a really big negative treatment effect of around minus 212%! To conduct correct inference on this ratio statistic, we need to use the delta method.\n\nThe Multivariate Delta Method\nIn a nutshell, the delta method provides a way to approximate the asympotic distribution of any non-linear transformation \\(g()\\) or one or more random variables.\nIn the case of the ratio statistics, this non-linear transformation can be denoted as \\(g(\\theta_{1}, \\theta_{2}) = \\theta_{1} / \\theta_{2}\\).\nHere‚Äôs the Delta Method theorem:\nFirst, we define \\(\\theta = (\\theta_{1}, \\theta_{2})'\\) and \\(\\mu = (\\mu_{1}, \\mu_{2})'\\).\nBy the law of large numbers, we know that\n\\[\n\\sqrt{N} (\\theta - \\mu) \\rightarrow_{d} N(0_{2}, \\Sigma_{2,2}) \\text{ if } N \\rightarrow \\infty.\n\\]\nBy the Delta Method, we can then approximate the limit distribution of \\(g(\\theta)\\) as\n\\[\n\\sqrt{N}  (g(\\theta) - g(\\mu)) \\rightarrow_{d} N(0_{1}, g'(\\theta) \\times \\Sigma \\times g(\\theta)) \\text{ if } N \\rightarrow \\infty.\n\\].\nHere‚Äôs a long derivation of how to use the the delta method for inference of ratio statistics.. The key steps from the formula above is to derive the expression for the asymptotic variance $ g‚Äô() g()$.\nBut hey - we‚Äôre lucky, because marginaleffects will do all this work for us: we don‚Äôt have to derive analytic gradients ourselves =)\n\n\nUsing the Delta Method via marginaleffects:\nWe can employ the Delta Method via marginaleffects via the hypotheses function:\n\nhypotheses(fit, \"(X1 / Intercept - 1) * 100 = 0\")\n\n\nshape: (1, 8)\n\n\n\nterm\nestimate\nstd_error\nstatistic\np_value\ns_value\nconf_low\nconf_high\n\n\nstr\nf64\nf64\nf64\nf64\nf64\nf64\nf64\n\n\n\n\n\"(X1/Intercept-‚Ä¶\n-211.719067\n8.478682\n-24.970751\n0.0\ninf\n-228.336979\n-195.101155\n\n\n\n\n\n\nAs before, we get an estimate of around -212%. Additionally, we obtain a 95% CI via the Delta Method of [-228%, -195%].\nBesides hypopotheses testing, you can do a range of other cool things with the marginaleffects package. For example (and likely unsurprisingly), you can easily compute all sorts of marginal effects for your regression models. For all the details, we highly recommend to take a look at the marginaleffects zoo book!."
  },
  {
    "objectID": "compare-fixest-pyfixest.html",
    "href": "compare-fixest-pyfixest.html",
    "title": "Does PyFixest match fixest?",
    "section": "",
    "text": "This vignette compares estimation results from fixest with pyfixest via the rpy2 package.\nimport pandas as pd\nimport rpy2.robjects as ro\nfrom rpy2.robjects import pandas2ri\nfrom rpy2.robjects.packages import importr\n\nimport pyfixest as pf\n\n# Activate pandas2ri\npandas2ri.activate()\n\n# Import R packages\nfixest = importr(\"fixest\")\nstats = importr(\"stats\")\n\n# IPython magic commands for autoreloading\n%load_ext autoreload\n%autoreload 2\n\n# Get data using pyfixest\ndata = pf.get_data(model=\"Feols\", N=10_000, seed=99292)"
  },
  {
    "objectID": "compare-fixest-pyfixest.html#ordinary-least-squares-ols",
    "href": "compare-fixest-pyfixest.html#ordinary-least-squares-ols",
    "title": "Does PyFixest match fixest?",
    "section": "Ordinary Least Squares (OLS)",
    "text": "Ordinary Least Squares (OLS)\n\nIID Inference\nFirst, we estimate a model via `pyfixest. We compute ‚Äúiid‚Äù standard errors.\n\nfit = pf.feols(fml=\"Y ~ X1 + X2 | f1 + f2\", data=data, vcov=\"iid\")\n\nWe estimate the same model with weights:\n\nfit_weights = pf.feols(\n    fml=\"Y ~ X1 + X2 | f1 + f2\", data=data, weights=\"weights\", vcov=\"iid\"\n)\n\nVia r-fixest and rpy2, we get\n\nr_fit = fixest.feols(\n    ro.Formula(\"Y ~ X1 + X2 | f1 + f2\"),\n    data=data,\n    vcov=\"iid\",\n    ssc=fixest.ssc(True, \"none\", True, \"min\", \"min\", False),\n)\n\nr_fit_weights = fixest.feols(\n    ro.Formula(\"Y ~ X1 + X2 | f1 + f2\"),\n    data=data,\n    weights=ro.Formula(\"~weights\"),\n    vcov=\"iid\",\n    ssc=fixest.ssc(True, \"none\", True, \"min\", \"min\", False),\n)\n\nR[write to console]: NOTE: 3 observations removed because of NA values (LHS: 1, RHS: 1, Fixed-effects: 1).\n\nR[write to console]: NOTE: 3 observations removed because of NA values (LHS: 1, RHS: 1, Fixed-effects: 1).\n\n\n\nLet‚Äôs compare how close the covariance matrices are:\n\nfit_vcov = fit._vcov\nr_vcov = stats.vcov(r_fit)\nfit_vcov - r_vcov\n\narray([[-7.04731412e-19, -3.34180967e-22],\n       [-3.34594558e-22, -1.38913403e-19]])\n\n\nAnd for WLS:\n\nfit_weights._vcov - stats.vcov(r_fit_weights)\n\narray([[ 1.68051337e-18, -1.69406589e-21],\n       [-1.69406589e-21, -1.49077799e-19]])\n\n\nWe conclude by comparing all estimation results via the etable function:\n\npf.etable([fit, fit_weights], digits=6)\n\n\n\n\n\n\n\n\n\n\n\n\n\nY\n\n\n(1)\n(2)\n\n\n\n\ncoef\n\n\nX1\n0.112019***\n(0.016947)\n0.123687***\n(0.016880)\n\n\nX2\n0.732788***\n(0.004595)\n0.732244***\n(0.004584)\n\n\nfe\n\n\nf1\nx\nx\n\n\nf2\nx\nx\n\n\nmodelstats\n\n\nObservations\n9997\n9997\n\n\nS.E. type\niid\niid\n\n\nR2\n0.774375\n-\n\n\n\nSignificance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell: Coefficient (Std. Error)\n\n\n\n\n\n\n\n        \n\n\n\npd.DataFrame(fixest.etable(r_fit, r_fit_weights, digits=6)).T\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\nDependent Var.:\nY\nY\n\n\n1\n\n\n\n\n\n2\nX1\n0.112019*** (0.016947)\n0.123687*** (0.016880)\n\n\n3\nX2\n0.732788*** (0.004595)\n0.732244*** (0.004584)\n\n\n4\nFixed-Effects:\n----------------------\n----------------------\n\n\n5\nf1\nYes\nYes\n\n\n6\nf2\nYes\nYes\n\n\n7\n_______________\n______________________\n______________________\n\n\n8\nS.E. type\nIID\nIID\n\n\n9\nObservations\n9,997\n9,997\n\n\n10\nR2\n0.77438\n0.77526\n\n\n11\nWithin R2\n0.71822\n0.71886\n\n\n\n\n\n\n\n\n\nHeteroskedastic Errors\nWe repeat the same exercise with heteroskedastic (HC1) errors:\n\nfit = pf.feols(fml=\"Y ~ X1 + X2 | f1 + f2\", data=data, vcov=\"hetero\")\nfit_weights = pf.feols(\n    fml=\"Y ~ X1 + X2 | f1 + f2\", data=data, vcov=\"hetero\", weights=\"weights\"\n)\n\n\nfit_r = fixest.feols(\n    ro.Formula(\"Y ~ X1 + X2 | f1 + f2\"),\n    data=data,\n    vcov=\"hetero\",\n    ssc=fixest.ssc(True, \"none\", True, \"min\", \"min\", False),\n)\n\nfit_weights_r = fixest.feols(\n    ro.Formula(\"Y ~ X1 + X2 | f1 + f2\"),\n    data=data,\n    weights=ro.Formula(\"~weights\"),\n    vcov=\"hetero\",\n    ssc=fixest.ssc(True, \"none\", True, \"min\", \"min\", False),\n)\n\nR[write to console]: NOTE: 3 observations removed because of NA values (LHS: 1, RHS: 1, Fixed-effects: 1).\n\nR[write to console]: NOTE: 3 observations removed because of NA values (LHS: 1, RHS: 1, Fixed-effects: 1).\n\n\n\nAs before, we compare the variance covariance matrices:\n\nfit._vcov - stats.vcov(fit_r)\n\narray([[-1.61925594e-16, -2.13306719e-17],\n       [-2.13306719e-17, -5.39593869e-17]])\n\n\n\nfit_weights._vcov - stats.vcov(fit_weights_r)\n\narray([[-2.04968421e-16, -9.53780274e-18],\n       [-9.53780274e-18, -3.03136151e-17]])\n\n\n\npf.etable([fit, fit_weights], digits=6)\n\n\n\n\n\n\n\n\n\n\n\n\n\nY\n\n\n(1)\n(2)\n\n\n\n\ncoef\n\n\nX1\n0.112019***\n(0.017009)\n0.123687***\n(0.019361)\n\n\nX2\n0.732788***\n(0.004553)\n0.732244***\n(0.005140)\n\n\nfe\n\n\nf1\nx\nx\n\n\nf2\nx\nx\n\n\nmodelstats\n\n\nObservations\n9997\n9997\n\n\nS.E. type\nhetero\nhetero\n\n\nR2\n0.774375\n-\n\n\n\nSignificance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell: Coefficient (Std. Error)\n\n\n\n\n\n\n\n        \n\n\n\npd.DataFrame(fixest.etable(fit_r, fit_weights_r, digits=6)).T\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\nDependent Var.:\nY\nY\n\n\n1\n\n\n\n\n\n2\nX1\n0.112019*** (0.017009)\n0.123687*** (0.019361)\n\n\n3\nX2\n0.732788*** (0.004553)\n0.732244*** (0.005140)\n\n\n4\nFixed-Effects:\n----------------------\n----------------------\n\n\n5\nf1\nYes\nYes\n\n\n6\nf2\nYes\nYes\n\n\n7\n_______________\n______________________\n______________________\n\n\n8\nS.E. type\nHeteroskedastici.-rob.\nHeteroskedastici.-rob.\n\n\n9\nObservations\n9,997\n9,997\n\n\n10\nR2\n0.77438\n0.77526\n\n\n11\nWithin R2\n0.71822\n0.71886\n\n\n\n\n\n\n\n\n\nCluster-Robust Errors\nWe conclude with cluster robust errors.\n\nfit = pf.feols(fml=\"Y ~ X1 + X2 | f1 + f2\", data=data, vcov={\"CRV1\": \"f1\"})\nfit_weights = pf.feols(\n    fml=\"Y ~ X1 + X2 | f1 + f2\", data=data, vcov={\"CRV1\": \"f1\"}, weights=\"weights\"\n)\n\nfit_r = fixest.feols(\n    ro.Formula(\"Y ~ X1 + X2 | f1 + f2\"),\n    data=data,\n    vcov=ro.Formula(\"~f1\"),\n    ssc=fixest.ssc(True, \"none\", True, \"min\", \"min\", False),\n)\nfit_r_weights = fixest.feols(\n    ro.Formula(\"Y ~ X1 + X2 | f1 + f2\"),\n    data=data,\n    weights=ro.Formula(\"~weights\"),\n    vcov=ro.Formula(\"~f1\"),\n    ssc=fixest.ssc(True, \"none\", True, \"min\", \"min\", False),\n)\n\nR[write to console]: NOTE: 3 observations removed because of NA values (LHS: 1, RHS: 1, Fixed-effects: 1).\n\nR[write to console]: NOTE: 3 observations removed because of NA values (LHS: 1, RHS: 1, Fixed-effects: 1).\n\n\n\n\nfit._vcov - stats.vcov(fit_r)\n\narray([[ 4.20345182e-16, -6.97387636e-17],\n       [-6.97404577e-17, -1.42166010e-17]])\n\n\n\nfit_weights._vcov - stats.vcov(fit_weights_r)\n\narray([[-3.95318402e-05,  2.05473422e-05],\n       [ 2.05473422e-05,  1.13249200e-06]])\n\n\n\npf.etable([fit, fit_weights], digits=6)\n\n\n\n\n\n\n\n\n\n\n\n\n\nY\n\n\n(1)\n(2)\n\n\n\n\ncoef\n\n\nX1\n0.112019***\n(0.015816)\n0.123687***\n(0.018311)\n\n\nX2\n0.732788***\n(0.004476)\n0.732244***\n(0.005249)\n\n\nfe\n\n\nf1\nx\nx\n\n\nf2\nx\nx\n\n\nmodelstats\n\n\nObservations\n9997\n9997\n\n\nS.E. type\nby: f1\nby: f1\n\n\nR2\n0.774375\n-\n\n\n\nSignificance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell: Coefficient (Std. Error)\n\n\n\n\n\n\n\n        \n\n\n\npd.DataFrame(fixest.etable(fit_r, fit_r_weights, digits=6)).T\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\nDependent Var.:\nY\nY\n\n\n1\n\n\n\n\n\n2\nX1\n0.112019*** (0.015816)\n0.123687*** (0.018311)\n\n\n3\nX2\n0.732788*** (0.004476)\n0.732244*** (0.005249)\n\n\n4\nFixed-Effects:\n----------------------\n----------------------\n\n\n5\nf1\nYes\nYes\n\n\n6\nf2\nYes\nYes\n\n\n7\n_______________\n______________________\n______________________\n\n\n8\nS.E.: Clustered\nby: f1\nby: f1\n\n\n9\nObservations\n9,997\n9,997\n\n\n10\nR2\n0.77438\n0.77526\n\n\n11\nWithin R2\n0.71822\n0.71886"
  },
  {
    "objectID": "compare-fixest-pyfixest.html#poisson-regression",
    "href": "compare-fixest-pyfixest.html#poisson-regression",
    "title": "Does PyFixest match fixest?",
    "section": "Poisson Regression",
    "text": "Poisson Regression\n\ndata = pf.get_data(model=\"Fepois\")\n\n\nfit_iid = pf.fepois(fml=\"Y ~ X1 + X2 | f1 + f2\", data=data, vcov=\"iid\", iwls_tol=1e-10)\nfit_hetero = pf.fepois(\n    fml=\"Y ~ X1 + X2 | f1 + f2\", data=data, vcov=\"hetero\", iwls_tol=1e-10\n)\nfit_crv = pf.fepois(\n    fml=\"Y ~ X1 + X2 | f1 + f2\", data=data, vcov={\"CRV1\": \"f1\"}, iwls_tol=1e-10\n)\n\nfit_r_iid = fixest.fepois(\n    ro.Formula(\"Y ~ X1 + X2 | f1 + f2\"),\n    data=data,\n    vcov=\"iid\",\n    ssc=fixest.ssc(True, \"none\", True, \"min\", \"min\", False),\n)\n\nfit_r_hetero = fixest.fepois(\n    ro.Formula(\"Y ~ X1 + X2 | f1 + f2\"),\n    data=data,\n    vcov=\"hetero\",\n    ssc=fixest.ssc(True, \"none\", True, \"min\", \"min\", False),\n)\n\nfit_r_crv = fixest.fepois(\n    ro.Formula(\"Y ~ X1 + X2 | f1 + f2\"),\n    data=data,\n    vcov=ro.Formula(\"~f1\"),\n    ssc=fixest.ssc(True, \"none\", True, \"min\", \"min\", False),\n)\n\nR[write to console]: NOTE: 3 observations removed because of NA values (LHS: 1, RHS: 1, Fixed-effects: 1).\n\nR[write to console]: NOTE: 3 observations removed because of NA values (LHS: 1, RHS: 1, Fixed-effects: 1).\n\nR[write to console]: NOTE: 3 observations removed because of NA values (LHS: 1, RHS: 1, Fixed-effects: 1).\n\n\n\n\nfit_iid._vcov - stats.vcov(fit_r_iid)\n\narray([[ 1.20791284e-08, -6.55604931e-10],\n       [-6.55604931e-10,  1.69958097e-09]])\n\n\n\nfit_hetero._vcov - stats.vcov(fit_r_hetero)\n\narray([[ 2.18101847e-08, -7.38711972e-10],\n       [-7.38711972e-10,  3.07587753e-09]])\n\n\n\nfit_crv._vcov - stats.vcov(fit_r_crv)\n\narray([[ 1.58300904e-08, -1.20806815e-10],\n       [-1.20806815e-10,  3.17512746e-09]])\n\n\n\npf.etable([fit_iid, fit_hetero, fit_crv], digits=6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nY\n\n\n(1)\n(2)\n(3)\n\n\n\n\ncoef\n\n\nX1\n-0.006591\n(0.040758)\n-0.006591\n(0.039145)\n-0.006591\n(0.034745)\n\n\nX2\n-0.014924\n(0.010994)\n-0.014924\n(0.010501)\n-0.014924\n(0.010303)\n\n\nfe\n\n\nf1\nx\nx\nx\n\n\nf2\nx\nx\nx\n\n\nmodelstats\n\n\nObservations\n997\n997\n997\n\n\nS.E. type\niid\nhetero\nby: f1\n\n\nR2\n-\n-\n-\n\n\n\nSignificance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell: Coefficient (Std. Error)\n\n\n\n\n\n\n\n        \n\n\n\npd.DataFrame(fixest.etable(fit_r_iid, fit_r_hetero, fit_r_crv, digits=6)).T\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n\n\n\n\n0\nDependent Var.:\nY\nY\nY\n\n\n1\n\n\n\n\n\n\n2\nX1\n-0.006591 (0.040758)\n-0.006591 (0.039145)\n-0.006591 (0.034745)\n\n\n3\nX2\n-0.014924 (0.010994)\n-0.014924 (0.010501)\n-0.014924 (0.010302)\n\n\n4\nFixed-Effects:\n--------------------\n--------------------\n--------------------\n\n\n5\nf1\nYes\nYes\nYes\n\n\n6\nf2\nYes\nYes\nYes\n\n\n7\n_______________\n____________________\n____________________\n____________________\n\n\n8\nS.E. type\nIID\nHeteroskedasti.-rob.\nby: f1\n\n\n9\nObservations\n997\n997\n997\n\n\n10\nSquared Cor.\n0.07687\n0.07687\n0.07687\n\n\n11\nPseudo R2\n0.02866\n0.02866\n0.02866\n\n\n12\nBIC\n2,934.7\n2,934.7\n2,934.7"
  },
  {
    "objectID": "reference/report.coefplot.html",
    "href": "reference/report.coefplot.html",
    "title": "report.coefplot",
    "section": "",
    "text": "report.coefplot(models, alpha=0.05, figsize=None, yintercept=0, xintercept=None, rotate_xticks=0, title=None, coord_flip=True, keep=None, drop=None, exact_match=False, plot_backend='lets_plot', labels=None, joint=None, seed=None, ax=None)\nPlot model coefficients with confidence intervals.",
    "crumbs": [
      "Documentation",
      "Summarize and Visualize",
      "report.coefplot"
    ]
  },
  {
    "objectID": "reference/report.coefplot.html#parameters",
    "href": "reference/report.coefplot.html#parameters",
    "title": "report.coefplot",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodels\nlist or object\nA list of fitted models of type Feols or Fepois, or just a single model.\nrequired\n\n\nfigsize\ntuple or None\nThe size of the figure. If None, the default size is used.\nNone\n\n\nalpha\nfloat\nThe significance level for the confidence intervals.\n0.05\n\n\nyintercept\nfloat or None\nThe value at which to draw a horizontal line on the plot. Default is 0.\n0\n\n\nxintercept\nfloat or None\nThe value at which to draw a vertical line on the plot. Default is None.\nNone\n\n\nrotate_xticks\nfloat\nThe angle in degrees to rotate the xticks labels. Default is 0 (no rotation).\n0\n\n\ntitle\nstr\nThe title of the plot.\nNone\n\n\ncoord_flip\nbool\nWhether to flip the coordinates of the plot. Default is True.\nTrue\n\n\nkeep\nOptional[Union[list, str]]\nThe pattern for retaining coefficient names. You can pass a string (one pattern) or a list (multiple patterns). Default is keeping all coefficients. You should use regular expressions to select coefficients. ‚Äúage‚Äù, # would keep all coefficients containing age r‚Äù^tr‚Äù, # would keep all coefficients starting with tr r‚Äù\\d$‚Äú, # would keep all coefficients ending with number Output will be in the order of the patterns.\nNone\n\n\ndrop\nOptional[Union[list, str]]\nThe pattern for excluding coefficient names. You can pass a string (one pattern) or a list (multiple patterns). Syntax is the same as for keep. Default is keeping all coefficients. Parameter keep and drop can be used simultaneously.\nNone\n\n\nexact_match\nbool\nWhether to use exact match for keep and drop. Default is False. If True, the pattern will be matched exactly to the coefficient name instead of using regular expressions.\nFalse\n\n\nplot_backend\nstr\nThe plotting backend to use between ‚Äúlets_plot‚Äù (default) and ‚Äúmatplotlib‚Äù.\n'lets_plot'\n\n\nlabels\nOptional[dict]\nA dictionary to relabel the variables. The keys are the original variable names and the values the new names. The renaming is applied after the selection of the coefficients via keep and drop.\nNone\n\n\njoint\nOptional[Union[str, bool]]\nWhether to plot simultaneous confidence bands for the coefficients. If True, simultaneous confidence bands are plotted. If False, ‚Äústandard‚Äù confidence intervals are plotted. If ‚Äúboth‚Äù, both are plotted in one figure. Default is None, which returns the standard confidence intervals. Note that this option is not available for objects of type FixestMulti, i.e.¬†multiple estimation.\nNone\n\n\nseed\nOptional[int]\nThe seed for the random number generator. Default is None. Only required / used when joint is True.\nNone",
    "crumbs": [
      "Documentation",
      "Summarize and Visualize",
      "report.coefplot"
    ]
  },
  {
    "objectID": "reference/report.coefplot.html#returns",
    "href": "reference/report.coefplot.html#returns",
    "title": "report.coefplot",
    "section": "Returns",
    "text": "Returns\n\n\n\nType\nDescription\n\n\n\n\nobject\nA lets-plot figure.",
    "crumbs": [
      "Documentation",
      "Summarize and Visualize",
      "report.coefplot"
    ]
  },
  {
    "objectID": "reference/report.coefplot.html#examples",
    "href": "reference/report.coefplot.html#examples",
    "title": "report.coefplot",
    "section": "Examples",
    "text": "Examples\n\nimport pyfixest as pf\nfrom pyfixest.report.utils import rename_categoricals\n\ndf = pf.get_data()\nfit1 = pf.feols(\"Y ~ X1\", data = df)\nfit2 = pf.feols(\"Y ~ X1 + X2\", data = df)\nfit3 = pf.feols(\"Y ~ X1 + X2 | f1\", data = df)\nfit4 = pf.feols(\"Y ~ C(X1)\", data = df)\n\npf.coefplot([fit1, fit2, fit3])\npf.coefplot([fit4], labels = rename_categoricals(fit1._coefnames))\n\npf.coefplot([fit1], joint = \"both\")",
    "crumbs": [
      "Documentation",
      "Summarize and Visualize",
      "report.coefplot"
    ]
  },
  {
    "objectID": "reference/estimation.feols.html",
    "href": "reference/estimation.feols.html",
    "title": "estimation.feols",
    "section": "",
    "text": "estimation.feols(fml, data, vcov=None, weights=None, ssc=ssc(), fixef_rm='none', fixef_tol=1e-08, collin_tol=1e-10, drop_intercept=False, i_ref1=None, copy_data=True, store_data=True, lean=False, weights_type='aweights')\nEstimate a linear regression models with fixed effects using fixest formula syntax.",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "estimation.feols"
    ]
  },
  {
    "objectID": "reference/estimation.feols.html#parameters",
    "href": "reference/estimation.feols.html#parameters",
    "title": "estimation.feols",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfml\nstr\nA three-sided formula string using fixest formula syntax. Syntax: ‚ÄúY ~ X1 + X2 | FE1 + FE2 | X1 ~ Z1‚Äù. ‚Äú|‚Äù separates dependent variable, fixed effects, and instruments. Special syntax includes stepwise regressions, cumulative stepwise regression, multiple dependent variables, interaction of variables (i(X1,X2)), and interacted fixed effects (fe1^fe2).\nrequired\n\n\ndata\nDataFrameType\nA pandas or polars dataframe containing the variables in the formula.\nrequired\n\n\nvcov\nUnion[str, dict[str, str]]\nType of variance-covariance matrix for inference. Options include ‚Äúiid‚Äù, ‚Äúhetero‚Äù, ‚ÄúHC1‚Äù, ‚ÄúHC2‚Äù, ‚ÄúHC3‚Äù, or a dictionary for CRV1/CRV3 inference.\nNone\n\n\nweights\nUnion[None, str], optional.\nDefault is None. Weights for WLS estimation. If None, all observations are weighted equally. If a string, the name of the column in data that contains the weights.\nNone\n\n\nssc\nstr\nA ssc object specifying the small sample correction for inference.\nssc()\n\n\nfixef_rm\nstr\nSpecifies whether to drop singleton fixed effects. Options: ‚Äúnone‚Äù (default), ‚Äúsingleton‚Äù.\n'none'\n\n\ncollin_tol\nfloat\nTolerance for collinearity check, by default 1e-10.\n1e-10\n\n\nfixef_tol\n\nTolerance for the fixed effects demeaning algorithm. Defaults to 1e-08.\n1e-08\n\n\ndrop_intercept\nbool\nWhether to drop the intercept from the model, by default False.\nFalse\n\n\ni_ref1\n\nDeprecated with pyfixest version 0.18.0. Please use i-syntax instead, i.e.¬†feols(‚ÄòY~ i(f1, ref=1)‚Äô, data = data) instead of the former feols(‚ÄòY~ i(f1)‚Äô, data = data, i_ref=1).\nNone\n\n\ncopy_data\nbool\nWhether to copy the data before estimation, by default True. If set to False, the data is not copied, which can save memory but may lead to unintended changes in the input data outside of fepois. For example, the input data set is re-index within the function. As far as I know, the only other relevant case is when using interacted fixed effects, in which case you‚Äôll find a column with interacted fixed effects in the data set.\nTrue\n\n\nstore_data\nbool\nWhether to store the data in the model object, by default True. If set to False, the data is not stored in the model object, which can improve performance and save memory. However, it will no longer be possible to access the data via the data attribute of the model object. This has impact on post-estimation capabilities that rely on the data, e.g.¬†predict() or vcov().\nTrue\n\n\nlean\nbool\nFalse by default. If True, then all large objects are removed from the returned result: this will save memory but will block the possibility to use many methods. It is recommended to use the argument vcov to obtain the appropriate standard-errors at estimation time, since obtaining different SEs won‚Äôt be possible afterwards.\nFalse\n\n\nweights_type\nstr\nOptions include aweights or fweights. aweights implement analytic or precision weights, while fweights implement frequency weights. For details see this blog post: https://notstatschat.rbind.io/2020/08/04/weights-in-statistics/.\n'aweights'",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "estimation.feols"
    ]
  },
  {
    "objectID": "reference/estimation.feols.html#returns",
    "href": "reference/estimation.feols.html#returns",
    "title": "estimation.feols",
    "section": "Returns",
    "text": "Returns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nobject\nAn instance of the [Feols(/reference/Feols.qmd) class or FixestMulti class for multiple models specified via fml.",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "estimation.feols"
    ]
  },
  {
    "objectID": "reference/estimation.feols.html#examples",
    "href": "reference/estimation.feols.html#examples",
    "title": "estimation.feols",
    "section": "Examples",
    "text": "Examples\nAs in fixest, the [Feols(/reference/Feols.qmd) function can be used to estimate a simple linear regression model with fixed effects. The following example regresses Y on X1 and X2 with fixed effects for f1 and f2: fixed effects are specified after the | symbol.\n\nimport pyfixest as pf\n\ndata = pf.get_data()\n\nfit = pf.feols(\"Y ~ X1 + X2 | f1 + f2\", data)\nfit.summary()\n\n\n            \n            \n            \n\n\n\n            \n            \n            \n\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -0.924 |        0.061 |   -15.165 |      0.000 | -1.049 |  -0.799 |\n| X2            |     -0.174 |        0.015 |   -11.918 |      0.000 | -0.204 |  -0.144 |\n---\nRMSE: 1.346 R2: 0.659 R2 Within: 0.303 \n\n\nCalling feols() returns an instance of the [Feols(/reference/Feols.qmd) class. The summary() method can be used to print the results.\nAn alternative way to retrieve model results is via the tidy() method, which returns a pandas dataframe with the estimated coefficients, standard errors, t-statistics, and p-values.\n\nfit.tidy()\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n2.5%\n97.5%\n\n\nCoefficient\n\n\n\n\n\n\n\n\n\n\nX1\n-0.924046\n0.060934\n-15.164621\n2.664535e-15\n-1.048671\n-0.799421\n\n\nX2\n-0.174107\n0.014608\n-11.918277\n1.069367e-12\n-0.203985\n-0.144230\n\n\n\n\n\n\n\nYou can also access all elements in the tidy data frame by dedicated methods, e.g.¬†fit.coef() for the coefficients, fit.se() for the standard errors, fit.tstat() for the t-statistics, and fit.pval() for the p-values, and fit.confint() for the confidence intervals.\nThe employed type of inference can be specified via the vcov argument. If vcov is not provided, PyFixest employs the fixest default of iid inference, unless there are fixed effects in the model, in which case feols() clusters the standard error by the first fixed effect (CRV1 inference).\n\nfit1 = pf.feols(\"Y ~ X1 + X2 | f1 + f2\", data, vcov=\"iid\")\nfit2 = pf.feols(\"Y ~ X1 + X2 | f1 + f2\", data, vcov=\"hetero\")\nfit3 = pf.feols(\"Y ~ X1 + X2 | f1 + f2\", data, vcov={\"CRV1\": \"f1\"})\n\nSupported inference types are ‚Äúiid‚Äù, ‚Äúhetero‚Äù, ‚ÄúHC1‚Äù, ‚ÄúHC2‚Äù, ‚ÄúHC3‚Äù, and ‚ÄúCRV1‚Äù/‚ÄúCRV3‚Äù. Clustered standard errors are specified via a dictionary, e.g.¬†{\"CRV1\": \"f1\"} for CRV1 inference with clustering by f1 or {\"CRV3\": \"f1\"} for CRV3 inference with clustering by f1. For two-way clustering, you can provide a formula string, e.g.¬†{\"CRV1\": \"f1 + f2\"} for CRV1 inference with clustering by f1.\n\nfit4 = pf.feols(\"Y ~ X1 + X2 | f1 + f2\", data, vcov={\"CRV1\": \"f1 + f2\"})\n\nInference can be adjusted post estimation via the vcov method:\n\nfit.summary()\nfit.vcov(\"iid\").summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -0.924 |        0.061 |   -15.165 |      0.000 | -1.049 |  -0.799 |\n| X2            |     -0.174 |        0.015 |   -11.918 |      0.000 | -0.204 |  -0.144 |\n---\nRMSE: 1.346 R2: 0.659 R2 Within: 0.303 \n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  iid\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -0.924 |        0.054 |   -16.995 |      0.000 | -1.031 |  -0.817 |\n| X2            |     -0.174 |        0.014 |   -12.081 |      0.000 | -0.202 |  -0.146 |\n---\nRMSE: 1.346 R2: 0.659 R2 Within: 0.303 \n\n\nThe ssc argument specifies the small sample correction for inference. In general, feols() uses all of fixest::feols() defaults, but sets the fixef.K argument to \"none\" whereas the fixest::feols() default is \"nested\". See here for more details: link to github.\nfeols() supports a range of multiple estimation syntax, i.e.¬†you can estimate multiple models in one call. The following example estimates two models, one with fixed effects for f1 and one with fixed effects for f2 using the sw() syntax.\n\nfit = pf.feols(\"Y ~ X1 + X2 | sw(f1, f2)\", data)\ntype(fit)\n\npyfixest.estimation.FixestMulti_.FixestMulti\n\n\nThe returned object is an instance of the FixestMulti class. You can access the results of the first model via fit.fetch_model(0) and the results of the second model via fit.fetch_model(1). You can compare the model results via the etable() function:\n\npf.etable([fit.fetch_model(0), fit.fetch_model(1)])\n\nModel:  Y~X1+X2|f1\nModel:  Y~X1+X2|f2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nY\n\n\n(1)\n(2)\n\n\n\n\ncoef\n\n\nX1\n-0.950***\n(0.067)\n-0.979***\n(0.077)\n\n\nX2\n-0.174***\n(0.018)\n-0.175***\n(0.022)\n\n\nfe\n\n\nf1\nx\n-\n\n\nf2\n-\nx\n\n\nmodelstats\n\n\nObservations\n997\n998\n\n\nS.E. type\nby: f1\nby: f2\n\n\nR2\n0.489\n0.354\n\n\n\nSignificance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell: Coefficient (Std. Error)\n\n\n\n\n\n\n\n        \n\n\nOther supported multiple estimation syntax include sw0(), csw() and csw0(). While sw() adds variables in a ‚Äústepwise‚Äù fashion, csw() does so cumulatively.\n\nfit = pf.feols(\"Y ~ X1 + X2 | csw(f1, f2)\", data)\npf.etable([fit.fetch_model(0), fit.fetch_model(1)])\n\nModel:  Y~X1+X2|f1\nModel:  Y~X1+X2|f1+f2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nY\n\n\n(1)\n(2)\n\n\n\n\ncoef\n\n\nX1\n-0.950***\n(0.067)\n-0.924***\n(0.061)\n\n\nX2\n-0.174***\n(0.018)\n-0.174***\n(0.015)\n\n\nfe\n\n\nf1\nx\nx\n\n\nf2\n-\nx\n\n\nmodelstats\n\n\nObservations\n997\n997\n\n\nS.E. type\nby: f1\nby: f1\n\n\nR2\n0.489\n0.659\n\n\n\nSignificance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell: Coefficient (Std. Error)\n\n\n\n\n\n\n\n        \n\n\nThe sw0() and csw0() syntax are similar to sw() and csw(), but start with a model that excludes the variables specified in sw() and csw():\n\nfit = pf.feols(\"Y ~ X1 + X2 | sw0(f1, f2)\", data)\npf.etable([fit.fetch_model(0), fit.fetch_model(1), fit.fetch_model(2)])\n\nModel:  Y~X1+X2\nModel:  Y~X1+X2|f1\nModel:  Y~X1+X2|f2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nY\n\n\n(1)\n(2)\n(3)\n\n\n\n\ncoef\n\n\nIntercept\n0.889***\n(0.108)\n\n\n\n\nX1\n-0.993***\n(0.082)\n-0.950***\n(0.067)\n-0.979***\n(0.077)\n\n\nX2\n-0.176***\n(0.022)\n-0.174***\n(0.018)\n-0.175***\n(0.022)\n\n\nfe\n\n\nf1\n-\nx\n-\n\n\nf2\n-\n-\nx\n\n\nmodelstats\n\n\nObservations\n998\n997\n998\n\n\nS.E. type\niid\nby: f1\nby: f2\n\n\nR2\n0.177\n0.489\n0.354\n\n\n\nSignificance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell: Coefficient (Std. Error)\n\n\n\n\n\n\n\n        \n\n\nThe feols() function also supports multiple dependent variables. The following example estimates two models, one with Y1 as the dependent variable and one with Y2 as the dependent variable.\n\nfit = pf.feols(\"Y + Y2 ~ X1 | f1 + f2\", data)\npf.etable([fit.fetch_model(0), fit.fetch_model(1)])\n\nModel:  Y~X1|f1+f2\nModel:  Y2~X1|f1+f2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nY\nY2\n\n\n(1)\n(2)\n\n\n\n\ncoef\n\n\nX1\n-0.919***\n(0.065)\n-1.228***\n(0.195)\n\n\nfe\n\n\nf1\nx\nx\n\n\nf2\nx\nx\n\n\nmodelstats\n\n\nObservations\n997\n998\n\n\nS.E. type\nby: f1\nby: f1\n\n\nR2\n0.609\n0.168\n\n\n\nSignificance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell: Coefficient (Std. Error)\n\n\n\n\n\n\n\n        \n\n\nIt is possible to combine different multiple estimation operators:\n\nfit = pf.feols(\"Y + Y2 ~ X1 | sw(f1, f2)\", data)\npf.etable([fit.fetch_model(0),\n        fit.fetch_model(1),\n        fit.fetch_model(2),\n        fit.fetch_model(3)\n        ]\n    )\n\nModel:  Y~X1|f1\nModel:  Y2~X1|f1\nModel:  Y~X1|f2\nModel:  Y2~X1|f2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nY\nY2\nY\nY2\n\n\n(1)\n(2)\n(3)\n(4)\n\n\n\n\ncoef\n\n\nX1\n-0.949***\n(0.069)\n-1.266***\n(0.176)\n-0.982***\n(0.081)\n-1.301***\n(0.205)\n\n\nfe\n\n\nf1\nx\nx\n-\n-\n\n\nf2\n-\n-\nx\nx\n\n\nmodelstats\n\n\nObservations\n997\n998\n998\n999\n\n\nS.E. type\nby: f1\nby: f1\nby: f2\nby: f2\n\n\nR2\n0.437\n0.115\n0.302\n0.090\n\n\n\nSignificance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell: Coefficient (Std. Error)\n\n\n\n\n\n\n\n        \n\n\nIn general, using muliple estimation syntax can improve the estimation time as covariates that are demeaned in one model and are used in another model do not need to be demeaned again: feols() implements a caching mechanism that stores the demeaned covariates.\nBesides OLS, feols() also supports IV estimation via three part formulas:\n\nfit = pf.feols(\"Y ~  X2 | f1 + f2 | X1 ~ Z1\", data)\nfit.tidy()\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n2.5%\n97.5%\n\n\nCoefficient\n\n\n\n\n\n\n\n\n\n\nX1\n-1.050097\n0.085493\n-12.282912\n5.133671e-13\n-1.224949\n-0.875245\n\n\nX2\n-0.174351\n0.014779\n-11.797039\n1.369793e-12\n-0.204578\n-0.144124\n\n\n\n\n\n\n\nHere, X1 is the endogenous variable and Z1 is the instrument. f1 and f2 are the fixed effects, as before. To estimate IV models without fixed effects, simply omit the fixed effects part of the formula:\n\nfit = pf.feols(\"Y ~  X2 | X1 ~ Z1\", data)\nfit.tidy()\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n2.5%\n97.5%\n\n\nCoefficient\n\n\n\n\n\n\n\n\n\n\nIntercept\n0.861939\n0.151187\n5.701137\n1.567858e-08\n0.565257\n1.158622\n\n\nX1\n-0.967238\n0.130078\n-7.435847\n2.238210e-13\n-1.222497\n-0.711980\n\n\nX2\n-0.176416\n0.021769\n-8.104001\n1.554312e-15\n-0.219134\n-0.133697\n\n\n\n\n\n\n\nLast, feols() supports interaction of variables via the i() syntax. Documentation on this is tba.\nAfter fitting a model via feols(), you can use the predict() method to get the predicted values:\n\nfit = pf.feols(\"Y ~ X1 + X2 | f1 + f2\", data)\nfit.predict()[0:5]\n\narray([ 3.0633663 , -0.69574133, -0.91240433, -0.46370257, -1.67331154])\n\n\nThe predict() method also supports a newdata argument to predict on new data, which returns a numpy array of the predicted values:\n\nfit = pf.feols(\"Y ~ X1 + X2 | f1 + f2\", data)\nfit.predict(newdata=data)[0:5]\n\narray([ 2.14598761,         nan,         nan,  3.06336415, -0.69574276])\n\n\nLast, you can plot the results of a model via the coefplot() method:\n\nfit = pf.feols(\"Y ~ X1 + X2 | f1 + f2\", data)\nfit.coefplot()\n\n   \n   \n\n\nObjects of type Feols support a range of other methods to conduct inference. For example, you can run a wild (cluster) bootstrap via the wildboottest() method:\n\nfit.wildboottest(param = \"X1\", reps=1000)\n\nparam                             X1\nt value           -14.70814685400939\nPr(&gt;|t|)                         0.0\nbootstrap_type                    11\ninference                    CRV(f1)\nimpose_null                     True\ndtype: object\n\n\nwould run a wild bootstrap test for the coefficient of X1 with 1000 bootstrap repetitions.\nFor a wild cluster bootstrap, you can specify the cluster variable via the cluster argument:\n\nfit.wildboottest(param = \"X1\", reps=1000, cluster=\"group_id\")\n\nparam                              X1\nt value           -13.658130940490494\nPr(&gt;|t|)                          0.0\nbootstrap_type                     11\ninference               CRV(group_id)\nimpose_null                      True\ndtype: object\n\n\nThe ritest() method can be used to conduct randomization inference:\n\nfit.ritest(resampvar = \"X1\", reps=1000)\n\nH0                                      X1=0\nri-type                      randomization-c\nEstimate                 -0.9240461507764967\nPr(&gt;|t|)                                 0.0\nStd. Error (Pr(&gt;|t|))                    0.0\n2.5% (Pr(&gt;|t|))                          0.0\n97.5% (Pr(&gt;|t|))                         0.0\ndtype: object\n\n\nLast, you can compute the cluster causal variance estimator by Athey et al by using the ccv() method:\n\nimport numpy as np\nrng = np.random.default_rng(1234)\ndata[\"D\"] = rng.choice([0, 1], size = data.shape[0])\nfit_D = pf.feols(\"Y ~ D\", data = data)\nfit_D.ccv(treatment = \"D\", cluster = \"group_id\")\n\n/home/runner/work/pyfixest/pyfixest/pyfixest/estimation/feols_.py:1250: UserWarning:\n\nThe initial model was not clustered. CRV1 inference is computed and stored in the model object.\n\n\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n2.5%\n97.5%\n\n\n\n\nCCV\n0.016087657906364183\n0.260975\n0.061644\n0.951525\n-0.5322\n0.564375\n\n\nCRV1\n0.016088\n0.13378\n0.120254\n0.905614\n-0.264974\n0.29715",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "estimation.feols"
    ]
  },
  {
    "objectID": "reference/estimation.model_matrix_fixest.html",
    "href": "reference/estimation.model_matrix_fixest.html",
    "title": "estimation.model_matrix_fixest",
    "section": "",
    "text": "estimation.model_matrix_fixest(FixestFormula, data, drop_singletons=False, weights=None, drop_intercept=False)\nCreate model matrices for fixed effects estimation.\nThis function processes the data and then calls formulaic.Formula.get_model_matrix() to create the model matrices.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nFixestFormula\nA pyfixest.estimation.FormulaParser.FixestFormula object\nthat contains information on the model formula, the formula of the first and second stage, dependent variable, covariates, fixed effects, endogenous variables (if any), and instruments (if any).\nrequired\n\n\ndata\npd.DataFrame\nThe input DataFrame containing the data.\nrequired\n\n\ndrop_singletons\nbool\nWhether to drop singleton fixed effects. Default is False.\nFalse\n\n\nweights\nstr or None\nA string specifying the name of the weights column in data. Default is None.\nNone\n\n\ndata\npd.DataFrame\nThe input DataFrame containing the data.\nrequired\n\n\ndrop_intercept\nbool\nWhether to drop the intercept from the model matrix. Default is False. If True, the intercept is dropped ex post from the model matrix created by formulaic.\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ndict\nA dictionary with the following keys and value types: - ‚ÄòY‚Äô : pd.DataFrame The dependent variable. - ‚ÄòX‚Äô : pd.DataFrame The Design Matrix. - ‚Äòfe‚Äô : Optional[pd.DataFrame] The model‚Äôs fixed effects. None if not applicable. - ‚Äòendogvar‚Äô : Optional[pd.DataFrame] The model‚Äôs endogenous variable(s), None if not applicable. - ‚ÄòZ‚Äô : np.ndarray The model‚Äôs set of instruments (exogenous covariates plus instruments). None if not applicable. - ‚Äòweights_df‚Äô : Optional[pd.DataFrame] DataFrame containing weights, None if weights are not used. - ‚Äòna_index‚Äô : np.ndarray Array indicating rows droppled beause of NA values or singleton fixed effects. - ‚Äòna_index_str‚Äô : str String representation of ‚Äòna_index‚Äô. - ‚Äô_icovars‚Äô : Optional[list[str]] List of variables interacted with i() syntax, None if not applicable. - ‚ÄòX_is_empty‚Äô : bool Flag indicating whether X is empty.",
    "crumbs": [
      "Documentation",
      "Misc / Utilities",
      "estimation.model_matrix_fixest"
    ]
  },
  {
    "objectID": "reference/estimation.model_matrix_fixest.html#parameters",
    "href": "reference/estimation.model_matrix_fixest.html#parameters",
    "title": "estimation.model_matrix_fixest",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nFixestFormula\nA pyfixest.estimation.FormulaParser.FixestFormula object\nthat contains information on the model formula, the formula of the first and second stage, dependent variable, covariates, fixed effects, endogenous variables (if any), and instruments (if any).\nrequired\n\n\ndata\npd.DataFrame\nThe input DataFrame containing the data.\nrequired\n\n\ndrop_singletons\nbool\nWhether to drop singleton fixed effects. Default is False.\nFalse\n\n\nweights\nstr or None\nA string specifying the name of the weights column in data. Default is None.\nNone\n\n\ndata\npd.DataFrame\nThe input DataFrame containing the data.\nrequired\n\n\ndrop_intercept\nbool\nWhether to drop the intercept from the model matrix. Default is False. If True, the intercept is dropped ex post from the model matrix created by formulaic.\nFalse",
    "crumbs": [
      "Documentation",
      "Misc / Utilities",
      "estimation.model_matrix_fixest"
    ]
  },
  {
    "objectID": "reference/estimation.model_matrix_fixest.html#returns",
    "href": "reference/estimation.model_matrix_fixest.html#returns",
    "title": "estimation.model_matrix_fixest",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\ndict\nA dictionary with the following keys and value types: - ‚ÄòY‚Äô : pd.DataFrame The dependent variable. - ‚ÄòX‚Äô : pd.DataFrame The Design Matrix. - ‚Äòfe‚Äô : Optional[pd.DataFrame] The model‚Äôs fixed effects. None if not applicable. - ‚Äòendogvar‚Äô : Optional[pd.DataFrame] The model‚Äôs endogenous variable(s), None if not applicable. - ‚ÄòZ‚Äô : np.ndarray The model‚Äôs set of instruments (exogenous covariates plus instruments). None if not applicable. - ‚Äòweights_df‚Äô : Optional[pd.DataFrame] DataFrame containing weights, None if weights are not used. - ‚Äòna_index‚Äô : np.ndarray Array indicating rows droppled beause of NA values or singleton fixed effects. - ‚Äòna_index_str‚Äô : str String representation of ‚Äòna_index‚Äô. - ‚Äô_icovars‚Äô : Optional[list[str]] List of variables interacted with i() syntax, None if not applicable. - ‚ÄòX_is_empty‚Äô : bool Flag indicating whether X is empty.",
    "crumbs": [
      "Documentation",
      "Misc / Utilities",
      "estimation.model_matrix_fixest"
    ]
  },
  {
    "objectID": "reference/estimation.detect_singletons.html",
    "href": "reference/estimation.detect_singletons.html",
    "title": "estimation.detect_singletons",
    "section": "",
    "text": "estimation.detect_singletons(ids)\nDetect singleton fixed effects in a dataset.\nThis function iterates over the columns of a 2D numpy array representing fixed effects to identify singleton fixed effects. An observation is considered a singleton if it is the only one in its group (fixed effect identifier).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nids\nnp.ndarray\nA 2D numpy array representing fixed effects, with a shape of (n_samples, n_features). Elements should be non-negative integers representing fixed effect identifiers.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.ndarray\nA boolean array of shape (n_samples,), indicating which observations have a singleton fixed effect.\n\n\n\n\n\n\nThe algorithm iterates over columns to identify fixed effects. After each column is processed, it updates the record of non-singleton rows. This approach accounts for the possibility that removing an observation in one column can lead to the emergence of new singletons in subsequent columns.\nFor performance reasons, the input array should be in column-major order. Operating on a row-major array can lead to significant performance losses.",
    "crumbs": [
      "Documentation",
      "Misc / Utilities",
      "estimation.detect_singletons"
    ]
  },
  {
    "objectID": "reference/estimation.detect_singletons.html#parameters",
    "href": "reference/estimation.detect_singletons.html#parameters",
    "title": "estimation.detect_singletons",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nids\nnp.ndarray\nA 2D numpy array representing fixed effects, with a shape of (n_samples, n_features). Elements should be non-negative integers representing fixed effect identifiers.\nrequired",
    "crumbs": [
      "Documentation",
      "Misc / Utilities",
      "estimation.detect_singletons"
    ]
  },
  {
    "objectID": "reference/estimation.detect_singletons.html#returns",
    "href": "reference/estimation.detect_singletons.html#returns",
    "title": "estimation.detect_singletons",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\nnumpy.ndarray\nA boolean array of shape (n_samples,), indicating which observations have a singleton fixed effect.",
    "crumbs": [
      "Documentation",
      "Misc / Utilities",
      "estimation.detect_singletons"
    ]
  },
  {
    "objectID": "reference/estimation.detect_singletons.html#notes",
    "href": "reference/estimation.detect_singletons.html#notes",
    "title": "estimation.detect_singletons",
    "section": "",
    "text": "The algorithm iterates over columns to identify fixed effects. After each column is processed, it updates the record of non-singleton rows. This approach accounts for the possibility that removing an observation in one column can lead to the emergence of new singletons in subsequent columns.\nFor performance reasons, the input array should be in column-major order. Operating on a row-major array can lead to significant performance losses.",
    "crumbs": [
      "Documentation",
      "Misc / Utilities",
      "estimation.detect_singletons"
    ]
  },
  {
    "objectID": "reference/estimation.demean.html",
    "href": "reference/estimation.demean.html",
    "title": "estimation.demean",
    "section": "",
    "text": "estimation.demean(x, flist, weights, tol=1e-08, maxiter=100000)\nDemean an array.\nWorkhorse for demeaning an input array x based on the specified fixed effects and weights via the alternating projections algorithm.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnumpy.ndarray\nInput array of shape (n_samples, n_features). Needs to be of type float.\nrequired\n\n\nflist\nnumpy.ndarray\nArray of shape (n_samples, n_factors) specifying the fixed effects. Needs to already be converted to integers.\nrequired\n\n\nweights\nnumpy.ndarray\nArray of shape (n_samples,) specifying the weights.\nrequired\n\n\ntol\nfloat\nTolerance criterion for convergence. Defaults to 1e-08.\n1e-08\n\n\nmaxiter\nint\nMaximum number of iterations. Defaults to 100_000.\n100000\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntuple[numpy.ndarray, bool]\nA tuple containing the demeaned array of shape (n_samples, n_features) and a boolean indicating whether the algorithm converged successfully.",
    "crumbs": [
      "Documentation",
      "Misc / Utilities",
      "estimation.demean"
    ]
  },
  {
    "objectID": "reference/estimation.demean.html#parameters",
    "href": "reference/estimation.demean.html#parameters",
    "title": "estimation.demean",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nx\nnumpy.ndarray\nInput array of shape (n_samples, n_features). Needs to be of type float.\nrequired\n\n\nflist\nnumpy.ndarray\nArray of shape (n_samples, n_factors) specifying the fixed effects. Needs to already be converted to integers.\nrequired\n\n\nweights\nnumpy.ndarray\nArray of shape (n_samples,) specifying the weights.\nrequired\n\n\ntol\nfloat\nTolerance criterion for convergence. Defaults to 1e-08.\n1e-08\n\n\nmaxiter\nint\nMaximum number of iterations. Defaults to 100_000.\n100000",
    "crumbs": [
      "Documentation",
      "Misc / Utilities",
      "estimation.demean"
    ]
  },
  {
    "objectID": "reference/estimation.demean.html#returns",
    "href": "reference/estimation.demean.html#returns",
    "title": "estimation.demean",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\ntuple[numpy.ndarray, bool]\nA tuple containing the demeaned array of shape (n_samples, n_features) and a boolean indicating whether the algorithm converged successfully.",
    "crumbs": [
      "Documentation",
      "Misc / Utilities",
      "estimation.demean"
    ]
  },
  {
    "objectID": "reference/did.estimation.lpdid.html",
    "href": "reference/did.estimation.lpdid.html",
    "title": "did.estimation.lpdid",
    "section": "",
    "text": "did.estimation.lpdid(data, yname, idname, tname, gname, vcov=None, pre_window=None, post_window=None, never_treated=0, att=True, xfml=None)\nLocal projections approach to estimation.\nEstimate a Difference-in-Differences / Event Study Model via the Local Projections Approach.",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "did.estimation.lpdid"
    ]
  },
  {
    "objectID": "reference/did.estimation.lpdid.html#parameters",
    "href": "reference/did.estimation.lpdid.html#parameters",
    "title": "did.estimation.lpdid",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\nDataFrame\nThe DataFrame containing all variables.\nrequired\n\n\nyname\nstr\nThe name of the dependent variable.\nrequired\n\n\nidname\nstr\nThe name of the id variable.\nrequired\n\n\ntname\nstr\nVariable name for calendar period.\nrequired\n\n\ngname\nstr\nUnit-specific time of initial treatment.\nrequired\n\n\nvcov\n(str, dict)\nThe type of inference to employ. Defaults to {‚ÄúCRV1‚Äù: idname}. Options include ‚Äúiid‚Äù, ‚Äúhetero‚Äù, or a dictionary like {‚ÄúCRV1‚Äù: idname}.\nNone\n\n\npre_window\nint\nThe number of periods before the treatment to include in the estimation. Default is the minimum relative year in the data.\nNone\n\n\npost_window\nint\nThe number of periods after the treatment to include in the estimation. Default is the maximum relative year in the data.\nNone\n\n\nnever_treated\nint\nValue in gname indicating units never treated. Default is 0.\n0\n\n\natt\nbool\nIf True, estimates the pooled average treatment effect on the treated (ATT). Default is False.\nTrue\n\n\nxfml\nstr\nFormula for the covariates. Not yet supported.\nNone",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "did.estimation.lpdid"
    ]
  },
  {
    "objectID": "reference/did.estimation.lpdid.html#returns",
    "href": "reference/did.estimation.lpdid.html#returns",
    "title": "did.estimation.lpdid",
    "section": "Returns",
    "text": "Returns\n\n\n\nType\nDescription\n\n\n\n\nDataFrame\nA DataFrame with the estimated coefficients.",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "did.estimation.lpdid"
    ]
  },
  {
    "objectID": "reference/did.estimation.lpdid.html#examples",
    "href": "reference/did.estimation.lpdid.html#examples",
    "title": "did.estimation.lpdid",
    "section": "Examples",
    "text": "Examples\n\nimport pandas as pd\nfrom pyfixest.did.estimation import lpdid\n\nurl = \"https://raw.githubusercontent.com/py-econometrics/pyfixest/master/pyfixest/did/data/df_het.csv\"\ndf_het = pd.read_csv(url)\n\nfit = lpdid(\n    df_het,\n    yname=\"dep_var\",\n    idname=\"unit\",\n    tname=\"year\",\n    gname=\"g\",\n    vcov={\"CRV1\": \"state\"},\n    pre_window=-20,\n    post_window=20,\n    att=False\n)\n\nfit.tidy().head()\nfit.iplot(figsize= [1200, 400], coord_flip=False).show()\n\n\n            \n            \n            \n\n\n\n            \n            \n            \n\n\n   \n   \n\n\nTo get the ATT, set att=True:\n\nfit = lpdid(\n    df_het,\n    yname=\"dep_var\",\n    idname=\"unit\",\n    tname=\"year\",\n    gname=\"g\",\n    vcov={\"CRV1\": \"state\"},\n    pre_window=-20,\n    post_window=20,\n    att=True\n)\nfit.tidy()\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n2.5%\n97.5%\nN\n\n\n\n\ntreat_diff\n2.506746\n0.071357\n35.129648\n0.0\n2.362413\n2.65108\n5716.0",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "did.estimation.lpdid"
    ]
  },
  {
    "objectID": "reference/did.estimation.did2s.html",
    "href": "reference/did.estimation.did2s.html",
    "title": "did.estimation.did2s",
    "section": "",
    "text": "did.estimation.did2s(data, yname, first_stage, second_stage, treatment, cluster)\nEstimate a Difference-in-Differences model using Gardner‚Äôs two-step DID2S estimator.",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "did.estimation.did2s"
    ]
  },
  {
    "objectID": "reference/did.estimation.did2s.html#parameters",
    "href": "reference/did.estimation.did2s.html#parameters",
    "title": "did.estimation.did2s",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\npd.DataFrame\nThe DataFrame containing all variables.\nrequired\n\n\nyname\nstr\nThe name of the dependent variable.\nrequired\n\n\nfirst_stage\nstr\nThe formula for the first stage, starting with ‚Äò~‚Äô.\nrequired\n\n\nsecond_stage\nstr\nThe formula for the second stage, starting with ‚Äò~‚Äô.\nrequired\n\n\ntreatment\nstr\nThe name of the treatment variable.\nrequired\n\n\ncluster\nstr\nThe name of the cluster variable.\nrequired",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "did.estimation.did2s"
    ]
  },
  {
    "objectID": "reference/did.estimation.did2s.html#returns",
    "href": "reference/did.estimation.did2s.html#returns",
    "title": "did.estimation.did2s",
    "section": "Returns",
    "text": "Returns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nobject\nA fitted model object of class [Feols(/reference/Feols.qmd).",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "did.estimation.did2s"
    ]
  },
  {
    "objectID": "reference/did.estimation.did2s.html#examples",
    "href": "reference/did.estimation.did2s.html#examples",
    "title": "did.estimation.did2s",
    "section": "Examples",
    "text": "Examples\n\nimport pandas as pd\nimport numpy as np\nfrom pyfixest.did.estimation import did2s\n\nurl = \"https://raw.githubusercontent.com/py-econometrics/pyfixest/master/pyfixest/did/data/df_het.csv\"\ndf_het = pd.read_csv(url)\ndf_het.head()\n\n\n            \n            \n            \n\n\n\n            \n            \n            \n\n\n\n\n\n\n\n\n\nunit\nstate\ngroup\nunit_fe\ng\nyear\nyear_fe\ntreat\nrel_year\nrel_year_binned\nerror\nte\nte_dynamic\ndep_var\n\n\n\n\n0\n1\n33\nGroup 2\n7.043016\n2010\n1990\n0.066159\nFalse\n-20.0\n-6\n-0.086466\n0\n0.0\n7.022709\n\n\n1\n1\n33\nGroup 2\n7.043016\n2010\n1991\n-0.030980\nFalse\n-19.0\n-6\n0.766593\n0\n0.0\n7.778628\n\n\n2\n1\n33\nGroup 2\n7.043016\n2010\n1992\n-0.119607\nFalse\n-18.0\n-6\n1.512968\n0\n0.0\n8.436377\n\n\n3\n1\n33\nGroup 2\n7.043016\n2010\n1993\n0.126321\nFalse\n-17.0\n-6\n0.021870\n0\n0.0\n7.191207\n\n\n4\n1\n33\nGroup 2\n7.043016\n2010\n1994\n-0.106921\nFalse\n-16.0\n-6\n-0.017603\n0\n0.0\n6.918492\n\n\n\n\n\n\n\nIn a first step, we estimate a classical event study model:\n\n# estimate the model\nfit = did2s(\n    df_het,\n    yname=\"dep_var\",\n    first_stage=\"~ 0 | unit + year\",\n    second_stage=\"~i(rel_year, ref=-1.0)\",\n    treatment=\"treat\",\n    cluster=\"state\",\n)\n\nfit.tidy().head()\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n2.5%\n97.5%\n\n\nCoefficient\n\n\n\n\n\n\n\n\n\n\nC(rel_year, contr.treatment(base=-1.0))[T.-inf]\n-3.551930e-08\n5.844125e-09\n-6.077778\n1.218593e-09\n-4.697357e-08\n-2.406502e-08\n\n\nC(rel_year, contr.treatment(base=-1.0))[T.-20.0]\n-5.822583e-02\n3.580900e-02\n-1.626011\n1.039473e-01\n-1.284102e-01\n1.195852e-02\n\n\nC(rel_year, contr.treatment(base=-1.0))[T.-19.0]\n-6.032212e-03\n3.034072e-02\n-0.198816\n8.424069e-01\n-6.549894e-02\n5.343451e-02\n\n\nC(rel_year, contr.treatment(base=-1.0))[T.-18.0]\n-6.152375e-03\n3.509400e-02\n-0.175311\n8.608350e-01\n-7.493535e-02\n6.263060e-02\n\n\nC(rel_year, contr.treatment(base=-1.0))[T.-17.0]\n-1.253327e-02\n2.483369e-02\n-0.504688\n6.137779e-01\n-6.120641e-02\n3.613987e-02\n\n\n\n\n\n\n\nWe can also inspect the model visually:\n\nfit.iplot(figsize= [1200, 400], coord_flip=False).show()\n\n   \n   \n\n\nTo estimate a pooled effect, we need to slightly update the second stage formula:\n\nfit = did2s(\n    df_het,\n    yname=\"dep_var\",\n    first_stage=\"~ 0 | unit + year\",\n    second_stage=\"~i(treat)\",\n    treatment=\"treat\",\n    cluster=\"state\"\n)\nfit.tidy().head()\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n2.5%\n97.5%\n\n\nCoefficient\n\n\n\n\n\n\n\n\n\n\nC(treat)[T.True]\n2.230482\n0.024709\n90.271444\n0.0\n2.182054\n2.27891",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "did.estimation.did2s"
    ]
  },
  {
    "objectID": "reference/estimation.Feiv.html",
    "href": "reference/estimation.Feiv.html",
    "title": "estimation.Feiv",
    "section": "",
    "text": "estimation.Feiv(self, Y, X, endogvar, Z, weights, coefnames_x, coefnames_z, collin_tol, weights_name, weights_type, solver='np.linalg.solve')\nNon user-facing class to estimate an IV model using a 2SLS estimator.\nInherits from the Feols class. Users should not directly instantiate this class, but rather use the feols() function. Note that no demeaning is performed in this class: demeaning is performed in the FixestMulti class (to allow for caching of demeaned variables for multiple estimation).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nY\nnp.ndarray\nDependent variable, a two-dimensional np.array.\nrequired\n\n\nX\nnp.ndarray\nIndependent variables, a two-dimensional np.array.\nrequired\n\n\nendgvar\nnp.ndarray\nEndogenous Indenpendent variables, a two-dimensional np.array.\nrequired\n\n\nZ\nnp.ndarray\nInstruments, a two-dimensional np.array.\nrequired\n\n\nweights\nnp.ndarray\nWeights, a one-dimensional np.array.\nrequired\n\n\ncoefnames_x\nlist\nNames of the coefficients of X.\nrequired\n\n\ncoefnames_z\nlist\nNames of the coefficients of Z.\nrequired\n\n\ncollin_tol\nfloat\nTolerance for collinearity check.\nrequired\n\n\nsolver\nstr\nSolver to use for the estimation. Alternative is ‚Äònp.linalg.lstsq‚Äô.\n'np.linalg.solve'\n\n\nweights_name\nOptional[str]\nName of the weights variable.\nrequired\n\n\nweights_type\nOptional[str]\nType of the weights variable. Either ‚Äúaweights‚Äù for analytic weights or ‚Äúfweights‚Äù for frequency weights.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n_Z\nnp.ndarray\nProcessed instruments after handling multicollinearity.\n\n\n_weights_type_feiv\nstr\nType of the weights variable defined in Feiv class. Either ‚Äúaweights‚Äù for analytic weights or ‚Äúfweights‚Äù for frequency weights.\n\n\n_coefnames_z\nlist\nNames of coefficients for Z after handling multicollinearity.\n\n\n_collin_vars_z\nlist\nVariables identified as collinear in Z.\n\n\n_collin_index_z\nlist\nIndices of collinear variables in Z.\n\n\n_is_iv\nbool\nIndicator if instrumental variables are used.\n\n\n_support_crv3_inference\nbool\nIndicator for supporting CRV3 inference.\n\n\n_support_iid_inference\nbool\nIndicator for supporting IID inference.\n\n\n_tZX\nnp.ndarray\nTranspose of Z times X.\n\n\n_tXZ\nnp.ndarray\nTranspose of X times Z.\n\n\n_tZy\nnp.ndarray\nTranspose of Z times Y.\n\n\n_tZZinv\nnp.ndarray\nInverse of transpose of Z times Z.\n\n\n_beta_hat\nnp.ndarray\nEstimated regression coefficients.\n\n\n_Y_hat_link\nnp.ndarray\nPredicted values of the regression model.\n\n\n_u_hat\nnp.ndarray\nResiduals of the regression model.\n\n\n_scores\nnp.ndarray\nScores used in the regression.\n\n\n_hessian\nnp.ndarray\nHessian matrix used in the regression.\n\n\n_bread\nnp.ndarray\nBread matrix used in the regression.\n\n\n_pi_hat\nnp.ndarray\nEstimated coefficients from 1st stage regression\n\n\n_X_hat\nnp.ndarray\nPredicted values of the 1st stage regression\n\n\n_v_hat\nnp.ndarray\nResiduals of the 1st stage regression\n\n\n_model_1st_stage\nAny\nfeols object of 1st stage regression. It contains various results and diagnostics from the fixed effects OLS regression.\n\n\n_endogvar_1st_stage\nnp.ndarray\nUnweihgted Endogenous independent variable vector\n\n\n_Z_1st_stage\nnp.ndarray\nUnweighted instruments vector to be used for 1st stage\n\n\n_non_exo_instruments\nlist\nList of instruments name excluding exogenous independent vars.\n\n\n__p_iv\nscalar\nNumber of instruments listed in _non_exo_instruments\n\n\n_f_stat_1st_stage\nscalar\nF-statistics of First Stage regression for evaluation of IV weakness. The computed F-statistics test the following null hypothesis : # H0 : Œ≤_{z_1} = 0 & ‚Ä¶ & Œ≤_{z_{p_iv}} = 0 where z_1, ‚Ä¶, z_{p_iv} # are the instrument variables # H1 : H0 does not hold Note that this F-statistics is adjusted to heteroskedasticity / clusters if users set specification of variance-covariance matrix type\n\n\n_eff_F\nscalar\nEffective F-statistics of first stage regression as in Olea and Pflueger 2013\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nIf Z is not a two-dimensional array.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nIV_Diag\nImplement IV diagnostic tests.\n\n\nIV_weakness_test\nImplement IV weakness test (F-test).\n\n\neff_F\nCompute Effective F stat (Olea and Pflueger 2013).\n\n\nfirst_stage\nImplement First stage regression.\n\n\nget_fit\nFit a IV model using a 2SLS estimator.\n\n\n\n\n\nestimation.Feiv.IV_Diag(statistics=None)\nImplement IV diagnostic tests.\n\n\nThis method covers diagnostic tests related with IV regression. We currently have IV weak tests only. More test will be updated in future updates!\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nstatistics\nlist[str]\nList of IV diagnostic statistics\nNone\n\n\n\n\n\n\nThe following is an example usage of this method:\nimport numpy as np\nimport pandas as pd\nfrom pyfixest.estimation.estimation import feols\n\n# Set random seed for reproducibility\nnp.random.seed(1)\n\n# Number of observations\nn = 1000\n\n# Simulate the data\n# Instrumental variable\nz = np.random.binomial(1, 0.5, size=n)\nz2 = np.random.binomial(1, 0.5, size=n)\n\n# Endogenous variable\nd = 0.5 * z + 1.5 * z2 + np.random.normal(size=n)\n\n# Control variables\nc1 = np.random.normal(size=n)\nc2 = np.random.normal(size=n)\n\n# Outcome variable\ny = 1.0 + 1.5 * d + 0.8 * c1 + 0.5 * c2 + np.random.normal(size=n)\n\n# Cluster variable\ncluster = np.random.randint(1, 50, size=n)\nweights = np.random.uniform(1, 3, size=n)\n\n# Create a DataFrame\ndata = pd.DataFrame({\n    'd': d,\n    'y': y,\n    'z': z,\n    'z2': z2,\n    'c1': c1,\n    'c2': c2,\n    'cluster': cluster,\n    'weights': weights\n})\n\nvcov_detail = \"iid\"\n\n# Fit OLS model\nfit_ols = feols(\"y ~ 1 + d + c1 + c2\", data=data, vcov=vcov_detail)\n\n# Fit IV model\nfit_iv = feols(\"y ~ 1 + c1 + c2 | d ~ z\", data=data,\n         vcov=vcov_detail,\n         weights=\"weights\")\nfit_iv.first_stage()\nF_stat_pf = fit_iv._f_stat_1st_stage\nfit_iv.IV_Diag()\nF_stat_eff_pf = fit_iv._eff_F\n\nprint(\"(Unadjusted) F stat :\", F_stat_pf)\nprint(\"Effective F stat :\", F_stat_eff_pf)\n\n# The example above generates the following results\n# (Unadjusted) F stat : 52.81535560457482\n# Effective F stat : 48.661542741328205\n\n\n\n\nestimation.Feiv.IV_weakness_test(iv_diag_statistics=None)\nImplement IV weakness test (F-test).\nThis method covers hetero-robust and clustered-robust F statistics. It produces two statistics:\n\nself._f_stat_1st_stage: F statistics of first stage regression\nself._eff_F: Effective F statistics (Olea and Pflueger 2013) of first stage regression\n\n\n\n‚Äúself._f_stat_1st_stage‚Äù is adjusted to the specification of vcov. If vcov_detail = ‚Äúiid‚Äù, F statistics is not adjusted, otherwise it is always adjusted.\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\niv_diag_statistics\nlist\nList of IV weakness statistics\nNone\n\n\n\n\n\n\n\nestimation.Feiv.eff_F()\nCompute Effective F stat (Olea and Pflueger 2013).\n\n\n\nestimation.Feiv.first_stage()\nImplement First stage regression.\n\n\n\nestimation.Feiv.get_fit()\nFit a IV model using a 2SLS estimator.",
    "crumbs": [
      "Documentation",
      "Estimation Classes",
      "estimation.Feiv"
    ]
  },
  {
    "objectID": "reference/estimation.Feiv.html#parameters",
    "href": "reference/estimation.Feiv.html#parameters",
    "title": "estimation.Feiv",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nY\nnp.ndarray\nDependent variable, a two-dimensional np.array.\nrequired\n\n\nX\nnp.ndarray\nIndependent variables, a two-dimensional np.array.\nrequired\n\n\nendgvar\nnp.ndarray\nEndogenous Indenpendent variables, a two-dimensional np.array.\nrequired\n\n\nZ\nnp.ndarray\nInstruments, a two-dimensional np.array.\nrequired\n\n\nweights\nnp.ndarray\nWeights, a one-dimensional np.array.\nrequired\n\n\ncoefnames_x\nlist\nNames of the coefficients of X.\nrequired\n\n\ncoefnames_z\nlist\nNames of the coefficients of Z.\nrequired\n\n\ncollin_tol\nfloat\nTolerance for collinearity check.\nrequired\n\n\nsolver\nstr\nSolver to use for the estimation. Alternative is ‚Äònp.linalg.lstsq‚Äô.\n'np.linalg.solve'\n\n\nweights_name\nOptional[str]\nName of the weights variable.\nrequired\n\n\nweights_type\nOptional[str]\nType of the weights variable. Either ‚Äúaweights‚Äù for analytic weights or ‚Äúfweights‚Äù for frequency weights.\nrequired",
    "crumbs": [
      "Documentation",
      "Estimation Classes",
      "estimation.Feiv"
    ]
  },
  {
    "objectID": "reference/estimation.Feiv.html#attributes",
    "href": "reference/estimation.Feiv.html#attributes",
    "title": "estimation.Feiv",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n_Z\nnp.ndarray\nProcessed instruments after handling multicollinearity.\n\n\n_weights_type_feiv\nstr\nType of the weights variable defined in Feiv class. Either ‚Äúaweights‚Äù for analytic weights or ‚Äúfweights‚Äù for frequency weights.\n\n\n_coefnames_z\nlist\nNames of coefficients for Z after handling multicollinearity.\n\n\n_collin_vars_z\nlist\nVariables identified as collinear in Z.\n\n\n_collin_index_z\nlist\nIndices of collinear variables in Z.\n\n\n_is_iv\nbool\nIndicator if instrumental variables are used.\n\n\n_support_crv3_inference\nbool\nIndicator for supporting CRV3 inference.\n\n\n_support_iid_inference\nbool\nIndicator for supporting IID inference.\n\n\n_tZX\nnp.ndarray\nTranspose of Z times X.\n\n\n_tXZ\nnp.ndarray\nTranspose of X times Z.\n\n\n_tZy\nnp.ndarray\nTranspose of Z times Y.\n\n\n_tZZinv\nnp.ndarray\nInverse of transpose of Z times Z.\n\n\n_beta_hat\nnp.ndarray\nEstimated regression coefficients.\n\n\n_Y_hat_link\nnp.ndarray\nPredicted values of the regression model.\n\n\n_u_hat\nnp.ndarray\nResiduals of the regression model.\n\n\n_scores\nnp.ndarray\nScores used in the regression.\n\n\n_hessian\nnp.ndarray\nHessian matrix used in the regression.\n\n\n_bread\nnp.ndarray\nBread matrix used in the regression.\n\n\n_pi_hat\nnp.ndarray\nEstimated coefficients from 1st stage regression\n\n\n_X_hat\nnp.ndarray\nPredicted values of the 1st stage regression\n\n\n_v_hat\nnp.ndarray\nResiduals of the 1st stage regression\n\n\n_model_1st_stage\nAny\nfeols object of 1st stage regression. It contains various results and diagnostics from the fixed effects OLS regression.\n\n\n_endogvar_1st_stage\nnp.ndarray\nUnweihgted Endogenous independent variable vector\n\n\n_Z_1st_stage\nnp.ndarray\nUnweighted instruments vector to be used for 1st stage\n\n\n_non_exo_instruments\nlist\nList of instruments name excluding exogenous independent vars.\n\n\n__p_iv\nscalar\nNumber of instruments listed in _non_exo_instruments\n\n\n_f_stat_1st_stage\nscalar\nF-statistics of First Stage regression for evaluation of IV weakness. The computed F-statistics test the following null hypothesis : # H0 : Œ≤_{z_1} = 0 & ‚Ä¶ & Œ≤_{z_{p_iv}} = 0 where z_1, ‚Ä¶, z_{p_iv} # are the instrument variables # H1 : H0 does not hold Note that this F-statistics is adjusted to heteroskedasticity / clusters if users set specification of variance-covariance matrix type\n\n\n_eff_F\nscalar\nEffective F-statistics of first stage regression as in Olea and Pflueger 2013",
    "crumbs": [
      "Documentation",
      "Estimation Classes",
      "estimation.Feiv"
    ]
  },
  {
    "objectID": "reference/estimation.Feiv.html#raises",
    "href": "reference/estimation.Feiv.html#raises",
    "title": "estimation.Feiv",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\nValueError\nIf Z is not a two-dimensional array.",
    "crumbs": [
      "Documentation",
      "Estimation Classes",
      "estimation.Feiv"
    ]
  },
  {
    "objectID": "reference/estimation.Feiv.html#methods",
    "href": "reference/estimation.Feiv.html#methods",
    "title": "estimation.Feiv",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nIV_Diag\nImplement IV diagnostic tests.\n\n\nIV_weakness_test\nImplement IV weakness test (F-test).\n\n\neff_F\nCompute Effective F stat (Olea and Pflueger 2013).\n\n\nfirst_stage\nImplement First stage regression.\n\n\nget_fit\nFit a IV model using a 2SLS estimator.\n\n\n\n\n\nestimation.Feiv.IV_Diag(statistics=None)\nImplement IV diagnostic tests.\n\n\nThis method covers diagnostic tests related with IV regression. We currently have IV weak tests only. More test will be updated in future updates!\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nstatistics\nlist[str]\nList of IV diagnostic statistics\nNone\n\n\n\n\n\n\nThe following is an example usage of this method:\nimport numpy as np\nimport pandas as pd\nfrom pyfixest.estimation.estimation import feols\n\n# Set random seed for reproducibility\nnp.random.seed(1)\n\n# Number of observations\nn = 1000\n\n# Simulate the data\n# Instrumental variable\nz = np.random.binomial(1, 0.5, size=n)\nz2 = np.random.binomial(1, 0.5, size=n)\n\n# Endogenous variable\nd = 0.5 * z + 1.5 * z2 + np.random.normal(size=n)\n\n# Control variables\nc1 = np.random.normal(size=n)\nc2 = np.random.normal(size=n)\n\n# Outcome variable\ny = 1.0 + 1.5 * d + 0.8 * c1 + 0.5 * c2 + np.random.normal(size=n)\n\n# Cluster variable\ncluster = np.random.randint(1, 50, size=n)\nweights = np.random.uniform(1, 3, size=n)\n\n# Create a DataFrame\ndata = pd.DataFrame({\n    'd': d,\n    'y': y,\n    'z': z,\n    'z2': z2,\n    'c1': c1,\n    'c2': c2,\n    'cluster': cluster,\n    'weights': weights\n})\n\nvcov_detail = \"iid\"\n\n# Fit OLS model\nfit_ols = feols(\"y ~ 1 + d + c1 + c2\", data=data, vcov=vcov_detail)\n\n# Fit IV model\nfit_iv = feols(\"y ~ 1 + c1 + c2 | d ~ z\", data=data,\n         vcov=vcov_detail,\n         weights=\"weights\")\nfit_iv.first_stage()\nF_stat_pf = fit_iv._f_stat_1st_stage\nfit_iv.IV_Diag()\nF_stat_eff_pf = fit_iv._eff_F\n\nprint(\"(Unadjusted) F stat :\", F_stat_pf)\nprint(\"Effective F stat :\", F_stat_eff_pf)\n\n# The example above generates the following results\n# (Unadjusted) F stat : 52.81535560457482\n# Effective F stat : 48.661542741328205\n\n\n\n\nestimation.Feiv.IV_weakness_test(iv_diag_statistics=None)\nImplement IV weakness test (F-test).\nThis method covers hetero-robust and clustered-robust F statistics. It produces two statistics:\n\nself._f_stat_1st_stage: F statistics of first stage regression\nself._eff_F: Effective F statistics (Olea and Pflueger 2013) of first stage regression\n\n\n\n‚Äúself._f_stat_1st_stage‚Äù is adjusted to the specification of vcov. If vcov_detail = ‚Äúiid‚Äù, F statistics is not adjusted, otherwise it is always adjusted.\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\niv_diag_statistics\nlist\nList of IV weakness statistics\nNone\n\n\n\n\n\n\n\nestimation.Feiv.eff_F()\nCompute Effective F stat (Olea and Pflueger 2013).\n\n\n\nestimation.Feiv.first_stage()\nImplement First stage regression.\n\n\n\nestimation.Feiv.get_fit()\nFit a IV model using a 2SLS estimator.",
    "crumbs": [
      "Documentation",
      "Estimation Classes",
      "estimation.Feiv"
    ]
  },
  {
    "objectID": "reference/estimation.Feols.html",
    "href": "reference/estimation.Feols.html",
    "title": "estimation.Feols",
    "section": "",
    "text": "estimation.Feols(self, Y, X, weights, collin_tol, coefnames, weights_name, weights_type, solver='np.linalg.solve')\nNon user-facing class to estimate a liner regression via OLS.\nUsers should not directly instantiate this class, but rather use the feols() function. Note that no demeaning is performed in this class: demeaning is performed in the FixestMulti class (to allow for caching of demeaned variables for multiple estimation).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nY\nnp.ndarray\nDependent variable, a two-dimensional numpy array.\nrequired\n\n\nX\nnp.ndarray\nIndependent variables, a two-dimensional numpy array.\nrequired\n\n\nweights\nnp.ndarray\nWeights, a one-dimensional numpy array.\nrequired\n\n\ncollin_tol\nfloat\nTolerance level for collinearity checks.\nrequired\n\n\ncoefnames\nlist[str]\nNames of the coefficients (of the design matrix X).\nrequired\n\n\nweights_name\nOptional[str]\nName of the weights variable.\nrequired\n\n\nweights_type\nOptional[str]\nType of the weights variable. Either ‚Äúaweights‚Äù for analytic weights or ‚Äúfweights‚Äù for frequency weights.\nrequired\n\n\nsolver\nstr, optional.\nThe solver to use for the regression. Can be either ‚Äúnp.linalg.solve‚Äù or ‚Äúnp.linalg.lstsq‚Äù. Defaults to ‚Äúnp.linalg.solve‚Äù.\n'np.linalg.solve'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n_method\nstr\nSpecifies the method used for regression, set to ‚Äúfeols‚Äù.\n\n\n_is_iv\nbool\nIndicates whether instrumental variables are used, initialized as False.\n\n\n_Y\nnp.ndarray\nThe dependent variable array.\n\n\n_X\nnp.ndarray\nThe independent variables array.\n\n\n_X_is_empty\nbool\nIndicates whether the X array is empty.\n\n\n_collin_tol\nfloat\nTolerance level for collinearity checks.\n\n\n_coefnames\nlist\nNames of the coefficients (of the design matrix X).\n\n\n_collin_vars\nlist\nVariables identified as collinear.\n\n\n_collin_index\nlist\nIndices of collinear variables.\n\n\n_Z\nnp.ndarray\nAlias for the _X array, used for calculations.\n\n\n_solver\nstr\nThe solver used for the regression.\n\n\n_weights\nnp.ndarray\nArray of weights for each observation.\n\n\n_N\nint\nNumber of observations.\n\n\n_k\nint\nNumber of independent variables (or features).\n\n\n_support_crv3_inference\nbool\nIndicates support for CRV3 inference.\n\n\n_data\nAny\nData used in the regression, to be enriched outside of the class.\n\n\n_fml\nAny\nFormula used in the regression, to be enriched outside of the class.\n\n\n_has_fixef\nbool\nIndicates whether fixed effects are used.\n\n\n_fixef\nAny\nFixed effects used in the regression.\n\n\n_icovars\nAny\nInternal covariates, to be enriched outside of the class.\n\n\n_ssc_dict\ndict\ndictionary for sum of squares and cross products matrices.\n\n\n_tZX\nnp.ndarray\nTranspose of Z multiplied by X, set in get_fit().\n\n\n_tXZ\nnp.ndarray\nTranspose of X multiplied by Z, set in get_fit().\n\n\n_tZy\nnp.ndarray\nTranspose of Z multiplied by Y, set in get_fit().\n\n\n_tZZinv\nnp.ndarray\nInverse of the transpose of Z multiplied by Z, set in get_fit().\n\n\n_beta_hat\nnp.ndarray\nEstimated regression coefficients.\n\n\n_Y_hat_link\nnp.ndarray\nPredicted values of the dependent variable.\n\n\n_Y_hat_response\nnp.ndarray\nResponse predictions of the model.\n\n\n_u_hat\nnp.ndarray\nResiduals of the regression model.\n\n\n_scores\nnp.ndarray\nScores used in the regression analysis.\n\n\n_hessian\nnp.ndarray\nHessian matrix used in the regression.\n\n\n_bread\nnp.ndarray\nBread matrix, used in calculating the variance-covariance matrix.\n\n\n_vcov_type\nAny\nType of variance-covariance matrix used.\n\n\n_vcov_type_detail\nAny\nDetailed specification of the variance-covariance matrix type.\n\n\n_is_clustered\nbool\nIndicates if clustering is used in the variance-covariance calculation.\n\n\n_clustervar\nAny\nVariable used for clustering in the variance-covariance calculation.\n\n\n_G\nAny\nGroup information used in clustering.\n\n\n_ssc\nAny\nSum of squares and cross products matrix.\n\n\n_vcov\nnp.ndarray\nVariance-covariance matrix of the estimated coefficients.\n\n\n_se\nnp.ndarray\nStandard errors of the estimated coefficients.\n\n\n_tstat\nnp.ndarray\nT-statistics of the estimated coefficients.\n\n\n_pvalue\nnp.ndarray\nP-values associated with the t-statistics.\n\n\n_conf_int\nnp.ndarray\nConfidence intervals for the estimated coefficients.\n\n\n_F_stat\nAny\nF-statistic for the model, set in get_Ftest().\n\n\n_fixef_dict\ndict\ndictionary containing fixed effects estimates.\n\n\n_sumFE\nnp.ndarray\nSum of all fixed effects for each observation.\n\n\n_rmse\nfloat\nRoot mean squared error of the model.\n\n\n_r2\nfloat\nR-squared value of the model.\n\n\n_r2_within\nfloat\nR-squared value computed on demeaned dependent variable.\n\n\n_adj_r2\nfloat\nAdjusted R-squared value of the model.\n\n\n_adj_r2_within\nfloat\nAdjusted R-squared value computed on demeaned dependent variable.\n\n\n_solver\nstr\nThe solver used to fit the normal equation.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_fixest_multi_context\nEnrich Feols object.\n\n\nccv\nCompute the Causal Cluster Variance following Abadie et al (QJE 2023).\n\n\ncoef\nFitted model coefficents.\n\n\nconfint\nFitted model confidence intervals.\n\n\nfixef\nCompute the coefficients of (swept out) fixed effects for a regression model.\n\n\nget_fit\nFit an OLS model.\n\n\nget_inference\nCompute standard errors, t-statistics, and p-values for the regression model.\n\n\nget_nobs\nFetch the number of observations used in fitting the regression model.\n\n\nget_performance\nGet Goodness-of-Fit measures.\n\n\nplot_ritest\nPlot the distribution of the Randomization Inference Statistics.\n\n\npredict\nPredict values of the model on new data.\n\n\npvalue\nFitted model p-values.\n\n\nresid\nFitted model residuals.\n\n\nritest\nConduct Randomization Inference (RI) test against a null hypothesis of\n\n\nse\nFitted model standard errors.\n\n\nsolve_ols\nSolve the ordinary least squares problem using the specified solver.\n\n\ntidy\nTidy model outputs.\n\n\ntstat\nFitted model t-statistics.\n\n\nupdate\nUpdate coefficients for new observations using Sherman-Morrison formula.\n\n\nvcov\nCompute covariance matrices for an estimated regression model.\n\n\nwald_test\nConduct Wald test.\n\n\nwildboottest\nRun a wild cluster bootstrap based on an object of type ‚ÄúFeols‚Äù.\n\n\n\n\n\nestimation.Feols.add_fixest_multi_context(fml, depvar, Y, _data, _ssc_dict, _k_fe, fval, store_data)\nEnrich Feols object.\nEnrich an instance of Feols Class with additional attributes set in the FixestMulti class.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfml\nstr\nThe formula used for estimation.\nrequired\n\n\ndepvar\nstr\nThe dependent variable of the regression model.\nrequired\n\n\nY\npd.Series\nThe dependent variable of the regression model.\nrequired\n\n\n_data\npd.DataFrame\nThe data used for estimation.\nrequired\n\n\n_ssc_dict\ndict\nA dictionary with the sum of squares and cross products matrices.\nrequired\n\n\n_k_fe\nint\nThe number of fixed effects.\nrequired\n\n\nfval\nstr\nThe fixed effects formula.\nrequired\n\n\nstore_data\nbool\nIndicates whether to save the data used for estimation in the object\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nestimation.Feols.ccv(treatment, cluster=None, seed=None, n_splits=8, pk=1, qk=1)\nCompute the Causal Cluster Variance following Abadie et al (QJE 2023).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntreatment\n\nThe name of the treatment variable.\nrequired\n\n\ncluster\nstr\nThe name of the cluster variable. None by default. If None, uses the cluster variable from the model fit.\nNone\n\n\nseed\nint\nAn integer to set the random seed. Defaults to None.\nNone\n\n\nn_splits\nint\nThe number of splits to use in the cross-fitting procedure. Defaults to 8.\n8\n\n\npk\nfloat\nThe proportion of sampled clusters. Defaults to 1, which corresponds to all clusters of the population being sampled.\n1\n\n\nqk\nfloat\nThe proportion of sampled observations within each cluster. Defaults to 1, which corresponds to all observations within each cluster being sampled.\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nA DataFrame with inference based on the ‚ÄúCausal Cluster Variance‚Äù and ‚Äúregular‚Äù CRV1 inference.\n\n\n\n\n\n\nfrom pyfixest.estimation import feols\nfrom pyfixest.utils import get_data\n\ndata = get_data()\ndata[\"D1\"] = np.random.choice([0, 1], size=data.shape[0])\n\nfit = feols(\"Y ~ D\", data=data, vcov={\"CRV1\": \"group_id\"})\nfit.ccv(treatment=\"D\", pk=0.05, gk=0.5, n_splits=8, seed=123).head()\n\n\n\n\nestimation.Feols.coef()\nFitted model coefficents.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.Series\nA pd.Series with the estimated coefficients of the regression model.\n\n\n\n\n\n\n\nestimation.Feols.confint(alpha=0.05, keep=None, drop=None, exact_match=False, joint=False, seed=None, reps=10000)\nFitted model confidence intervals.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nalpha\nfloat\nThe significance level for confidence intervals. Defaults to 0.05. keep: str or list of str, optional\n0.05\n\n\njoint\nbool\nWhether to compute simultaneous confidence interval for joint null of parameters selected by keep and drop. Defaults to False. See https://www.causalml-book.org/assets/chapters/CausalML_chap_4.pdf, Remark 4.4.1 for details.\nFalse\n\n\nkeep\nOptional[Union[list, str]]\nThe pattern for retaining coefficient names. You can pass a string (one pattern) or a list (multiple patterns). Default is keeping all coefficients. You should use regular expressions to select coefficients. ‚Äúage‚Äù, # would keep all coefficients containing age r‚Äù^tr‚Äù, # would keep all coefficients starting with tr r‚Äù\\d$‚Äú, # would keep all coefficients ending with number Output will be in the order of the patterns.\nNone\n\n\ndrop\nOptional[Union[list, str]]\nThe pattern for excluding coefficient names. You can pass a string (one pattern) or a list (multiple patterns). Syntax is the same as for keep. Default is keeping all coefficients. Parameter keep and drop can be used simultaneously.\nNone\n\n\nexact_match\nOptional[bool]\nWhether to use exact match for keep and drop. Default is False. If True, the pattern will be matched exactly to the coefficient name instead of using regular expressions.\nFalse\n\n\nreps\nint\nThe number of bootstrap iterations to run for joint confidence intervals. Defaults to 10_000. Only used if joint is True.\n10000\n\n\nseed\nint\nThe seed for the random number generator. Defaults to None. Only used if joint is True.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nA pd.DataFrame with confidence intervals of the estimated regression model for the selected coefficients.\n\n\n\n\n\n\nfrom pyfixest.utils import get_data\nfrom pyfixest.estimation import feols\n\ndata = get_data()\nfit = feols(\"Y ~ C(f1)\", data=data)\nfit.confint(alpha=0.10).head()\nfit.confint(alpha=0.10, joint=True, reps=9999).head()\n\n\n\n\nestimation.Feols.fixef(atol=1e-06, btol=1e-06)\nCompute the coefficients of (swept out) fixed effects for a regression model.\nThis method creates the following attributes: - alphaDF (pd.DataFrame): A DataFrame with the estimated fixed effects. - sumFE (np.array): An array with the sum of fixed effects for each observation (i = 1, ‚Ä¶, N).\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nestimation.Feols.get_fit()\nFit an OLS model.\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nestimation.Feols.get_inference(alpha=0.05)\nCompute standard errors, t-statistics, and p-values for the regression model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nalpha\nfloat\nThe significance level for confidence intervals. Defaults to 0.05, which produces a 95% confidence interval.\n0.05\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nestimation.Feols.get_nobs()\nFetch the number of observations used in fitting the regression model.\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nestimation.Feols.get_performance()\nGet Goodness-of-Fit measures.\nCompute multiple additional measures commonly reported with linear regression output, including R-squared and adjusted R-squared. Note that variables with the suffix _within use demeaned dependent variables Y, while variables without do not or are invariant to demeaning.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\nCreates the following instances:\n\n\n\n- r2 (float): R-squared of the regression model.\n\n\n\n- adj_r2 (float): Adjusted R-squared of the regression model.\n\n\n\n- r2_within (float): R-squared of the regression model, computed on\n\n\n\ndemeaned dependent variable.\n\n\n\n- adj_r2_within (float): Adjusted R-squared of the regression model,\n\n\n\ncomputed on demeaned dependent variable.\n\n\n\n\n\n\n\n\nestimation.Feols.plot_ritest(plot_backend='lets_plot')\nPlot the distribution of the Randomization Inference Statistics.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nplot_backend\nstr\nThe plotting backend to use. Defaults to ‚Äúlets_plot‚Äù. Alternatively, ‚Äúmatplotlib‚Äù is available.\n'lets_plot'\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nA lets_plot or matplotlib figure with the distribution of the Randomization\n\n\n\nInference Statistics.\n\n\n\n\n\n\n\n\nestimation.Feols.predict(newdata=None, atol=1e-06, btol=1e-06, type='link')\nPredict values of the model on new data.\nReturn a flat np.array with predicted values of the regression model. If new fixed effect levels are introduced in newdata, predicted values for such observations will be set to NaN.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nnewdata\nOptional[DataFrameType]\nA pd.DataFrame or pl.DataFrame with the data to be used for prediction. If None (default), the data used for fitting the model is used.\nNone\n\n\ntype\nstr\nThe type of prediction to be computed. Can be either ‚Äúresponse‚Äù (default) or ‚Äúlink‚Äù. For linear models, both are identical.\n'link'\n\n\natol\nFloat\nStopping tolerance for scipy.sparse.linalg.lsqr(). See https://docs.scipy.org/doc/ scipy/reference/generated/scipy.sparse.linalg.lsqr.html\n1e-6\n\n\nbtol\nFloat\nAnother stopping tolerance for scipy.sparse.linalg.lsqr(). See https://docs.scipy.org/doc/ scipy/reference/generated/scipy.sparse.linalg.lsqr.html\n1e-6\n\n\nlink\n\nThe type of prediction to be made. Can be either ‚Äòlink‚Äô or ‚Äòresponse‚Äô. Defaults to ‚Äòlink‚Äô. ‚Äòlink‚Äô and ‚Äòresponse‚Äô lead to identical results for linear models.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnp.ndarray\nA flat np.array with predicted values of the regression model.\n\n\n\n\n\n\n\nestimation.Feols.pvalue()\nFitted model p-values.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.Series\nA pd.Series with p-values of the estimated regression model.\n\n\n\n\n\n\n\nestimation.Feols.resid()\nFitted model residuals.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnp.ndarray\nA np.ndarray with the residuals of the estimated regression model.\n\n\n\n\n\n\n\nestimation.Feols.ritest(resampvar, cluster=None, reps=100, type='randomization-c', rng=None, choose_algorithm='auto', store_ritest_statistics=False, level=0.95)\nConduct Randomization Inference (RI) test against a null hypothesis of resampvar = 0.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nresampvar\nstr\nThe name of the variable to be resampled.\nrequired\n\n\ncluster\nstr\nThe name of the cluster variable in case of cluster random assignment. If provided, resampvar is held constant within each cluster. Defaults to None.\nNone\n\n\nreps\nint\nThe number of randomization iterations. Defaults to 100.\n100\n\n\ntype\nstr\nThe type of the randomization inference test. Can be ‚Äúrandomization-c‚Äù or ‚Äúrandomization-t‚Äù. Note that the ‚Äúrandomization-c‚Äù is much faster, while the ‚Äúrandomization-t‚Äù is recommended by Wu & Ding (JASA, 2021).\n'randomization-c'\n\n\nrng\nnp.random.Generator\nA random number generator. Defaults to None.\nNone\n\n\nchoose_algorithm\nstr\nThe algorithm to use for the computation. Defaults to ‚Äúauto‚Äù. The alternative is ‚Äúfast‚Äù and ‚Äúslow‚Äù, and should only be used for running CI tests. Ironically, this argument is not tested for any input errors from the user! So please don‚Äôt use it =)\n'auto'\n\n\ninclude_plot\n\nWhether to include a plot of the distribution p-values. Defaults to False.\nrequired\n\n\nstore_ritest_statistics\nbool\nWhether to store the simulated statistics of the RI procedure. Defaults to False. If True, stores the simulated statistics in the model object via the ritest_statistics attribute as a numpy array.\nFalse\n\n\nlevel\nfloat\nThe level for the confidence interval of the randomization inference p-value. Defaults to 0.95.\n0.95\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nA pd.Series with the regression coefficient of resampvar and the p-value\n\n\n\nof the RI test. Additionally, reports the standard error and the confidence\n\n\n\ninterval of the p-value.\n\n\n\n\n\n\n\n\nestimation.Feols.se()\nFitted model standard errors.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.Series\nA pd.Series with the standard errors of the estimated regression model.\n\n\n\n\n\n\n\nestimation.Feols.solve_ols(tZX, tZY, solver)\nSolve the ordinary least squares problem using the specified solver.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntZX\nnp.ndarray\n\nrequired\n\n\ntZY\nnp.ndarray\n\nrequired\n\n\nsolver\nstr\n\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\narray-like: The solution to the ordinary least squares problem.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError: If the specified solver is not supported.\n\n\n\n\n\n\n\n\nestimation.Feols.tidy(alpha=None)\nTidy model outputs.\nReturn a tidy pd.DataFrame with the point estimates, standard errors, t-statistics, and p-values.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nalpha\nOptional[float]\nThe significance level for the confidence intervals. If None, computes a 95% confidence interval (alpha = 0.05).\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nA tidy pd.DataFrame containing the regression results, including point estimates, standard errors, t-statistics, and p-values.\n\n\n\n\n\n\n\nestimation.Feols.tstat()\nFitted model t-statistics.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.Series\nA pd.Series with t-statistics of the estimated regression model.\n\n\n\n\n\n\n\nestimation.Feols.update(X_new, y_new, inplace=False)\nUpdate coefficients for new observations using Sherman-Morrison formula.\n\n\n\n\n\nType\nDescription\n\n\n\n\nnp.ndarray\nUpdated coefficients\n\n\n\n\n\n\n\nestimation.Feols.vcov(vcov, data=None)\nCompute covariance matrices for an estimated regression model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvcov\nUnion[str, dict[str, str]]\nA string or dictionary specifying the type of variance-covariance matrix to use for inference. If a string, it can be one of ‚Äúiid‚Äù, ‚Äúhetero‚Äù, ‚ÄúHC1‚Äù, ‚ÄúHC2‚Äù, ‚ÄúHC3‚Äù. If a dictionary, it should have the format {‚ÄúCRV1‚Äù: ‚Äúclustervar‚Äù} for CRV1 inference or {‚ÄúCRV3‚Äù: ‚Äúclustervar‚Äù} for CRV3 inference. Note that CRV3 inference is currently not supported for IV estimation.\nrequired\n\n\ndata\nOptional[DataFrameType]\nThe data used for estimation. If None, tries to fetch the data from the model object. Defaults to None.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nFeols\nAn instance of class [Feols(/reference/Feols.qmd) with updated inference.\n\n\n\n\n\n\n\nestimation.Feols.wald_test(R=None, q=None, distribution='F')\nConduct Wald test.\nCompute a Wald test for a linear hypothesis of the form R * Œ≤ = q. where R is m x k matrix, Œ≤ is a k x 1 vector of coefficients, and q is m x 1 vector. By default, tests the joint null hypothesis that all coefficients are zero.\nThis method producues the following attriutes\n_dfd : int degree of freedom in denominator _dfn : int degree of freedom in numerator _wald_statistic : scalar Wald-statistics computed for hypothesis testing _f_statistic : scalar Wald-statistics(when R is an indentity matrix, and q being zero vector) computed for hypothesis testing _p_value : scalar corresponding p-value for statistics\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nR\narray - like\nThe matrix R of the linear hypothesis. If None, defaults to an identity matrix.\nNone\n\n\nq\narray - like\nThe vector q of the linear hypothesis. If None, defaults to a vector of zeros.\nNone\n\n\ndistribution\nstr\nThe distribution to use for the p-value. Can be either ‚ÄúF‚Äù or ‚Äúchi2‚Äù. Defaults to ‚ÄúF‚Äù.\n'F'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.Series\nA pd.Series with the Wald statistic and p-value.\n\n\n\n\n\n\nimport numpy as np import pandas as pd\nfrom pyfixest.estimation.estimation import feols\ndata = pd.read_csv(‚Äúpyfixest/did/data/df_het.csv‚Äù) data = data.iloc[1:3000]\nR = np.array([[1,-1]] ) q = np.array([0.0])\nfml = ‚Äúdep_var ~ treat‚Äù fit = feols(fml, data, vcov={‚ÄúCRV1‚Äù: ‚Äúyear‚Äù}, ssc=ssc(adj=False))",
    "crumbs": [
      "Documentation",
      "Estimation Classes",
      "estimation.Feols"
    ]
  },
  {
    "objectID": "reference/estimation.Feols.html#parameters",
    "href": "reference/estimation.Feols.html#parameters",
    "title": "estimation.Feols",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nY\nnp.ndarray\nDependent variable, a two-dimensional numpy array.\nrequired\n\n\nX\nnp.ndarray\nIndependent variables, a two-dimensional numpy array.\nrequired\n\n\nweights\nnp.ndarray\nWeights, a one-dimensional numpy array.\nrequired\n\n\ncollin_tol\nfloat\nTolerance level for collinearity checks.\nrequired\n\n\ncoefnames\nlist[str]\nNames of the coefficients (of the design matrix X).\nrequired\n\n\nweights_name\nOptional[str]\nName of the weights variable.\nrequired\n\n\nweights_type\nOptional[str]\nType of the weights variable. Either ‚Äúaweights‚Äù for analytic weights or ‚Äúfweights‚Äù for frequency weights.\nrequired\n\n\nsolver\nstr, optional.\nThe solver to use for the regression. Can be either ‚Äúnp.linalg.solve‚Äù or ‚Äúnp.linalg.lstsq‚Äù. Defaults to ‚Äúnp.linalg.solve‚Äù.\n'np.linalg.solve'",
    "crumbs": [
      "Documentation",
      "Estimation Classes",
      "estimation.Feols"
    ]
  },
  {
    "objectID": "reference/estimation.Feols.html#attributes",
    "href": "reference/estimation.Feols.html#attributes",
    "title": "estimation.Feols",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n_method\nstr\nSpecifies the method used for regression, set to ‚Äúfeols‚Äù.\n\n\n_is_iv\nbool\nIndicates whether instrumental variables are used, initialized as False.\n\n\n_Y\nnp.ndarray\nThe dependent variable array.\n\n\n_X\nnp.ndarray\nThe independent variables array.\n\n\n_X_is_empty\nbool\nIndicates whether the X array is empty.\n\n\n_collin_tol\nfloat\nTolerance level for collinearity checks.\n\n\n_coefnames\nlist\nNames of the coefficients (of the design matrix X).\n\n\n_collin_vars\nlist\nVariables identified as collinear.\n\n\n_collin_index\nlist\nIndices of collinear variables.\n\n\n_Z\nnp.ndarray\nAlias for the _X array, used for calculations.\n\n\n_solver\nstr\nThe solver used for the regression.\n\n\n_weights\nnp.ndarray\nArray of weights for each observation.\n\n\n_N\nint\nNumber of observations.\n\n\n_k\nint\nNumber of independent variables (or features).\n\n\n_support_crv3_inference\nbool\nIndicates support for CRV3 inference.\n\n\n_data\nAny\nData used in the regression, to be enriched outside of the class.\n\n\n_fml\nAny\nFormula used in the regression, to be enriched outside of the class.\n\n\n_has_fixef\nbool\nIndicates whether fixed effects are used.\n\n\n_fixef\nAny\nFixed effects used in the regression.\n\n\n_icovars\nAny\nInternal covariates, to be enriched outside of the class.\n\n\n_ssc_dict\ndict\ndictionary for sum of squares and cross products matrices.\n\n\n_tZX\nnp.ndarray\nTranspose of Z multiplied by X, set in get_fit().\n\n\n_tXZ\nnp.ndarray\nTranspose of X multiplied by Z, set in get_fit().\n\n\n_tZy\nnp.ndarray\nTranspose of Z multiplied by Y, set in get_fit().\n\n\n_tZZinv\nnp.ndarray\nInverse of the transpose of Z multiplied by Z, set in get_fit().\n\n\n_beta_hat\nnp.ndarray\nEstimated regression coefficients.\n\n\n_Y_hat_link\nnp.ndarray\nPredicted values of the dependent variable.\n\n\n_Y_hat_response\nnp.ndarray\nResponse predictions of the model.\n\n\n_u_hat\nnp.ndarray\nResiduals of the regression model.\n\n\n_scores\nnp.ndarray\nScores used in the regression analysis.\n\n\n_hessian\nnp.ndarray\nHessian matrix used in the regression.\n\n\n_bread\nnp.ndarray\nBread matrix, used in calculating the variance-covariance matrix.\n\n\n_vcov_type\nAny\nType of variance-covariance matrix used.\n\n\n_vcov_type_detail\nAny\nDetailed specification of the variance-covariance matrix type.\n\n\n_is_clustered\nbool\nIndicates if clustering is used in the variance-covariance calculation.\n\n\n_clustervar\nAny\nVariable used for clustering in the variance-covariance calculation.\n\n\n_G\nAny\nGroup information used in clustering.\n\n\n_ssc\nAny\nSum of squares and cross products matrix.\n\n\n_vcov\nnp.ndarray\nVariance-covariance matrix of the estimated coefficients.\n\n\n_se\nnp.ndarray\nStandard errors of the estimated coefficients.\n\n\n_tstat\nnp.ndarray\nT-statistics of the estimated coefficients.\n\n\n_pvalue\nnp.ndarray\nP-values associated with the t-statistics.\n\n\n_conf_int\nnp.ndarray\nConfidence intervals for the estimated coefficients.\n\n\n_F_stat\nAny\nF-statistic for the model, set in get_Ftest().\n\n\n_fixef_dict\ndict\ndictionary containing fixed effects estimates.\n\n\n_sumFE\nnp.ndarray\nSum of all fixed effects for each observation.\n\n\n_rmse\nfloat\nRoot mean squared error of the model.\n\n\n_r2\nfloat\nR-squared value of the model.\n\n\n_r2_within\nfloat\nR-squared value computed on demeaned dependent variable.\n\n\n_adj_r2\nfloat\nAdjusted R-squared value of the model.\n\n\n_adj_r2_within\nfloat\nAdjusted R-squared value computed on demeaned dependent variable.\n\n\n_solver\nstr\nThe solver used to fit the normal equation.",
    "crumbs": [
      "Documentation",
      "Estimation Classes",
      "estimation.Feols"
    ]
  },
  {
    "objectID": "reference/estimation.Feols.html#methods",
    "href": "reference/estimation.Feols.html#methods",
    "title": "estimation.Feols",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_fixest_multi_context\nEnrich Feols object.\n\n\nccv\nCompute the Causal Cluster Variance following Abadie et al (QJE 2023).\n\n\ncoef\nFitted model coefficents.\n\n\nconfint\nFitted model confidence intervals.\n\n\nfixef\nCompute the coefficients of (swept out) fixed effects for a regression model.\n\n\nget_fit\nFit an OLS model.\n\n\nget_inference\nCompute standard errors, t-statistics, and p-values for the regression model.\n\n\nget_nobs\nFetch the number of observations used in fitting the regression model.\n\n\nget_performance\nGet Goodness-of-Fit measures.\n\n\nplot_ritest\nPlot the distribution of the Randomization Inference Statistics.\n\n\npredict\nPredict values of the model on new data.\n\n\npvalue\nFitted model p-values.\n\n\nresid\nFitted model residuals.\n\n\nritest\nConduct Randomization Inference (RI) test against a null hypothesis of\n\n\nse\nFitted model standard errors.\n\n\nsolve_ols\nSolve the ordinary least squares problem using the specified solver.\n\n\ntidy\nTidy model outputs.\n\n\ntstat\nFitted model t-statistics.\n\n\nupdate\nUpdate coefficients for new observations using Sherman-Morrison formula.\n\n\nvcov\nCompute covariance matrices for an estimated regression model.\n\n\nwald_test\nConduct Wald test.\n\n\nwildboottest\nRun a wild cluster bootstrap based on an object of type ‚ÄúFeols‚Äù.\n\n\n\n\n\nestimation.Feols.add_fixest_multi_context(fml, depvar, Y, _data, _ssc_dict, _k_fe, fval, store_data)\nEnrich Feols object.\nEnrich an instance of Feols Class with additional attributes set in the FixestMulti class.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfml\nstr\nThe formula used for estimation.\nrequired\n\n\ndepvar\nstr\nThe dependent variable of the regression model.\nrequired\n\n\nY\npd.Series\nThe dependent variable of the regression model.\nrequired\n\n\n_data\npd.DataFrame\nThe data used for estimation.\nrequired\n\n\n_ssc_dict\ndict\nA dictionary with the sum of squares and cross products matrices.\nrequired\n\n\n_k_fe\nint\nThe number of fixed effects.\nrequired\n\n\nfval\nstr\nThe fixed effects formula.\nrequired\n\n\nstore_data\nbool\nIndicates whether to save the data used for estimation in the object\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nestimation.Feols.ccv(treatment, cluster=None, seed=None, n_splits=8, pk=1, qk=1)\nCompute the Causal Cluster Variance following Abadie et al (QJE 2023).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntreatment\n\nThe name of the treatment variable.\nrequired\n\n\ncluster\nstr\nThe name of the cluster variable. None by default. If None, uses the cluster variable from the model fit.\nNone\n\n\nseed\nint\nAn integer to set the random seed. Defaults to None.\nNone\n\n\nn_splits\nint\nThe number of splits to use in the cross-fitting procedure. Defaults to 8.\n8\n\n\npk\nfloat\nThe proportion of sampled clusters. Defaults to 1, which corresponds to all clusters of the population being sampled.\n1\n\n\nqk\nfloat\nThe proportion of sampled observations within each cluster. Defaults to 1, which corresponds to all observations within each cluster being sampled.\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nA DataFrame with inference based on the ‚ÄúCausal Cluster Variance‚Äù and ‚Äúregular‚Äù CRV1 inference.\n\n\n\n\n\n\nfrom pyfixest.estimation import feols\nfrom pyfixest.utils import get_data\n\ndata = get_data()\ndata[\"D1\"] = np.random.choice([0, 1], size=data.shape[0])\n\nfit = feols(\"Y ~ D\", data=data, vcov={\"CRV1\": \"group_id\"})\nfit.ccv(treatment=\"D\", pk=0.05, gk=0.5, n_splits=8, seed=123).head()\n\n\n\n\nestimation.Feols.coef()\nFitted model coefficents.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.Series\nA pd.Series with the estimated coefficients of the regression model.\n\n\n\n\n\n\n\nestimation.Feols.confint(alpha=0.05, keep=None, drop=None, exact_match=False, joint=False, seed=None, reps=10000)\nFitted model confidence intervals.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nalpha\nfloat\nThe significance level for confidence intervals. Defaults to 0.05. keep: str or list of str, optional\n0.05\n\n\njoint\nbool\nWhether to compute simultaneous confidence interval for joint null of parameters selected by keep and drop. Defaults to False. See https://www.causalml-book.org/assets/chapters/CausalML_chap_4.pdf, Remark 4.4.1 for details.\nFalse\n\n\nkeep\nOptional[Union[list, str]]\nThe pattern for retaining coefficient names. You can pass a string (one pattern) or a list (multiple patterns). Default is keeping all coefficients. You should use regular expressions to select coefficients. ‚Äúage‚Äù, # would keep all coefficients containing age r‚Äù^tr‚Äù, # would keep all coefficients starting with tr r‚Äù\\d$‚Äú, # would keep all coefficients ending with number Output will be in the order of the patterns.\nNone\n\n\ndrop\nOptional[Union[list, str]]\nThe pattern for excluding coefficient names. You can pass a string (one pattern) or a list (multiple patterns). Syntax is the same as for keep. Default is keeping all coefficients. Parameter keep and drop can be used simultaneously.\nNone\n\n\nexact_match\nOptional[bool]\nWhether to use exact match for keep and drop. Default is False. If True, the pattern will be matched exactly to the coefficient name instead of using regular expressions.\nFalse\n\n\nreps\nint\nThe number of bootstrap iterations to run for joint confidence intervals. Defaults to 10_000. Only used if joint is True.\n10000\n\n\nseed\nint\nThe seed for the random number generator. Defaults to None. Only used if joint is True.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nA pd.DataFrame with confidence intervals of the estimated regression model for the selected coefficients.\n\n\n\n\n\n\nfrom pyfixest.utils import get_data\nfrom pyfixest.estimation import feols\n\ndata = get_data()\nfit = feols(\"Y ~ C(f1)\", data=data)\nfit.confint(alpha=0.10).head()\nfit.confint(alpha=0.10, joint=True, reps=9999).head()\n\n\n\n\nestimation.Feols.fixef(atol=1e-06, btol=1e-06)\nCompute the coefficients of (swept out) fixed effects for a regression model.\nThis method creates the following attributes: - alphaDF (pd.DataFrame): A DataFrame with the estimated fixed effects. - sumFE (np.array): An array with the sum of fixed effects for each observation (i = 1, ‚Ä¶, N).\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nestimation.Feols.get_fit()\nFit an OLS model.\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nestimation.Feols.get_inference(alpha=0.05)\nCompute standard errors, t-statistics, and p-values for the regression model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nalpha\nfloat\nThe significance level for confidence intervals. Defaults to 0.05, which produces a 95% confidence interval.\n0.05\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nestimation.Feols.get_nobs()\nFetch the number of observations used in fitting the regression model.\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nestimation.Feols.get_performance()\nGet Goodness-of-Fit measures.\nCompute multiple additional measures commonly reported with linear regression output, including R-squared and adjusted R-squared. Note that variables with the suffix _within use demeaned dependent variables Y, while variables without do not or are invariant to demeaning.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\nCreates the following instances:\n\n\n\n- r2 (float): R-squared of the regression model.\n\n\n\n- adj_r2 (float): Adjusted R-squared of the regression model.\n\n\n\n- r2_within (float): R-squared of the regression model, computed on\n\n\n\ndemeaned dependent variable.\n\n\n\n- adj_r2_within (float): Adjusted R-squared of the regression model,\n\n\n\ncomputed on demeaned dependent variable.\n\n\n\n\n\n\n\n\nestimation.Feols.plot_ritest(plot_backend='lets_plot')\nPlot the distribution of the Randomization Inference Statistics.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nplot_backend\nstr\nThe plotting backend to use. Defaults to ‚Äúlets_plot‚Äù. Alternatively, ‚Äúmatplotlib‚Äù is available.\n'lets_plot'\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nA lets_plot or matplotlib figure with the distribution of the Randomization\n\n\n\nInference Statistics.\n\n\n\n\n\n\n\n\nestimation.Feols.predict(newdata=None, atol=1e-06, btol=1e-06, type='link')\nPredict values of the model on new data.\nReturn a flat np.array with predicted values of the regression model. If new fixed effect levels are introduced in newdata, predicted values for such observations will be set to NaN.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nnewdata\nOptional[DataFrameType]\nA pd.DataFrame or pl.DataFrame with the data to be used for prediction. If None (default), the data used for fitting the model is used.\nNone\n\n\ntype\nstr\nThe type of prediction to be computed. Can be either ‚Äúresponse‚Äù (default) or ‚Äúlink‚Äù. For linear models, both are identical.\n'link'\n\n\natol\nFloat\nStopping tolerance for scipy.sparse.linalg.lsqr(). See https://docs.scipy.org/doc/ scipy/reference/generated/scipy.sparse.linalg.lsqr.html\n1e-6\n\n\nbtol\nFloat\nAnother stopping tolerance for scipy.sparse.linalg.lsqr(). See https://docs.scipy.org/doc/ scipy/reference/generated/scipy.sparse.linalg.lsqr.html\n1e-6\n\n\nlink\n\nThe type of prediction to be made. Can be either ‚Äòlink‚Äô or ‚Äòresponse‚Äô. Defaults to ‚Äòlink‚Äô. ‚Äòlink‚Äô and ‚Äòresponse‚Äô lead to identical results for linear models.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnp.ndarray\nA flat np.array with predicted values of the regression model.\n\n\n\n\n\n\n\nestimation.Feols.pvalue()\nFitted model p-values.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.Series\nA pd.Series with p-values of the estimated regression model.\n\n\n\n\n\n\n\nestimation.Feols.resid()\nFitted model residuals.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnp.ndarray\nA np.ndarray with the residuals of the estimated regression model.\n\n\n\n\n\n\n\nestimation.Feols.ritest(resampvar, cluster=None, reps=100, type='randomization-c', rng=None, choose_algorithm='auto', store_ritest_statistics=False, level=0.95)\nConduct Randomization Inference (RI) test against a null hypothesis of resampvar = 0.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nresampvar\nstr\nThe name of the variable to be resampled.\nrequired\n\n\ncluster\nstr\nThe name of the cluster variable in case of cluster random assignment. If provided, resampvar is held constant within each cluster. Defaults to None.\nNone\n\n\nreps\nint\nThe number of randomization iterations. Defaults to 100.\n100\n\n\ntype\nstr\nThe type of the randomization inference test. Can be ‚Äúrandomization-c‚Äù or ‚Äúrandomization-t‚Äù. Note that the ‚Äúrandomization-c‚Äù is much faster, while the ‚Äúrandomization-t‚Äù is recommended by Wu & Ding (JASA, 2021).\n'randomization-c'\n\n\nrng\nnp.random.Generator\nA random number generator. Defaults to None.\nNone\n\n\nchoose_algorithm\nstr\nThe algorithm to use for the computation. Defaults to ‚Äúauto‚Äù. The alternative is ‚Äúfast‚Äù and ‚Äúslow‚Äù, and should only be used for running CI tests. Ironically, this argument is not tested for any input errors from the user! So please don‚Äôt use it =)\n'auto'\n\n\ninclude_plot\n\nWhether to include a plot of the distribution p-values. Defaults to False.\nrequired\n\n\nstore_ritest_statistics\nbool\nWhether to store the simulated statistics of the RI procedure. Defaults to False. If True, stores the simulated statistics in the model object via the ritest_statistics attribute as a numpy array.\nFalse\n\n\nlevel\nfloat\nThe level for the confidence interval of the randomization inference p-value. Defaults to 0.95.\n0.95\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nA pd.Series with the regression coefficient of resampvar and the p-value\n\n\n\nof the RI test. Additionally, reports the standard error and the confidence\n\n\n\ninterval of the p-value.\n\n\n\n\n\n\n\n\nestimation.Feols.se()\nFitted model standard errors.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.Series\nA pd.Series with the standard errors of the estimated regression model.\n\n\n\n\n\n\n\nestimation.Feols.solve_ols(tZX, tZY, solver)\nSolve the ordinary least squares problem using the specified solver.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntZX\nnp.ndarray\n\nrequired\n\n\ntZY\nnp.ndarray\n\nrequired\n\n\nsolver\nstr\n\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\narray-like: The solution to the ordinary least squares problem.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError: If the specified solver is not supported.\n\n\n\n\n\n\n\n\nestimation.Feols.tidy(alpha=None)\nTidy model outputs.\nReturn a tidy pd.DataFrame with the point estimates, standard errors, t-statistics, and p-values.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nalpha\nOptional[float]\nThe significance level for the confidence intervals. If None, computes a 95% confidence interval (alpha = 0.05).\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nA tidy pd.DataFrame containing the regression results, including point estimates, standard errors, t-statistics, and p-values.\n\n\n\n\n\n\n\nestimation.Feols.tstat()\nFitted model t-statistics.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.Series\nA pd.Series with t-statistics of the estimated regression model.\n\n\n\n\n\n\n\nestimation.Feols.update(X_new, y_new, inplace=False)\nUpdate coefficients for new observations using Sherman-Morrison formula.\n\n\n\n\n\nType\nDescription\n\n\n\n\nnp.ndarray\nUpdated coefficients\n\n\n\n\n\n\n\nestimation.Feols.vcov(vcov, data=None)\nCompute covariance matrices for an estimated regression model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvcov\nUnion[str, dict[str, str]]\nA string or dictionary specifying the type of variance-covariance matrix to use for inference. If a string, it can be one of ‚Äúiid‚Äù, ‚Äúhetero‚Äù, ‚ÄúHC1‚Äù, ‚ÄúHC2‚Äù, ‚ÄúHC3‚Äù. If a dictionary, it should have the format {‚ÄúCRV1‚Äù: ‚Äúclustervar‚Äù} for CRV1 inference or {‚ÄúCRV3‚Äù: ‚Äúclustervar‚Äù} for CRV3 inference. Note that CRV3 inference is currently not supported for IV estimation.\nrequired\n\n\ndata\nOptional[DataFrameType]\nThe data used for estimation. If None, tries to fetch the data from the model object. Defaults to None.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nFeols\nAn instance of class [Feols(/reference/Feols.qmd) with updated inference.\n\n\n\n\n\n\n\nestimation.Feols.wald_test(R=None, q=None, distribution='F')\nConduct Wald test.\nCompute a Wald test for a linear hypothesis of the form R * Œ≤ = q. where R is m x k matrix, Œ≤ is a k x 1 vector of coefficients, and q is m x 1 vector. By default, tests the joint null hypothesis that all coefficients are zero.\nThis method producues the following attriutes\n_dfd : int degree of freedom in denominator _dfn : int degree of freedom in numerator _wald_statistic : scalar Wald-statistics computed for hypothesis testing _f_statistic : scalar Wald-statistics(when R is an indentity matrix, and q being zero vector) computed for hypothesis testing _p_value : scalar corresponding p-value for statistics\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nR\narray - like\nThe matrix R of the linear hypothesis. If None, defaults to an identity matrix.\nNone\n\n\nq\narray - like\nThe vector q of the linear hypothesis. If None, defaults to a vector of zeros.\nNone\n\n\ndistribution\nstr\nThe distribution to use for the p-value. Can be either ‚ÄúF‚Äù or ‚Äúchi2‚Äù. Defaults to ‚ÄúF‚Äù.\n'F'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.Series\nA pd.Series with the Wald statistic and p-value.\n\n\n\n\n\n\nimport numpy as np import pandas as pd\nfrom pyfixest.estimation.estimation import feols\ndata = pd.read_csv(‚Äúpyfixest/did/data/df_het.csv‚Äù) data = data.iloc[1:3000]\nR = np.array([[1,-1]] ) q = np.array([0.0])\nfml = ‚Äúdep_var ~ treat‚Äù fit = feols(fml, data, vcov={‚ÄúCRV1‚Äù: ‚Äúyear‚Äù}, ssc=ssc(adj=False))",
    "crumbs": [
      "Documentation",
      "Estimation Classes",
      "estimation.Feols"
    ]
  },
  {
    "objectID": "news.html",
    "href": "news.html",
    "title": "News",
    "section": "",
    "text": "Fix bug in wildboottest method @s3alfisc (#506)\ndocs: add sanskriti2005 as a contributor for infra @allcontributors (#503)\nInfra: added the release-drafter for automation of release notes @sanskriti2005 (#502)\nFix broken link in contributing.md @s3alfisc (#499)\ndocs: add leostimpfle as a contributor for bug @allcontributors (#495)\nUpdate justfile @leostimpfle (#494)\ndocs: add baggiponte as a contributor for doc @allcontributors (#490)\ndocs: improve installation section @baggiponte (#489)\nBump tornado from 6.4 to 6.4.1 @dependabot (#487)\ndocs: add leostimpfle as a contributor for code @allcontributors (#478)\nFeols: speed up the creation of interacted fixed effects via fe1^fe2 syntax @leostimpfle (#475)\nrename resampling iterations to ‚Äòreps‚Äô in all methods @s3alfisc (#474)\nfix a lot of broken links throught the repo @s3alfisc (#472)\nMultiple readme fixes required after package was moved to py-econometrics project @s3alfisc (#450)\n\n\n\n\n\ninfrastructure: fix minor release drafter bugs @s3alfisc (#504)"
  },
  {
    "objectID": "news.html#pyfixest-0.22.0",
    "href": "news.html#pyfixest-0.22.0",
    "title": "News",
    "section": "",
    "text": "Fix bug in wildboottest method @s3alfisc (#506)\ndocs: add sanskriti2005 as a contributor for infra @allcontributors (#503)\nInfra: added the release-drafter for automation of release notes @sanskriti2005 (#502)\nFix broken link in contributing.md @s3alfisc (#499)\ndocs: add leostimpfle as a contributor for bug @allcontributors (#495)\nUpdate justfile @leostimpfle (#494)\ndocs: add baggiponte as a contributor for doc @allcontributors (#490)\ndocs: improve installation section @baggiponte (#489)\nBump tornado from 6.4 to 6.4.1 @dependabot (#487)\ndocs: add leostimpfle as a contributor for code @allcontributors (#478)\nFeols: speed up the creation of interacted fixed effects via fe1^fe2 syntax @leostimpfle (#475)\nrename resampling iterations to ‚Äòreps‚Äô in all methods @s3alfisc (#474)\nfix a lot of broken links throught the repo @s3alfisc (#472)\nMultiple readme fixes required after package was moved to py-econometrics project @s3alfisc (#450)\n\n\n\n\n\ninfrastructure: fix minor release drafter bugs @s3alfisc (#504)"
  },
  {
    "objectID": "news.html#pyfixest-0.21.0",
    "href": "news.html#pyfixest-0.21.0",
    "title": "News",
    "section": "PyFixest 0.21.0",
    "text": "PyFixest 0.21.0\n\nAdd support for randomization inference via the ritest() method:\n\n\nimport pyfixest as pf\ndata = pf.get_data()\n\nfit = pf.feols(\"Y ~ X1\", data = data)\nfit.ritest(resampvar=\"X1=0\", reps = 1000)"
  },
  {
    "objectID": "news.html#pyfixest-0.20.0",
    "href": "news.html#pyfixest-0.20.0",
    "title": "News",
    "section": "PyFixest 0.20.0",
    "text": "PyFixest 0.20.0\n\nThis version introduces MyPy type checks to the entire pyfixest codebase. Thanks to @juanitorduz for nudging me to get started with this =). It also fixes a handful of smaller bugs."
  },
  {
    "objectID": "news.html#pyfixest-0.19.0",
    "href": "news.html#pyfixest-0.19.0",
    "title": "News",
    "section": "PyFixest 0.19.0",
    "text": "PyFixest 0.19.0\n\nFixes multiple smaller and larger performance regressions. The NYC-Taxi example regression now takes approximately 22 seconds to run (‚Ä¶ if my laptopt is connected to a power charger)!\n\n\n%load_ext autoreload\n%autoreload 2\n\nimport duckdb\nimport time\nimport numpy as np\nimport pyfixest as pf\n\n# %%\nnyc = duckdb.sql(\n    '''\n    FROM 'C:/Users/alexa/Documents/nyc-taxi/**/*.parquet'\n    SELECT\n        tip_amount, trip_distance, passenger_count,\n        vendor_id, payment_type, dropoff_at,\n        dayofweek(dropoff_at) AS dofw\n    WHERE year = 2012 AND month &lt;= 3\n    '''\n    ).df()\n\n# convert dowf, vendor_id, payment_type to categorical\ntic = time.time()\nnyc[\"dofw\"] = nyc[\"dofw\"].astype(int)\nnyc[\"vendor_id\"] = nyc[\"vendor_id\"].astype(\"category\")\nnyc[\"payment_type\"] = nyc[\"payment_type\"].astype(\"category\")\nprint(f\"\"\"\n    I am convering columns of type 'objects' to 'categories' and 'int'data types outside\n    of the regression, hence I am cheating a bit. This saves {np.round(time.time() - tic)} seconds.\n    \"\"\"\n)\n#    I am convering columns of type 'objects' to 'categories' and 'int'data types outside\n#    of the regression, hence I am cheating a bit. This saves 7.0 seconds.\n\nrun = True\nif run:\n\n    # mock regression for JIT compilation\n    fit = pf.feols(\n        fml = \"tip_amount ~ trip_distance + passenger_count | vendor_id + payment_type + dofw\",\n        data = nyc.iloc[1:10_000],\n        copy_data = False,\n        store_data = False\n        )\n\n    import time\n    tic = time.time()\n    fit = pf.feols(\n        fml = \"tip_amount ~ trip_distance + passenger_count | vendor_id + payment_type + dofw\",\n        data = nyc,\n        copy_data = False, # saves a few seconds\n        store_data = False # saves a few second\n        )\n    passed = time.time() - tic\n    print(f\"Passed time is {np.round(passed)}.\")\n    # Passed time is 22.\n\n\nAdds three new function arguments to feols() and fepois(): copy_data, store_data, and fixef_tol.\nAdds support for frequency weights with the weights_type function argument.\n\n\nimport pyfixest as pf\n\ndata = pf.get_data(N = 10000, model = \"Fepois\")\ndf_weighted = data[[\"Y\", \"X1\", \"f1\"]].groupby([\"Y\", \"X1\", \"f1\"]).size().reset_index().rename(columns={0: \"count\"})\ndf_weighted[\"id\"] = list(range(df_weighted.shape[0]))\n\nprint(\"Dimension of the aggregated df:\", df_weighted.shape)\nprint(df_weighted.head())\n\nfit = pf.feols(\n    \"Y ~ X1 | f1\",\n    data = data\n)\nfit_weighted = pf.feols(\n    \"Y ~ X1 | f1\",\n    data = df_weighted,\n    weights = \"count\",\n    weights_type = \"fweights\"\n)\npf.etable([fit, fit_weighted], coef_fmt = \"b(se) \\n (t) \\n (p)\")\n\n\n            \n            \n            \n\n\n\n            \n            \n            \n\n\nDimension of the aggregated df: (1278, 5)\n     Y   X1   f1  count  id\n0  0.0  0.0  0.0     17   0\n1  0.0  0.0  1.0     11   1\n2  0.0  0.0  2.0     10   2\n3  0.0  0.0  3.0     17   3\n4  0.0  0.0  4.0     14   4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nY\n\n\n(1)\n(2)\n\n\n\n\ncoef\n\n\nX1\n0.001(0.012)\n(0.092)\n(0.927)\n0.001(0.012)\n(0.092)\n(0.927)\n\n\nfe\n\n\nf1\nx\nx\n\n\nmodelstats\n\n\nObservations\n9997\n9997\n\n\nS.E. type\nby: f1\nby: f1\n\n\nR2\n0.011\n-\n\n\n\nSignificance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell: Coefficient(Std. Error) (t-stats) (p-value)\n\n\n\n\n\n\n\n        \n\n\n\nBugfix: Wild Cluster Bootstrap Inference with Weights would compute unweighted standard errors. Sorry about that! WLS is not supported for the WCB.\nAdds support for CRV3 inference with weights."
  },
  {
    "objectID": "news.html#pyfixest-0.18.0",
    "href": "news.html#pyfixest-0.18.0",
    "title": "News",
    "section": "PyFixest 0.18.0",
    "text": "PyFixest 0.18.0\n\nLarge Refactoring of Interal Processing of Model Formulas, in particular FixestFormulaParser and model_matrix_fixest. As a results, the code should be cleaner and more robust.\nThanks to the refactoring, we can now bump the required formulaic version to the stable 1.0.0 release.\nThe fml argument of model_matrix_fixest is deprecated. Instead, model_matrix_fixest now asks for a FixestFormula, which is essentially a dictionary with information on model specifications like a first stage formula (if applicable), dependent variables, fixed effects, etc.\nAdditionally, model_matrix_fixest now returns a dictionary instead of a tuple.\nBrings back fixed effects reference setting via i(var1, var2, ref) syntax. Deprecates the i_ref1, i_ref2 function arguments. I.e. it is again possible to e.g.¬†run\n\n\nimport pyfixest as pf\ndata = pf.get_data()\n\nfit1 = pf.feols(\"Y ~ i(f1, X2)\", data=data)\nfit1.coef()[0:8]\n\nVia the ref syntax, via can set the reference level:\n\nfit2 = pf.feols(\"Y ~ i(f1, X2, ref = 1)\", data=data)\nfit2.coef()[0:8]"
  },
  {
    "objectID": "news.html#pyfixest-0.17.0",
    "href": "news.html#pyfixest-0.17.0",
    "title": "News",
    "section": "PyFixest 0.17.0",
    "text": "PyFixest 0.17.0\n\nRestructures the codebase and reorganizes how users can interact with the pyfixest API. It is now recommended to use pyfixest in the following way:\n\nimport numpy as np\nimport pyfixest as pf\ndata = pf.get_data()\ndata[\"D\"] = data[\"X1\"] &gt; 0\nfit = pf.feols(\"Y ~ D + f1\", data = data)\nfit.tidy()\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n2.5%\n97.5%\n\n\nCoefficient\n\n\n\n\n\n\n\n\n\n\nIntercept\n0.778849\n0.170261\n4.574437\n0.000005\n0.444737\n1.112961\n\n\nD\n-1.402617\n0.152224\n-9.214140\n0.000000\n-1.701335\n-1.103899\n\n\nf1\n0.004774\n0.008058\n0.592508\n0.553645\n-0.011038\n0.020587\n\n\n\n\n\n\n\nThe update should not inroduce any breaking changes. Thanks to @Wenzhi-Ding for the PR!\nAdds support for simultaneous confidence intervals via a multiplier bootstrap. Thanks to @apoorvalal for the contribution!\n\nfit.confint(joint = True)\n\n\n\n\n\n\n\n\n2.5%\n97.5%\n\n\n\n\nIntercept\n0.381471\n1.176227\n\n\nD\n-1.757898\n-1.047335\n\n\nf1\n-0.014032\n0.023581\n\n\n\n\n\n\n\nAdds support for the causal cluster variance estimator by Abadie et al.¬†(QJE, 2023) for OLS via the .ccv() method.\n\nfit.ccv(treatment = \"D\", cluster = \"group_id\")\n\n/home/runner/work/pyfixest/pyfixest/pyfixest/estimation/feols_.py:1250: UserWarning:\n\nThe initial model was not clustered. CRV1 inference is computed and stored in the model object.\n\n\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n2.5%\n97.5%\n\n\n\n\nCCV\n-1.4026168622179929\n0.263301\n-5.327041\n0.000046\n-1.955792\n-0.849441\n\n\nCRV1\n-1.402617\n0.205132\n-6.837621\n0.000002\n-1.833584\n-0.97165"
  },
  {
    "objectID": "news.html#pyfixest-0.16.0",
    "href": "news.html#pyfixest-0.16.0",
    "title": "News",
    "section": "PyFixest 0.16.0",
    "text": "PyFixest 0.16.0\n\nAdds multiple quality of life improvements for developers, thanks to NKeleher.\nAdds more options to customize etable() output thanks to Wenzhi-Ding.\nImplements Romano-Wolf and Bonferroni corrections for multiple testing in the multcomp module."
  },
  {
    "objectID": "news.html#pyfixest-0.15.",
    "href": "news.html#pyfixest-0.15.",
    "title": "News",
    "section": "PyFixest 0.15.",
    "text": "PyFixest 0.15.\n\nAdds support for weighted least squares for feols().\nReduces testing time drastically by running tests on fewer random data samples. Qualitatively, the set of test remains identical.\nSome updates for future pandas compatibility."
  },
  {
    "objectID": "news.html#pyfixest-0.14.0",
    "href": "news.html#pyfixest-0.14.0",
    "title": "News",
    "section": "PyFixest 0.14.0",
    "text": "PyFixest 0.14.0\n\nMoves the documentation to quartodoc.\nChanges all docstrings to numpy format.\nDifference-in-differences estimation functions now need to be imported via the pyfixest.did.estimation module:\n\n\nfrom pyfixest.did.estimation import did2s, lpdid, event_study"
  },
  {
    "objectID": "news.html#pyfixest-0.13.5",
    "href": "news.html#pyfixest-0.13.5",
    "title": "News",
    "section": "PyFixest 0.13.5",
    "text": "PyFixest 0.13.5\n\nFixes a bug that lead to incorrect results when the dependent variable and all covariates (excluding the fixed effects) where integers."
  },
  {
    "objectID": "news.html#pyfixest-0.13.4",
    "href": "news.html#pyfixest-0.13.4",
    "title": "News",
    "section": "PyFixest 0.13.4",
    "text": "PyFixest 0.13.4\n\nFixes a bug in etable() with IV‚Äôs that occurred because feols() does not report R2 statistics for IVs."
  },
  {
    "objectID": "news.html#pyfixest-0.13.2",
    "href": "news.html#pyfixest-0.13.2",
    "title": "News",
    "section": "PyFixest 0.13.2",
    "text": "PyFixest 0.13.2\n\nFixes a bug in etable() and a warning in fixest_model_matrix that arose with higher pandas versions. Thanks to @aeturrell for reporting!"
  },
  {
    "objectID": "news.html#pyfixest-0.13.0",
    "href": "news.html#pyfixest-0.13.0",
    "title": "News",
    "section": "PyFixest 0.13.0",
    "text": "PyFixest 0.13.0\n\nNew Features\n\nIntroduces a new pyfixest.did module which contains routines for Difference-in-Differences estimation.\nIntroduces support for basic versions of the local projections DiD estimator following Dube et al (2023)\nAdds a new vignette for Difference-in-Differences estimation.\nReports R2 values in etable()."
  },
  {
    "objectID": "news.html#pyfixest-0.12.0",
    "href": "news.html#pyfixest-0.12.0",
    "title": "News",
    "section": "PyFixest 0.12.0",
    "text": "PyFixest 0.12.0\n\nEnhancements:\n\nGood performance improvements for singleton fixed effects detection. Thanks to @styfenschaer for the PR! See #229.\nUses the r2u project for installing R and R packages on github actions, with great performance improvements.\nAllows to pass polars data frames to feols(), fepois() and predict(). #232. Thanks to @vincentarelbundock for the suggestion!\n\n\n\nBug Fixes:\n\nMissing variables in features were not always handled correctly in predict() with newdata not None in the presence of missing data, which would lead to an error. See #246 for details.\nCategorical variables were not always handled correctly in predict() with newdata not None, because the number of fixed effects levels in newdata might be smaller than in data. In consequence, some levels were not found, which lead to an error. See #245 for details. Thanks to @jiafengkevinchen for the pointer!\nMulticollinearity checks for over-identified IV was not implemented correctly, which lead to a dimension error. See #236 for details. Thanks to @jiafengkevinchen for the pointer!\nThe number of degrees of freedom k was computed incorrectly if columns were dropped from the design matrix X in the presence of multicollinearity. See #235 for details. Thanks to @jiafengkevinchen for the pointer!\nIf all variables were dropped due to multicollinearity, an unclear and imprecise error message was produced. See #228 for details. Thanks to @manferdinig for the pointer!\nIf selection fixef_rm = 'singleton', feols() and fepois() would fail, which has been fixed. #192\n\n\n\nDependency Requirements\n\nFor now, sets formulaic versions to be 0.6.6 or lower as version 1.0.0 seems to have introduced a problem with the i() operator, See #244 for details.\nDrops dependency on pyhdfe."
  },
  {
    "objectID": "news.html#pyfixest-0.11.1",
    "href": "news.html#pyfixest-0.11.1",
    "title": "News",
    "section": "PyFixest 0.11.1",
    "text": "PyFixest 0.11.1\n\nFixes some bugs around the computation of R-squared values (see issue #103).\nReports R-squared values again when calling .summary()."
  },
  {
    "objectID": "news.html#pyfixest-0.11.0",
    "href": "news.html#pyfixest-0.11.0",
    "title": "News",
    "section": "PyFixest 0.11.0",
    "text": "PyFixest 0.11.0\n\nSignificant speedups for CRV1 inference."
  },
  {
    "objectID": "news.html#pyfixest-0.10.12",
    "href": "news.html#pyfixest-0.10.12",
    "title": "News",
    "section": "PyFixest 0.10.12",
    "text": "PyFixest 0.10.12\nFixes a small bug with the separation check for poisson regression #138."
  },
  {
    "objectID": "news.html#pyfixest-0.10.11",
    "href": "news.html#pyfixest-0.10.11",
    "title": "News",
    "section": "PyFixest 0.10.11",
    "text": "PyFixest 0.10.11\nFixes bugs with i(var1, var2) syntax introduced with PyFixest 0.10.10."
  },
  {
    "objectID": "news.html#pyfixest-0.10.10",
    "href": "news.html#pyfixest-0.10.10",
    "title": "News",
    "section": "PyFixest 0.10.10",
    "text": "PyFixest 0.10.10\nFixes a bug with variable interactions via i(var) syntax. See issue #221."
  },
  {
    "objectID": "news.html#pyfixest-0.10.9",
    "href": "news.html#pyfixest-0.10.9",
    "title": "News",
    "section": "PyFixest 0.10.9",
    "text": "PyFixest 0.10.9\nMakes etable() prettier and more informative."
  },
  {
    "objectID": "news.html#pyfixest-0.10.8",
    "href": "news.html#pyfixest-0.10.8",
    "title": "News",
    "section": "PyFixest 0.10.8",
    "text": "PyFixest 0.10.8\n\nBreaking changes\nReference levels for the i() formula syntax can no longer be set within the formula, but need to be added via the i_ref1 function argument to either feols() and fepois().\n\n\nNew feature\nA dids2() function is added, which implements the 2-stage difference-in-differences procedure √† la Gardner and follows the syntax of @kylebutts did2s R package.\nfrom pyfixest.did.did import did2s\nfrom pyfixest.estimation import feols\nfrom pyfixest.visualize import iplot\nimport pandas as pd\nimport numpy as np\n\ndf_het = pd.read_csv(\"https://raw.githubusercontent.com/py-econometrics/pyfixest/master/pyfixest/did/data/df_het.csv\")\n\nfit = did2s(\n    df_het,\n    yname = \"dep_var\",\n    first_stage = \"~ 0 | state + year\",\n    second_stage = \"~i(rel_year)\",\n    treatment = \"treat\",\n    cluster = \"state\",\n    i_ref1 = [-1.0, np.inf],\n)\n\nfit_twfe = feols(\n    \"dep_var ~ i(rel_year) | state + year\",\n    df_het,\n    i_ref1 = [-1.0, np.inf]\n)\n\niplot([fit, fit_twfe], coord_flip=False, figsize = (900, 400), title = \"TWFE vs DID2S\")"
  },
  {
    "objectID": "news.html#pyfixest-0.10.7",
    "href": "news.html#pyfixest-0.10.7",
    "title": "News",
    "section": "PyFixest 0.10.7",
    "text": "PyFixest 0.10.7\n\nAdds basic support for event study estimation via two-way fixed effects and Gardner‚Äôs two-stage ‚ÄúDid2s‚Äù approach. This is a beta version and experimental. Further updates (i.e.¬†proper event studies vs ‚Äúonly‚Äù ATTs) and a more flexible did2s front end will follow in future releases.\n\n%load_ext autoreload\n%autoreload 2\n\nfrom pyfixest.did.did import event_study\nimport pyfixest as pf\nimport pandas as pd\ndf_het = pd.read_csv(\"pyfixest/did/data/df_het.csv\")\n\nfit_twfe = event_study(\n    data = df_het,\n    yname = \"dep_var\",\n    idname= \"state\",\n    tname = \"year\",\n    gname = \"g\",\n    estimator = \"twfe\"\n)\n\nfit_did2s = event_study(\n    data = df_het,\n    yname = \"dep_var\",\n    idname= \"state\",\n    tname = \"year\",\n    gname = \"g\",\n    estimator = \"did2s\"\n)\n\npf.etable([fit_twfe, fit_did2s])\n# | Coefficient   | est1             | est2             |\n# |:--------------|:-----------------|:-----------------|\n# | ATT           | 2.135*** (0.044) | 2.152*** (0.048) |\n# Significance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001"
  },
  {
    "objectID": "news.html#pyfixest-0.10.6",
    "href": "news.html#pyfixest-0.10.6",
    "title": "News",
    "section": "PyFixest 0.10.6",
    "text": "PyFixest 0.10.6\n\nAdds an etable() function that outputs markdown, latex or a pd.DataFrame."
  },
  {
    "objectID": "news.html#pyfixest-0.10.5",
    "href": "news.html#pyfixest-0.10.5",
    "title": "News",
    "section": "PyFixest 0.10.5",
    "text": "PyFixest 0.10.5\n\nFixes a big in IV estimation that would trigger an error. See here for details. Thanks to @aeturrell for reporting!"
  },
  {
    "objectID": "news.html#pyfixest-0.10.4",
    "href": "news.html#pyfixest-0.10.4",
    "title": "News",
    "section": "PyFixest 0.10.4",
    "text": "PyFixest 0.10.4\n\nImplements a custom function to drop singleton fixed effects.\nAdditional small performance improvements."
  },
  {
    "objectID": "news.html#pyfixest-0.10.3",
    "href": "news.html#pyfixest-0.10.3",
    "title": "News",
    "section": "PyFixest 0.10.3",
    "text": "PyFixest 0.10.3\n\nAllows for white space in the multiway clustering formula.\nAdds documentation for multiway clustering."
  },
  {
    "objectID": "news.html#pyfixest-0.10.2",
    "href": "news.html#pyfixest-0.10.2",
    "title": "News",
    "section": "PyFixest 0.10.2",
    "text": "PyFixest 0.10.2\n\nAdds support for two-way clustering.\nAdds support for CRV3 inference for Poisson regression."
  },
  {
    "objectID": "news.html#pyfixest-0.10.1",
    "href": "news.html#pyfixest-0.10.1",
    "title": "News",
    "section": "PyFixest 0.10.1",
    "text": "PyFixest 0.10.1\n\nAdapts the internal fixed effects demeaning criteron to match `PyHDFE‚Äôs default.\nAdds Styfen as coauthor."
  },
  {
    "objectID": "news.html#pyfixest-0.10",
    "href": "news.html#pyfixest-0.10",
    "title": "News",
    "section": "PyFixest 0.10",
    "text": "PyFixest 0.10\n\nMultiple performance improvements.\nMost importantly, implements a custom demeaning algorithm in numba - thanks to Styfen Schaer (@styfenschaer), which leads to performance improvements of 5x or more:\n\n%load_ext autoreload\n%autoreload 2\n\nimport numpy as np\nimport time\nimport pyhdfe\nfrom pyfixest.demean import demean\n\nnp.random.seed(1238)\nN = 10_000_000\nx = np.random.normal(0, 1, 10*N).reshape((N,10))\nf1 = np.random.choice(list(range(1000)), N).reshape((N,1))\nf2 = np.random.choice(list(range(1000)), N).reshape((N,1))\n\nflist = np.concatenate((f1, f2), axis = 1)\nweights = np.ones(N)\n\nalgorithm = pyhdfe.create(flist)\n\nstart_time = time.time()\nres_pyhdfe = algorithm.residualize(x)\nend_time = time.time()\nprint(end_time - start_time)\n# 26.04527711868286\n\n\nstart_time = time.time()\nres_pyfixest, success = demean(x, flist, weights, tol = 1e-10)\n# Calculate the execution time\nend_time = time.time()\nprint(end_time - start_time)\n#4.334428071975708\n\nnp.allclose(res_pyhdfe , res_pyfixest)\n# True"
  },
  {
    "objectID": "news.html#pyfixest-0.9.11",
    "href": "news.html#pyfixest-0.9.11",
    "title": "News",
    "section": "PyFixest 0.9.11",
    "text": "PyFixest 0.9.11\n\nBump required formulaic version to 0.6.5.\nStop copying the data frame in fixef()."
  },
  {
    "objectID": "news.html#pyfixest-0.9.10",
    "href": "news.html#pyfixest-0.9.10",
    "title": "News",
    "section": "PyFixest 0.9.10",
    "text": "PyFixest 0.9.10\n\nFixes a big in the wildboottest method (see #158).\nAllows to run a wild bootstrap after fixed effect estimation."
  },
  {
    "objectID": "news.html#pyfixest-0.9.9",
    "href": "news.html#pyfixest-0.9.9",
    "title": "News",
    "section": "PyFixest 0.9.9",
    "text": "PyFixest 0.9.9\n\nAdds support for wildboottest for Python 3.11."
  },
  {
    "objectID": "news.html#pyfixest-0.9.8",
    "href": "news.html#pyfixest-0.9.8",
    "title": "News",
    "section": "PyFixest 0.9.8",
    "text": "PyFixest 0.9.8\n\nFixes a couple more bugs in the predict() and fixef() methods.\nThe predict() argument data is renamed to newdata."
  },
  {
    "objectID": "news.html#pyfixest-0.9.7",
    "href": "news.html#pyfixest-0.9.7",
    "title": "News",
    "section": "PyFixest 0.9.7",
    "text": "PyFixest 0.9.7\nFixes a bug in predict() produced when multicollinear variables are dropped."
  },
  {
    "objectID": "news.html#pyfixest-0.9.6",
    "href": "news.html#pyfixest-0.9.6",
    "title": "News",
    "section": "PyFixest 0.9.6",
    "text": "PyFixest 0.9.6\nImproved Collinearity handling. See #145"
  },
  {
    "objectID": "news.html#pyfixest-0.9.5",
    "href": "news.html#pyfixest-0.9.5",
    "title": "News",
    "section": "PyFixest 0.9.5",
    "text": "PyFixest 0.9.5\n\nMoves plotting from matplotlib to lets-plot.\nFixes a few minor bugs in plotting and the fixef() method."
  },
  {
    "objectID": "news.html#pyfixest-0.9.1",
    "href": "news.html#pyfixest-0.9.1",
    "title": "News",
    "section": "PyFixest 0.9.1",
    "text": "PyFixest 0.9.1\n\nBreaking API changes\nIt is no longer required to initiate an object of type Fixest prior to running [Feols(/reference/Feols.qmd) or fepois. Instead, you can now simply use feols() and fepois() as functions, just as in fixest. Both function can be found in an estimation module and need to obtain a pd.DataFrame as a function argument:\nfrom pyfixest.estimation import fixest, fepois\nfrom pyfixest.utils import get_data\n\ndata = get_data()\nfit = feols(\"Y ~ X1 | f1\", data = data, vcov = \"iid\")\nCalling feols() will return an instance of class [Feols(/reference/Feols.qmd), while calling fepois() will return an instance of class Fepois. Multiple estimation syntax will return an instance of class FixestMulti.\nPost processing works as before via .summary(), .tidy() and other methods.\n\n\nNew Features\nA summary function allows to compare multiple models:\nfrom pyfixest.summarize import summary\nfit2 = feols(\"Y ~ X1 + X2| f1\", data = data, vcov = \"iid\")\nsummary([fit, fit2])\nVisualization is possible via custom methods (.iplot() & .coefplot()), but a new module allows to visualize a list of [Feols(/reference/Feols.qmd) and/or Fepois instances:\nfrom pyfixest.visualize import coefplot, iplot\ncoefplot([fit, fit2])\nThe documentation has been improved (though there is still room for progress), and the code has been cleaned up a bit (also lots of room for improvements)."
  },
  {
    "objectID": "contributing.html",
    "href": "contributing.html",
    "title": "Contributing",
    "section": "",
    "text": "Thanks for showing interest in contributing to pyfixest! We appreciate all contributions and constructive feedback, whether that be reporting bugs, requesting new features, or suggesting improvements to documentation.\nIf you‚Äôd like to get involved, but are not yet sure how, please feel free to send us an email. Some familiarity with either Python or econometrics will help, but you really don‚Äôt need to be a numpy core developer or have published in Econometrica =) We‚Äôd be more than happy to invest time to help you get started!\n\n\nWe use GitHub issues to track bugs. You can report a bug by opening a new issue or contribute to an existing issue if related to the bug you are reporting.\nBefore creating a bug report, please check that your bug has not already been reported, and that your bug exists on the latest version of pyfixest. If you find a closed issue that seems to report the same bug you‚Äôre experiencing, open a new issue and include a link to the original issue in your issue description.\nPlease include as many details as possible in your bug report. The information helps the maintainers resolve the issue faster.\n\n\n\nWe use GitHub issues to track bugs and suggested enhancements. You can suggest an enhancement by opening a new feature request. Before creating an enhancement suggestion, please check that a similar issue does not already exist.\nPlease describe the behavior you want and why, and provide examples of how pyfixest would be used if your feature were added.\n\n\n\n\n\npyfixest development flow relies on Python. Testing statistical and econometric models is implement using Python and R. Documents are written with Quarto and Jupyter.\nStart by forking the pyfixest GitHub repository, then clone your forked repository using git:\ngit clone https://github.com/&lt;username&gt;/pyfixest.git\ncd pyfixest\nIn order to work of pyfixest, you will need Python and R installed. If working on documentation, you will need Quarto installed.\nThere are multiple ways of installing Python and R, but if you need to install them prior to development the following are potential options:\n\n\nOn Mac/Linux via Hombrew:\nbrew install python@3.11 # specify the version of python you prefer\nOn Windows via Winget:\nwinget install -e --id Python.Python.3.11\n\n\n\n\nNote that installing R and the R packages listed below is only necessary if you want to test against R in your local installation. You can also test against R by using github actions.\nOn Mac/Linux:\nbrew install r\nDepending on your local set up, you may need to install additional libraries, for example:\nsudo apt install gcc-11 cmake\nOn Windows using Winget:\nwinget install -e --id RProject.R\nTests run with R require the following packages:\n\nbase\nbroom\nclubSandwich\ndid2s\nfixest\nstats\nwildrwolf\nritest\nivDiag\n\nRscript -e 'install.packages(c(\"broom\", \"clubSandwich\", \"did2s\", \"fixest\", \"wildrwolf\"), repos=\"https://cran.rstudio.com\"); install.packages('ritest', repos = c('https://grantmcdermott.r-universe.dev', 'https://cloud.r-project.org'))'\nDocumentation for pyfixest is written, compiled, and published using Quarto.\nTo install Quarto, run:\nOn MacOS via Homebrew:\nbrew install --cask quarto\nOn Linux (Ubuntu using gdebi):\nsudo curl -o quarto-linux-amd64.deb -L &lt;https://github.com/quarto-dev/quarto-cli/releases/download/v${QUARTO_VERSION}/quarto-${QUARTO_VERSION}-linux-amd64.deb&gt;\nsudo gdebi quarto-linux-amd64.deb\nOn Windows:\nscoop bucket add extras\nscoop install extras/quarto\n\n\n\nPyFixest is using poetry.\nPlease follow the installation instructions from the poetry documentation.\nAfterwards, you can initiate the project environment and install all dependencies by running\ncd path-to-pyfixest\npoetry install\nIf you type\npoetry shell\nyou will see that you have activated a custom poetry environment for pyfixest.\n\n\n\nWe use ruff and pre-commit to ensure a consistent code style.\nYou can install pre-commit from pip by running\npip install pre-commit\nTo install the required hooks, run\npre-commit install\nand you‚Äôre ready to go!\n\n\n\nThere are several command line targets that assist with development included in the justfile. Just can be installed to help run these command line targets. Installing just is only recommended and not needed for development of pyfixest.\nOn Mac/Linux via Homebrew:\nbrew install just\nOn Windows:\nscoop bucket add main\nscoop install main/just\nThe justfile includes multiple helpful shorthands to help with development. Note that if you are not using windows/powershell, you will have to uncomment the first line of the justfile set shell := [\"powershell.exe\", \"-c\"].\n# install all development dependencies\njust install-dev\n# install all R development dependencies\njust install-r\n# run all tests via pytest\njust tests\nTo rebuild the documentation locally, you can run\n# Build documentation and website\njust docs-build\n# render the docs\njust render\n# preview the docs\njust preview\nTo re-create the csv files in tests/data that contain results from R packages for testing, you can run just update-tests-data."
  },
  {
    "objectID": "contributing.html#reporting-bugs",
    "href": "contributing.html#reporting-bugs",
    "title": "Contributing",
    "section": "",
    "text": "We use GitHub issues to track bugs. You can report a bug by opening a new issue or contribute to an existing issue if related to the bug you are reporting.\nBefore creating a bug report, please check that your bug has not already been reported, and that your bug exists on the latest version of pyfixest. If you find a closed issue that seems to report the same bug you‚Äôre experiencing, open a new issue and include a link to the original issue in your issue description.\nPlease include as many details as possible in your bug report. The information helps the maintainers resolve the issue faster."
  },
  {
    "objectID": "contributing.html#suggesting-enhancements",
    "href": "contributing.html#suggesting-enhancements",
    "title": "Contributing",
    "section": "",
    "text": "We use GitHub issues to track bugs and suggested enhancements. You can suggest an enhancement by opening a new feature request. Before creating an enhancement suggestion, please check that a similar issue does not already exist.\nPlease describe the behavior you want and why, and provide examples of how pyfixest would be used if your feature were added."
  },
  {
    "objectID": "contributing.html#contributing-to-the-codebase",
    "href": "contributing.html#contributing-to-the-codebase",
    "title": "Contributing",
    "section": "",
    "text": "pyfixest development flow relies on Python. Testing statistical and econometric models is implement using Python and R. Documents are written with Quarto and Jupyter.\nStart by forking the pyfixest GitHub repository, then clone your forked repository using git:\ngit clone https://github.com/&lt;username&gt;/pyfixest.git\ncd pyfixest\nIn order to work of pyfixest, you will need Python and R installed. If working on documentation, you will need Quarto installed.\nThere are multiple ways of installing Python and R, but if you need to install them prior to development the following are potential options:\n\n\nOn Mac/Linux via Hombrew:\nbrew install python@3.11 # specify the version of python you prefer\nOn Windows via Winget:\nwinget install -e --id Python.Python.3.11\n\n\n\n\nNote that installing R and the R packages listed below is only necessary if you want to test against R in your local installation. You can also test against R by using github actions.\nOn Mac/Linux:\nbrew install r\nDepending on your local set up, you may need to install additional libraries, for example:\nsudo apt install gcc-11 cmake\nOn Windows using Winget:\nwinget install -e --id RProject.R\nTests run with R require the following packages:\n\nbase\nbroom\nclubSandwich\ndid2s\nfixest\nstats\nwildrwolf\nritest\nivDiag\n\nRscript -e 'install.packages(c(\"broom\", \"clubSandwich\", \"did2s\", \"fixest\", \"wildrwolf\"), repos=\"https://cran.rstudio.com\"); install.packages('ritest', repos = c('https://grantmcdermott.r-universe.dev', 'https://cloud.r-project.org'))'\nDocumentation for pyfixest is written, compiled, and published using Quarto.\nTo install Quarto, run:\nOn MacOS via Homebrew:\nbrew install --cask quarto\nOn Linux (Ubuntu using gdebi):\nsudo curl -o quarto-linux-amd64.deb -L &lt;https://github.com/quarto-dev/quarto-cli/releases/download/v${QUARTO_VERSION}/quarto-${QUARTO_VERSION}-linux-amd64.deb&gt;\nsudo gdebi quarto-linux-amd64.deb\nOn Windows:\nscoop bucket add extras\nscoop install extras/quarto\n\n\n\nPyFixest is using poetry.\nPlease follow the installation instructions from the poetry documentation.\nAfterwards, you can initiate the project environment and install all dependencies by running\ncd path-to-pyfixest\npoetry install\nIf you type\npoetry shell\nyou will see that you have activated a custom poetry environment for pyfixest.\n\n\n\nWe use ruff and pre-commit to ensure a consistent code style.\nYou can install pre-commit from pip by running\npip install pre-commit\nTo install the required hooks, run\npre-commit install\nand you‚Äôre ready to go!\n\n\n\nThere are several command line targets that assist with development included in the justfile. Just can be installed to help run these command line targets. Installing just is only recommended and not needed for development of pyfixest.\nOn Mac/Linux via Homebrew:\nbrew install just\nOn Windows:\nscoop bucket add main\nscoop install main/just\nThe justfile includes multiple helpful shorthands to help with development. Note that if you are not using windows/powershell, you will have to uncomment the first line of the justfile set shell := [\"powershell.exe\", \"-c\"].\n# install all development dependencies\njust install-dev\n# install all R development dependencies\njust install-r\n# run all tests via pytest\njust tests\nTo rebuild the documentation locally, you can run\n# Build documentation and website\njust docs-build\n# render the docs\njust render\n# preview the docs\njust preview\nTo re-create the csv files in tests/data that contain results from R packages for testing, you can run just update-tests-data."
  },
  {
    "objectID": "reference/estimation.bonferroni.html",
    "href": "reference/estimation.bonferroni.html",
    "title": "estimation.bonferroni",
    "section": "",
    "text": "estimation.bonferroni(models, param)\nCompute Bonferroni adjusted p-values for multiple hypothesis testing.\nFor each model, it is assumed that tests to adjust are of the form ‚Äúparam = 0‚Äù.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodels\n(list[Feols, Fepois], Feols or Fepois)\nA list of models for which the p-values should be adjusted, or a Feols or Fepois object.\nrequired\n\n\nparam\nstr\nThe parameter for which the p-values should be adjusted.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nA DataFrame containing estimation statistics, including the Bonferroni adjusted p-values.\n\n\n\n\n\n\nfrom pyfixest.estimation import feols\nfrom pyfixest.utils import get_data\nfrom pyfixest.multcomp import bonferroni\n\ndata = get_data().dropna()\nfit1 = feols(\"Y ~ X1\", data=data)\nfit2 = feols(\"Y ~ X1 + X2\", data=data)\nbonf_df = bonferroni([fit1, fit2], param=\"X1\")\nbonf_df",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "estimation.bonferroni"
    ]
  },
  {
    "objectID": "reference/estimation.bonferroni.html#parameters",
    "href": "reference/estimation.bonferroni.html#parameters",
    "title": "estimation.bonferroni",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nmodels\n(list[Feols, Fepois], Feols or Fepois)\nA list of models for which the p-values should be adjusted, or a Feols or Fepois object.\nrequired\n\n\nparam\nstr\nThe parameter for which the p-values should be adjusted.\nrequired",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "estimation.bonferroni"
    ]
  },
  {
    "objectID": "reference/estimation.bonferroni.html#returns",
    "href": "reference/estimation.bonferroni.html#returns",
    "title": "estimation.bonferroni",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\npd.DataFrame\nA DataFrame containing estimation statistics, including the Bonferroni adjusted p-values.",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "estimation.bonferroni"
    ]
  },
  {
    "objectID": "reference/estimation.bonferroni.html#examples",
    "href": "reference/estimation.bonferroni.html#examples",
    "title": "estimation.bonferroni",
    "section": "",
    "text": "from pyfixest.estimation import feols\nfrom pyfixest.utils import get_data\nfrom pyfixest.multcomp import bonferroni\n\ndata = get_data().dropna()\nfit1 = feols(\"Y ~ X1\", data=data)\nfit2 = feols(\"Y ~ X1 + X2\", data=data)\nbonf_df = bonferroni([fit1, fit2], param=\"X1\")\nbonf_df",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "estimation.bonferroni"
    ]
  },
  {
    "objectID": "reference/estimation.fepois.html",
    "href": "reference/estimation.fepois.html",
    "title": "estimation.fepois",
    "section": "",
    "text": "estimation.fepois(fml, data, vcov=None, ssc=ssc(), fixef_rm='none', fixef_tol=1e-08, iwls_tol=1e-08, iwls_maxiter=25, collin_tol=1e-10, drop_intercept=False, i_ref1=None, copy_data=True, store_data=True, lean=False)\nEstimate Poisson regression model with fixed effects using the ppmlhdfe algorithm.",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "estimation.fepois"
    ]
  },
  {
    "objectID": "reference/estimation.fepois.html#parameters",
    "href": "reference/estimation.fepois.html#parameters",
    "title": "estimation.fepois",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfml\nstr\nA two-sided formula string using fixest formula syntax. Syntax: ‚ÄúY ~ X1 + X2 | FE1 + FE2‚Äù. ‚Äú|‚Äù separates left-hand side and fixed effects. Special syntax includes: - Stepwise regressions (sw, sw0) - Cumulative stepwise regression (csw, csw0) - Multiple dependent variables (Y1 + Y2 ~ X) - Interaction of variables (i(X1,X2)) - Interacted fixed effects (fe1^fe2) Compatible with formula parsing via the formulaic module.\nrequired\n\n\ndata\nDataFrameType\nA pandas or polars dataframe containing the variables in the formula.\nrequired\n\n\nvcov\nUnion[str, dict[str, str]]\nType of variance-covariance matrix for inference. Options include ‚Äúiid‚Äù, ‚Äúhetero‚Äù, ‚ÄúHC1‚Äù, ‚ÄúHC2‚Äù, ‚ÄúHC3‚Äù, or a dictionary for CRV1/CRV3 inference.\nNone\n\n\nssc\nstr\nA ssc object specifying the small sample correction for inference.\nssc()\n\n\nfixef_rm\nstr\nSpecifies whether to drop singleton fixed effects. Options: ‚Äúnone‚Äù (default), ‚Äúsingleton‚Äù.\n'none'\n\n\nfixef_tol\nfloat\nTolerance for the fixed effects demeaning algorithm. Defaults to 1e-08.\n1e-08\n\n\niwls_tol\nOptional[float]\nTolerance for IWLS convergence, by default 1e-08.\n1e-08\n\n\niwls_maxiter\nOptional[float]\nMaximum number of iterations for IWLS convergence, by default 25.\n25\n\n\ncollin_tol\nfloat\nTolerance for collinearity check, by default 1e-10.\n1e-10\n\n\ndrop_intercept\nbool\nWhether to drop the intercept from the model, by default False.\nFalse\n\n\ni_ref1\n\nDeprecated with pyfixest version 0.18.0. Please use i-syntax instead, i.e.¬†fepois(‚ÄòY~ i(f1, ref=1)‚Äô, data = data) instead of the former fepois(‚ÄòY~ i(f1)‚Äô, data = data, i_ref=1).\nNone\n\n\ncopy_data\nbool\nWhether to copy the data before estimation, by default True. If set to False, the data is not copied, which can save memory but may lead to unintended changes in the input data outside of fepois. For example, the input data set is re-index within the function. As far as I know, the only other relevant case is when using interacted fixed effects, in which case you‚Äôll find a column with interacted fixed effects in the data set.\nTrue\n\n\nstore_data\nbool\nWhether to store the data in the model object, by default True. If set to False, the data is not stored in the model object, which can improve performance and save memory. However, it will no longer be possible to access the data via the data attribute of the model object. This has impact on post-estimation capabilities that rely on the data, e.g.¬†predict() or vcov().\nTrue\n\n\nlean\nbool\nFalse by default. If True, then all large objects are removed from the returned result: this will save memory but will block the possibility to use many methods. It is recommended to use the argument vcov to obtain the appropriate standard-errors at estimation time, since obtaining different SEs won‚Äôt be possible afterwards.\nFalse",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "estimation.fepois"
    ]
  },
  {
    "objectID": "reference/estimation.fepois.html#returns",
    "href": "reference/estimation.fepois.html#returns",
    "title": "estimation.fepois",
    "section": "Returns",
    "text": "Returns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nobject\nAn instance of the Fepois class or an instance of class FixestMulti for multiple models specified via fml.",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "estimation.fepois"
    ]
  },
  {
    "objectID": "reference/estimation.fepois.html#examples",
    "href": "reference/estimation.fepois.html#examples",
    "title": "estimation.fepois",
    "section": "Examples",
    "text": "Examples\nThe fepois() function can be used to estimate a simple Poisson regression model with fixed effects. The following example regresses Y on X1 and X2 with fixed effects for f1 and f2: fixed effects are specified after the | symbol.\n\nimport pyfixest as pf\n\ndata = pf.get_data(model = \"Fepois\")\nfit = pf.fepois(\"Y ~ X1 + X2 | f1 + f2\", data)\nfit.summary()\n\n\n            \n            \n            \n\n\n\n            \n            \n            \n\n\n###\n\nEstimation:  Poisson\nDep. var.: Y, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -0.007 |        0.035 |    -0.190 |      0.850 | -0.075 |   0.062 |\n| X2            |     -0.015 |        0.010 |    -1.449 |      0.147 | -0.035 |   0.005 |\n---\nDeviance: 1068.169 \n\n\nFor more examples, please take a look at the documentation of the feols() function.",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "estimation.fepois"
    ]
  },
  {
    "objectID": "reference/report.iplot.html",
    "href": "reference/report.iplot.html",
    "title": "report.iplot",
    "section": "",
    "text": "report.iplot(models, alpha=0.05, figsize=None, yintercept=None, xintercept=None, rotate_xticks=0, title=None, coord_flip=True, keep=None, drop=None, exact_match=False, plot_backend='lets_plot', labels=None, ax=None, joint=None, seed=None)\nPlot model coefficients for variables interacted via ‚Äúi()‚Äù syntax, with confidence intervals.",
    "crumbs": [
      "Documentation",
      "Summarize and Visualize",
      "report.iplot"
    ]
  },
  {
    "objectID": "reference/report.iplot.html#parameters",
    "href": "reference/report.iplot.html#parameters",
    "title": "report.iplot",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodels\nlist or object\nA list of fitted models of type Feols or Fepois, or just a single model.\nrequired\n\n\nfigsize\ntuple or None\nThe size of the figure. If None, the default size is used.\nNone\n\n\nalpha\nfloat\nThe significance level for the confidence intervals.\n0.05\n\n\nyintercept\nint or None\nThe value at which to draw a horizontal line on the plot.\nNone\n\n\nxintercept\nint or None\nThe value at which to draw a vertical line on the plot.\nNone\n\n\nrotate_xticks\nfloat\nThe angle in degrees to rotate the xticks labels. Default is 0 (no rotation).\n0\n\n\ntitle\nstr\nThe title of the plot.\nNone\n\n\ncoord_flip\nbool\nWhether to flip the coordinates of the plot. Default is True.\nTrue\n\n\nkeep\nOptional[Union[list, str]]\nThe pattern for retaining coefficient names. You can pass a string (one pattern) or a list (multiple patterns). Default is keeping all coefficients. You should use regular expressions to select coefficients. ‚Äúage‚Äù, # would keep all coefficients containing age r‚Äù^tr‚Äù, # would keep all coefficients starting with tr r‚Äù\\d$‚Äú, # would keep all coefficients ending with number Output will be in the order of the patterns.\nNone\n\n\ndrop\nOptional[Union[list, str]]\nThe pattern for excluding coefficient names. You can pass a string (one pattern) or a list (multiple patterns). Syntax is the same as for keep. Default is keeping all coefficients. Parameter keep and drop can be used simultaneously.\nNone\n\n\nexact_match\nbool\nWhether to use exact match for keep and drop. Default is False. If True, the pattern will be matched exactly to the coefficient name instead of using regular expressions.\nFalse\n\n\nplot_backend\nstr\nThe plotting backend to use between ‚Äúlets_plot‚Äù (default) and ‚Äúmatplotlib‚Äù.\n'lets_plot'\n\n\nlabels\nOptional[dict]\nA dictionary to relabel the variables. The keys are the original variable names and the values the new names. The renaming is applied after the selection of the coefficients via keep and drop.\nNone\n\n\njoint\nOptional[Union[str, bool]]\nWhether to plot simultaneous confidence bands for the coefficients. If True, simultaneous confidence bands are plotted. If False, ‚Äústandard‚Äù confidence intervals are plotted. If ‚Äúboth‚Äù, both are plotted in one figure. Default is None, which returns the standard confidence intervals. Note that this option is not available for objects of type FixestMulti, i.e.¬†multiple estimation.\nNone\n\n\nseed\nOptional[int]\nThe seed for the random number generator. Default is None. Only required / used when joint is True.\nNone",
    "crumbs": [
      "Documentation",
      "Summarize and Visualize",
      "report.iplot"
    ]
  },
  {
    "objectID": "reference/report.iplot.html#returns",
    "href": "reference/report.iplot.html#returns",
    "title": "report.iplot",
    "section": "Returns",
    "text": "Returns\n\n\n\nType\nDescription\n\n\n\n\nobject\nA lets-plot figure.",
    "crumbs": [
      "Documentation",
      "Summarize and Visualize",
      "report.iplot"
    ]
  },
  {
    "objectID": "reference/report.iplot.html#examples",
    "href": "reference/report.iplot.html#examples",
    "title": "report.iplot",
    "section": "Examples",
    "text": "Examples\n\nimport pyfixest as pf\nfrom pyfixest.report.utils import rename_categoricals\n\ndf = pf.get_data()\nfit1 = pf.feols(\"Y ~ i(f1)\", data = df)\nfit2 = pf.feols(\"Y ~ i(f1) + X2\", data = df)\nfit3 = pf.feols(\"Y ~ i(f1) + X2 | f2\", data = df)\n\npf.iplot([fit1, fit2, fit3], labels = rename_categoricals(fit1._coefnames))\n\npf.iplot([fit1], joint = \"both\")",
    "crumbs": [
      "Documentation",
      "Summarize and Visualize",
      "report.iplot"
    ]
  },
  {
    "objectID": "reference/report.summary.html",
    "href": "reference/report.summary.html",
    "title": "report.summary",
    "section": "",
    "text": "report.summary(models, digits=3)\nPrint a summary of estimation results for each estimated model.\nFor each model, this method prints a header indicating the fixed-effects and the dependent variable, followed by a table of coefficient estimates with standard errors, t-values, and p-values.",
    "crumbs": [
      "Documentation",
      "Summarize and Visualize",
      "report.summary"
    ]
  },
  {
    "objectID": "reference/report.summary.html#parameters",
    "href": "reference/report.summary.html#parameters",
    "title": "report.summary",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodels\nlist[Union[Feols, Fepois, Feiv]] or FixestMulti.\nThe models to be summarized.\nrequired\n\n\ndigits\nint\nThe number of decimal places to round the summary statistics to. Default is 3.\n3",
    "crumbs": [
      "Documentation",
      "Summarize and Visualize",
      "report.summary"
    ]
  },
  {
    "objectID": "reference/report.summary.html#returns",
    "href": "reference/report.summary.html#returns",
    "title": "report.summary",
    "section": "Returns",
    "text": "Returns\n\n\n\nType\nDescription\n\n\n\n\nNone",
    "crumbs": [
      "Documentation",
      "Summarize and Visualize",
      "report.summary"
    ]
  },
  {
    "objectID": "reference/report.summary.html#examples",
    "href": "reference/report.summary.html#examples",
    "title": "report.summary",
    "section": "Examples",
    "text": "Examples\n\nimport pyfixest as pf\n\n# load data\ndf = pf.get_data()\nfit1 = pf.feols(\"Y~X1 + X2 | f1\", df)\nfit2 = pf.feols(\"Y~X1 + X2 | f1 + f2\", df)\nfit3 = pf.feols(\"Y~X1 + X2 | f1 + f2 + f3\", df)\n\npf.summary([fit1, fit2, fit3])\n\n\n            \n            \n            \n\n\n\n            \n            \n            \n\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -0.950 |        0.067 |   -14.273 |      0.000 | -1.086 |  -0.813 |\n| X2            |     -0.174 |        0.018 |    -9.469 |      0.000 | -0.212 |  -0.137 |\n---\nRMSE: 1.648 R2: 0.489 R2 Within: 0.239 \n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -0.924 |        0.061 |   -15.165 |      0.000 | -1.049 |  -0.799 |\n| X2            |     -0.174 |        0.015 |   -11.918 |      0.000 | -0.204 |  -0.144 |\n---\nRMSE: 1.346 R2: 0.659 R2 Within: 0.303 \n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2+f3\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -0.957 |        0.039 |   -24.645 |      0.000 | -1.037 |  -0.878 |\n| X2            |     -0.194 |        0.009 |   -21.730 |      0.000 | -0.212 |  -0.176 |\n---\nRMSE: 0.97 R2: 0.823 R2 Within: 0.481",
    "crumbs": [
      "Documentation",
      "Summarize and Visualize",
      "report.summary"
    ]
  },
  {
    "objectID": "reference/report.etable.html",
    "href": "reference/report.etable.html",
    "title": "report.etable",
    "section": "",
    "text": "report.etable(models, type='gt', signif_code=[0.001, 0.01, 0.05], coef_fmt='b \\n (se)', custom_stats=None, keep=None, drop=None, exact_match=False, labels=None, show_fe=True, show_se_type=True, felabels=None, notes=None, model_heads=None, head_order='dh', custom_model_stats=None, filename=None, print_tex=False, **kwargs)\nCreate an esttab-like table from a list of models.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodels\nlist\nA list of models of type Feols, Feiv, Fepois.\nrequired\n\n\ntype\nstr\nType of output. Either ‚Äúdf‚Äù for pandas DataFrame, ‚Äúmd‚Äù for markdown, ‚Äúgt‚Äù for great_tables, or ‚Äútex‚Äù for LaTeX table. Default is ‚Äúgt‚Äù.\n'gt'\n\n\nsignif_code\nlist\nSignificance levels for the stars. Default is [0.001, 0.01, 0.05]. If None, no stars are printed.\n[0.001, 0.01, 0.05]\n\n\ncoef_fmt\nstr\nThe format of the coefficient (b), standard error (se), t-stats (t), and p-value (p). Default is \"b \\n (se)\". Spaces , parentheses (), brackets [], newlines \\n are supported.\n'b \\n (se)'\n\n\ncustom_stats\nOptional[dict]\nA dictionary of custom statistics. ‚Äúb‚Äù, ‚Äúse‚Äù, ‚Äút‚Äù, or ‚Äúp‚Äù are reserved.\nNone\n\n\nkeep\nOptional[Union[list, str]]\nThe pattern for retaining coefficient names. You can pass a string (one pattern) or a list (multiple patterns). Default is keeping all coefficients. You should use regular expressions to select coefficients. ‚Äúage‚Äù, # would keep all coefficients containing age r‚Äù^tr‚Äù, # would keep all coefficients starting with tr r‚Äù\\d$‚Äú, # would keep all coefficients ending with number Output will be in the order of the patterns.\nNone\n\n\ndrop\nOptional[Union[list, str]]\nThe pattern for excluding coefficient names. You can pass a string (one pattern) or a list (multiple patterns). Syntax is the same as for keep. Default is keeping all coefficients. Parameter keep and drop can be used simultaneously.\nNone\n\n\nexact_match\nOptional[bool]\nWhether to use exact match for keep and drop. Default is False. If True, the pattern will be matched exactly to the coefficient name instead of using regular expressions.\nFalse\n\n\nlabels\nOptional[dict]\nA dictionary to relabel the variables. The keys are the original variable names and the values the new names. Note that interaction terms will also be relabeled using the labels of the individual variables. The command is applied after the keep and drop commands.\nNone\n\n\nshow_fe\nOptional[bool]\nWhether to show the rows with fixed effects markers. Default is True.\nTrue\n\n\nshow_se_type\nOptional[bool]\nWhether to show the rows with standard error type. Default is True.\nTrue\n\n\nfelabels\nOptional[dict]\nA dictionary to relabel the fixed effects. Only needed if you want to relabel the FE lines with a different label than the one specied for the respective variable in the labels dictionary. The command is applied after the keep and drop commands.\nNone\n\n\ndigits\n\nThe number of digits to round to.\nrequired\n\n\nthousands_sep\n\nThe thousands separator. Default is False.\nrequired\n\n\nscientific_notation\n\nWhether to use scientific notation. Default is True.\nrequired\n\n\nscientific_notation_threshold\n\nThe threshold for using scientific notation. Default is 10_000.\nrequired\n\n\nnotes\nOptional[str]\nCustom table notes. Default shows the significance levels and the format of the coefficient cell.\nNone\n\n\nmodel_heads\nOptional[list]\nAdd custom headlines to models when output as df or latex. Length of list must correspond to number of models. Default is None.\nNone\n\n\nhead_order\nOptional[str]\nString to determine the display of the table header when output as df or latex. Allowed values are ‚Äúdh‚Äù, ‚Äúhd‚Äù, ‚Äúd‚Äù, ‚Äúh‚Äù, or ‚Äú‚Äú. When head_order is‚Äùdh‚Äù, the dependent variable is displayed first, followed by the custom model_heads (provided the user has specified them). With ‚Äúhd‚Äù it is the other way around. When head_order is ‚Äúd‚Äù, only the dependent variable and model numbers are displayed and with ‚Äú‚Äù only the model numbers. Default is ‚Äúdh‚Äù.\n'dh'\n\n\nfilename\nOptional[str]\nThe filename to save the LaTeX table to. If None, the LaTeX code is returned as a string. Default is None.\nNone\n\n\nprint_tex\nOptional[bool]\nWhether to print the LaTeX code to the console. Default is False.\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nA styled DataFrame with the coefficients and standard errors of the models. When output is ‚Äútex‚Äù, the LaTeX code is returned as a string.",
    "crumbs": [
      "Documentation",
      "Summarize and Visualize",
      "report.etable"
    ]
  },
  {
    "objectID": "reference/report.etable.html#parameters",
    "href": "reference/report.etable.html#parameters",
    "title": "report.etable",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nmodels\nlist\nA list of models of type Feols, Feiv, Fepois.\nrequired\n\n\ntype\nstr\nType of output. Either ‚Äúdf‚Äù for pandas DataFrame, ‚Äúmd‚Äù for markdown, ‚Äúgt‚Äù for great_tables, or ‚Äútex‚Äù for LaTeX table. Default is ‚Äúgt‚Äù.\n'gt'\n\n\nsignif_code\nlist\nSignificance levels for the stars. Default is [0.001, 0.01, 0.05]. If None, no stars are printed.\n[0.001, 0.01, 0.05]\n\n\ncoef_fmt\nstr\nThe format of the coefficient (b), standard error (se), t-stats (t), and p-value (p). Default is \"b \\n (se)\". Spaces , parentheses (), brackets [], newlines \\n are supported.\n'b \\n (se)'\n\n\ncustom_stats\nOptional[dict]\nA dictionary of custom statistics. ‚Äúb‚Äù, ‚Äúse‚Äù, ‚Äút‚Äù, or ‚Äúp‚Äù are reserved.\nNone\n\n\nkeep\nOptional[Union[list, str]]\nThe pattern for retaining coefficient names. You can pass a string (one pattern) or a list (multiple patterns). Default is keeping all coefficients. You should use regular expressions to select coefficients. ‚Äúage‚Äù, # would keep all coefficients containing age r‚Äù^tr‚Äù, # would keep all coefficients starting with tr r‚Äù\\d$‚Äú, # would keep all coefficients ending with number Output will be in the order of the patterns.\nNone\n\n\ndrop\nOptional[Union[list, str]]\nThe pattern for excluding coefficient names. You can pass a string (one pattern) or a list (multiple patterns). Syntax is the same as for keep. Default is keeping all coefficients. Parameter keep and drop can be used simultaneously.\nNone\n\n\nexact_match\nOptional[bool]\nWhether to use exact match for keep and drop. Default is False. If True, the pattern will be matched exactly to the coefficient name instead of using regular expressions.\nFalse\n\n\nlabels\nOptional[dict]\nA dictionary to relabel the variables. The keys are the original variable names and the values the new names. Note that interaction terms will also be relabeled using the labels of the individual variables. The command is applied after the keep and drop commands.\nNone\n\n\nshow_fe\nOptional[bool]\nWhether to show the rows with fixed effects markers. Default is True.\nTrue\n\n\nshow_se_type\nOptional[bool]\nWhether to show the rows with standard error type. Default is True.\nTrue\n\n\nfelabels\nOptional[dict]\nA dictionary to relabel the fixed effects. Only needed if you want to relabel the FE lines with a different label than the one specied for the respective variable in the labels dictionary. The command is applied after the keep and drop commands.\nNone\n\n\ndigits\n\nThe number of digits to round to.\nrequired\n\n\nthousands_sep\n\nThe thousands separator. Default is False.\nrequired\n\n\nscientific_notation\n\nWhether to use scientific notation. Default is True.\nrequired\n\n\nscientific_notation_threshold\n\nThe threshold for using scientific notation. Default is 10_000.\nrequired\n\n\nnotes\nOptional[str]\nCustom table notes. Default shows the significance levels and the format of the coefficient cell.\nNone\n\n\nmodel_heads\nOptional[list]\nAdd custom headlines to models when output as df or latex. Length of list must correspond to number of models. Default is None.\nNone\n\n\nhead_order\nOptional[str]\nString to determine the display of the table header when output as df or latex. Allowed values are ‚Äúdh‚Äù, ‚Äúhd‚Äù, ‚Äúd‚Äù, ‚Äúh‚Äù, or ‚Äú‚Äú. When head_order is‚Äùdh‚Äù, the dependent variable is displayed first, followed by the custom model_heads (provided the user has specified them). With ‚Äúhd‚Äù it is the other way around. When head_order is ‚Äúd‚Äù, only the dependent variable and model numbers are displayed and with ‚Äú‚Äù only the model numbers. Default is ‚Äúdh‚Äù.\n'dh'\n\n\nfilename\nOptional[str]\nThe filename to save the LaTeX table to. If None, the LaTeX code is returned as a string. Default is None.\nNone\n\n\nprint_tex\nOptional[bool]\nWhether to print the LaTeX code to the console. Default is False.\nFalse",
    "crumbs": [
      "Documentation",
      "Summarize and Visualize",
      "report.etable"
    ]
  },
  {
    "objectID": "reference/report.etable.html#returns",
    "href": "reference/report.etable.html#returns",
    "title": "report.etable",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\npandas.DataFrame\nA styled DataFrame with the coefficients and standard errors of the models. When output is ‚Äútex‚Äù, the LaTeX code is returned as a string.",
    "crumbs": [
      "Documentation",
      "Summarize and Visualize",
      "report.etable"
    ]
  },
  {
    "objectID": "reference/did.estimation.event_study.html",
    "href": "reference/did.estimation.event_study.html",
    "title": "did.estimation.event_study",
    "section": "",
    "text": "did.estimation.event_study(data, yname, idname, tname, gname, xfml=None, estimator='twfe', att=True, cluster='idname')\nEstimate Event Study Model.\nThis function allows for the estimation of treatment effects using different estimators. Currently, it supports ‚Äútwfe‚Äù for the two-way fixed effects estimator and ‚Äúdid2s‚Äù for Gardner‚Äôs two-step DID2S estimator. Other estimators are in development.",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "did.estimation.event_study"
    ]
  },
  {
    "objectID": "reference/did.estimation.event_study.html#parameters",
    "href": "reference/did.estimation.event_study.html#parameters",
    "title": "did.estimation.event_study",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\nDataFrame\nThe DataFrame containing all variables.\nrequired\n\n\nyname\nstr\nThe name of the dependent variable.\nrequired\n\n\nidname\nstr\nThe name of the id variable.\nrequired\n\n\ntname\nstr\nVariable name for calendar period.\nrequired\n\n\ngname\nstr\nUnit-specific time of initial treatment.\nrequired\n\n\nxfml\nstr\nThe formula for the covariates.\nNone\n\n\nestimator\nstr\nThe estimator to use. Options are ‚Äúdid2s‚Äù and ‚Äútwfe‚Äù.\n'twfe'\n\n\natt\nbool\nIf True, estimates the average treatment effect on the treated (ATT). If False, estimates the canonical event study design with all leads and lags. Default is True.\nTrue",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "did.estimation.event_study"
    ]
  },
  {
    "objectID": "reference/did.estimation.event_study.html#returns",
    "href": "reference/did.estimation.event_study.html#returns",
    "title": "did.estimation.event_study",
    "section": "Returns",
    "text": "Returns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nobject\nA fitted model object of class [Feols(/reference/Feols.qmd).",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "did.estimation.event_study"
    ]
  },
  {
    "objectID": "reference/did.estimation.event_study.html#examples",
    "href": "reference/did.estimation.event_study.html#examples",
    "title": "did.estimation.event_study",
    "section": "Examples",
    "text": "Examples\n\nimport pandas as pd\nfrom pyfixest.did.estimation import event_study\n\nurl = \"https://raw.githubusercontent.com/py-econometrics/pyfixest/master/pyfixest/did/data/df_het.csv\"\ndf_het = pd.read_csv(url)\n\nfit_twfe = event_study(\n    df_het,\n    yname=\"dep_var\",\n    idname=\"unit\",\n    tname=\"year\",\n    gname=\"g\",\n    estimator=\"twfe\",\n    att=True,\n)\n\nfit_twfe.tidy()\n\n\n            \n            \n            \n\n\n\n            \n            \n            \n\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n2.5%\n97.5%\n\n\nCoefficient\n\n\n\n\n\n\n\n\n\n\nATT\n1.98254\n0.019093\n103.83491\n0.0\n1.945118\n2.019962",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "did.estimation.event_study"
    ]
  },
  {
    "objectID": "reference/estimation.Fepois.html",
    "href": "reference/estimation.Fepois.html",
    "title": "estimation.Fepois",
    "section": "",
    "text": "estimation.Fepois(self, Y, X, fe, weights, coefnames, drop_singletons, collin_tol, maxiter=25, tol=1e-08, fixef_tol=1e-08, solver='np.linalg.solve', weights_name=None, weights_type=None)\nEstimate a Poisson regression model.\nNon user-facing class to estimate a Poisson regression model via Iterated Weighted Least Squares (IWLS).\nInherits from the Feols class. Users should not directly instantiate this class, but rather use the fepois() function. Note that no demeaning is performed in this class: demeaning is performed in the FixestMulti class (to allow for caching of demeaned variables for multiple estimation).\nThe method implements the algorithm from Stata‚Äôs ppmlhdfe module.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nY\nnp.ndarray\nDependent variable, a two-dimensional numpy array.\n\n\nX\nnp.ndarray\nIndependent variables, a two-dimensional numpy array.\n\n\nfe\nnp.ndarray\nFixed effects, a two-dimensional numpy array or None.\n\n\nweights\nnp.ndarray\nWeights, a one-dimensional numpy array or None.\n\n\ncoefnames\nlist[str]\nNames of the coefficients in the design matrix X.\n\n\ndrop_singletons\nbool\nWhether to drop singleton fixed effects.\n\n\ncollin_tol\nfloat\nTolerance level for the detection of collinearity.\n\n\nmaxiter\nOptional[int], default=25\nMaximum number of iterations for the IRLS algorithm.\n\n\ntol\nOptional[float], default=1e-08\nTolerance level for the convergence of the IRLS algorithm.\n\n\nsolver\n(str, default is np.linalg.solve)\nSolver to use for the estimation. Alternative is ‚Äònp.linalg.lstsq‚Äô.\n\n\nfixef_tol\nfloat, default = 1e-08.\nTolerance level for the convergence of the demeaning algorithm.\n\n\nsolver\n\n\n\n\nweights_name\nOptional[str]\nName of the weights variable.\n\n\nweights_type\nOptional[str]\nType of weights variable.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_fit\nFit a Poisson Regression Model via Iterated Weighted Least Squares (IWLS).\n\n\npredict\nReturn predicted values from regression model.\n\n\n\n\n\nestimation.Fepois.get_fit()\nFit a Poisson Regression Model via Iterated Weighted Least Squares (IWLS).\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nbeta_hat\nnp.ndarray\nEstimated coefficients.\n\n\nY_hat\nnp.ndarray\nEstimated dependent variable.\n\n\nu_hat\nnp.ndarray\nEstimated residuals.\n\n\nweights\nnp.ndarray\nWeights (from the last iteration of the IRLS algorithm).\n\n\nX\nnp.ndarray\nDemeaned independent variables (from the last iteration of the IRLS algorithm).\n\n\nZ\nnp.ndarray\nDemeaned independent variables (from the last iteration of the IRLS algorithm).\n\n\nY\nnp.ndarray\nDemeaned dependent variable (from the last iteration of the IRLS algorithm).\n\n\n\n\n\n\n\nestimation.Fepois.predict(newdata=None, atol=1e-06, btol=1e-06, type='link')\nReturn predicted values from regression model.\nReturn a flat np.array with predicted values of the regression model. If new fixed effect levels are introduced in newdata, predicted values for such observations will be set to NaN.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nnewdata\nUnion[None, pd.DataFrame]\nA pd.DataFrame with the new data, to be used for prediction. If None (default), uses the data used for fitting the model.\nNone\n\n\natol\nFloat\nStopping tolerance for scipy.sparse.linalg.lsqr(). See https://docs.scipy.org/doc/ scipy/reference/generated/scipy.sparse.linalg.lsqr.html\n1e-6\n\n\nbtol\nFloat\nAnother stopping tolerance for scipy.sparse.linalg.lsqr(). See https://docs.scipy.org/doc/ scipy/reference/generated/scipy.sparse.linalg.lsqr.html\n1e-6\n\n\ntype\nstr\nThe type of prediction to be computed. Can be either ‚Äúresponse‚Äù (default) or ‚Äúlink‚Äù. If type=‚Äúresponse‚Äù, the output is at the level of the response variable, i.e., it is the expected predictor E(Y|X). If ‚Äúlink‚Äù, the output is at the level of the explanatory variables, i.e., the linear predictor X @ beta.\n'link'\n\n\natol\nFloat\nStopping tolerance for scipy.sparse.linalg.lsqr(). See https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.lsqr.html\n1e-6\n\n\nbtol\nFloat\nAnother stopping tolerance for scipy.sparse.linalg.lsqr(). See https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.lsqr.html\n1e-6\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnp.ndarray\nA flat array with the predicted values of the regression model.",
    "crumbs": [
      "Documentation",
      "Estimation Classes",
      "estimation.Fepois"
    ]
  },
  {
    "objectID": "reference/estimation.Fepois.html#attributes",
    "href": "reference/estimation.Fepois.html#attributes",
    "title": "estimation.Fepois",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nY\nnp.ndarray\nDependent variable, a two-dimensional numpy array.\n\n\nX\nnp.ndarray\nIndependent variables, a two-dimensional numpy array.\n\n\nfe\nnp.ndarray\nFixed effects, a two-dimensional numpy array or None.\n\n\nweights\nnp.ndarray\nWeights, a one-dimensional numpy array or None.\n\n\ncoefnames\nlist[str]\nNames of the coefficients in the design matrix X.\n\n\ndrop_singletons\nbool\nWhether to drop singleton fixed effects.\n\n\ncollin_tol\nfloat\nTolerance level for the detection of collinearity.\n\n\nmaxiter\nOptional[int], default=25\nMaximum number of iterations for the IRLS algorithm.\n\n\ntol\nOptional[float], default=1e-08\nTolerance level for the convergence of the IRLS algorithm.\n\n\nsolver\n(str, default is np.linalg.solve)\nSolver to use for the estimation. Alternative is ‚Äònp.linalg.lstsq‚Äô.\n\n\nfixef_tol\nfloat, default = 1e-08.\nTolerance level for the convergence of the demeaning algorithm.\n\n\nsolver\n\n\n\n\nweights_name\nOptional[str]\nName of the weights variable.\n\n\nweights_type\nOptional[str]\nType of weights variable.",
    "crumbs": [
      "Documentation",
      "Estimation Classes",
      "estimation.Fepois"
    ]
  },
  {
    "objectID": "reference/estimation.Fepois.html#methods",
    "href": "reference/estimation.Fepois.html#methods",
    "title": "estimation.Fepois",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget_fit\nFit a Poisson Regression Model via Iterated Weighted Least Squares (IWLS).\n\n\npredict\nReturn predicted values from regression model.\n\n\n\n\n\nestimation.Fepois.get_fit()\nFit a Poisson Regression Model via Iterated Weighted Least Squares (IWLS).\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nbeta_hat\nnp.ndarray\nEstimated coefficients.\n\n\nY_hat\nnp.ndarray\nEstimated dependent variable.\n\n\nu_hat\nnp.ndarray\nEstimated residuals.\n\n\nweights\nnp.ndarray\nWeights (from the last iteration of the IRLS algorithm).\n\n\nX\nnp.ndarray\nDemeaned independent variables (from the last iteration of the IRLS algorithm).\n\n\nZ\nnp.ndarray\nDemeaned independent variables (from the last iteration of the IRLS algorithm).\n\n\nY\nnp.ndarray\nDemeaned dependent variable (from the last iteration of the IRLS algorithm).\n\n\n\n\n\n\n\nestimation.Fepois.predict(newdata=None, atol=1e-06, btol=1e-06, type='link')\nReturn predicted values from regression model.\nReturn a flat np.array with predicted values of the regression model. If new fixed effect levels are introduced in newdata, predicted values for such observations will be set to NaN.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nnewdata\nUnion[None, pd.DataFrame]\nA pd.DataFrame with the new data, to be used for prediction. If None (default), uses the data used for fitting the model.\nNone\n\n\natol\nFloat\nStopping tolerance for scipy.sparse.linalg.lsqr(). See https://docs.scipy.org/doc/ scipy/reference/generated/scipy.sparse.linalg.lsqr.html\n1e-6\n\n\nbtol\nFloat\nAnother stopping tolerance for scipy.sparse.linalg.lsqr(). See https://docs.scipy.org/doc/ scipy/reference/generated/scipy.sparse.linalg.lsqr.html\n1e-6\n\n\ntype\nstr\nThe type of prediction to be computed. Can be either ‚Äúresponse‚Äù (default) or ‚Äúlink‚Äù. If type=‚Äúresponse‚Äù, the output is at the level of the response variable, i.e., it is the expected predictor E(Y|X). If ‚Äúlink‚Äù, the output is at the level of the explanatory variables, i.e., the linear predictor X @ beta.\n'link'\n\n\natol\nFloat\nStopping tolerance for scipy.sparse.linalg.lsqr(). See https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.lsqr.html\n1e-6\n\n\nbtol\nFloat\nAnother stopping tolerance for scipy.sparse.linalg.lsqr(). See https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.lsqr.html\n1e-6\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnp.ndarray\nA flat array with the predicted values of the regression model.",
    "crumbs": [
      "Documentation",
      "Estimation Classes",
      "estimation.Fepois"
    ]
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "PyFixest Function Reference",
    "section": "",
    "text": "User facing estimation functions\n\n\n\nestimation.feols\nEstimate a linear regression models with fixed effects using fixest formula syntax.\n\n\nestimation.fepois\nEstimate Poisson regression model with fixed effects using the ppmlhdfe algorithm.\n\n\ndid.estimation.did2s\nEstimate a Difference-in-Differences model using Gardner‚Äôs two-step DID2S estimator.\n\n\ndid.estimation.lpdid\nLocal projections approach to estimation.\n\n\ndid.estimation.event_study\nEstimate Event Study Model.\n\n\nestimation.bonferroni\nCompute Bonferroni adjusted p-values for multiple hypothesis testing.\n\n\nestimation.rwolf\nCompute Romano-Wolf adjusted p-values for multiple hypothesis testing.\n\n\n\n\n\n\nDetails on Methods and Attributes\n\n\n\nestimation.Feols\nNon user-facing class to estimate a liner regression via OLS.\n\n\nestimation.Fepois\nEstimate a Poisson regression model.\n\n\nestimation.Feiv\nNon user-facing class to estimate an IV model using a 2SLS estimator.\n\n\n\n\n\n\nPost-Processing of Estimation Results\n\n\n\nreport.summary\nPrint a summary of estimation results for each estimated model.\n\n\nreport.etable\nCreate an esttab-like table from a list of models.\n\n\nreport.coefplot\nPlot model coefficients with confidence intervals.\n\n\nreport.iplot\nPlot model coefficients for variables interacted via ‚Äúi()‚Äù syntax, with\n\n\n\n\n\n\nPyFixest internals and utilities\n\n\n\nestimation.demean\nDemean an array.\n\n\nestimation.detect_singletons\nDetect singleton fixed effects in a dataset.\n\n\nestimation.model_matrix_fixest\nCreate model matrices for fixed effects estimation.",
    "crumbs": [
      "Documentation",
      "PyFixest Function Reference"
    ]
  },
  {
    "objectID": "reference/index.html#estimation-functions",
    "href": "reference/index.html#estimation-functions",
    "title": "PyFixest Function Reference",
    "section": "",
    "text": "User facing estimation functions\n\n\n\nestimation.feols\nEstimate a linear regression models with fixed effects using fixest formula syntax.\n\n\nestimation.fepois\nEstimate Poisson regression model with fixed effects using the ppmlhdfe algorithm.\n\n\ndid.estimation.did2s\nEstimate a Difference-in-Differences model using Gardner‚Äôs two-step DID2S estimator.\n\n\ndid.estimation.lpdid\nLocal projections approach to estimation.\n\n\ndid.estimation.event_study\nEstimate Event Study Model.\n\n\nestimation.bonferroni\nCompute Bonferroni adjusted p-values for multiple hypothesis testing.\n\n\nestimation.rwolf\nCompute Romano-Wolf adjusted p-values for multiple hypothesis testing.",
    "crumbs": [
      "Documentation",
      "PyFixest Function Reference"
    ]
  },
  {
    "objectID": "reference/index.html#estimation-classes",
    "href": "reference/index.html#estimation-classes",
    "title": "PyFixest Function Reference",
    "section": "",
    "text": "Details on Methods and Attributes\n\n\n\nestimation.Feols\nNon user-facing class to estimate a liner regression via OLS.\n\n\nestimation.Fepois\nEstimate a Poisson regression model.\n\n\nestimation.Feiv\nNon user-facing class to estimate an IV model using a 2SLS estimator.",
    "crumbs": [
      "Documentation",
      "PyFixest Function Reference"
    ]
  },
  {
    "objectID": "reference/index.html#summarize-and-visualize",
    "href": "reference/index.html#summarize-and-visualize",
    "title": "PyFixest Function Reference",
    "section": "",
    "text": "Post-Processing of Estimation Results\n\n\n\nreport.summary\nPrint a summary of estimation results for each estimated model.\n\n\nreport.etable\nCreate an esttab-like table from a list of models.\n\n\nreport.coefplot\nPlot model coefficients with confidence intervals.\n\n\nreport.iplot\nPlot model coefficients for variables interacted via ‚Äúi()‚Äù syntax, with",
    "crumbs": [
      "Documentation",
      "PyFixest Function Reference"
    ]
  },
  {
    "objectID": "reference/index.html#misc-utilities",
    "href": "reference/index.html#misc-utilities",
    "title": "PyFixest Function Reference",
    "section": "",
    "text": "PyFixest internals and utilities\n\n\n\nestimation.demean\nDemean an array.\n\n\nestimation.detect_singletons\nDetect singleton fixed effects in a dataset.\n\n\nestimation.model_matrix_fixest\nCreate model matrices for fixed effects estimation.",
    "crumbs": [
      "Documentation",
      "PyFixest Function Reference"
    ]
  },
  {
    "objectID": "reference/estimation.rwolf.html",
    "href": "reference/estimation.rwolf.html",
    "title": "estimation.rwolf",
    "section": "",
    "text": "estimation.rwolf(models, param, reps, seed, sampling_method='wild-bootstrap')\nCompute Romano-Wolf adjusted p-values for multiple hypothesis testing.\nFor each model, it is assumed that tests to adjust are of the form ‚Äúparam = 0‚Äù. This function uses the wildboottest() method for running the bootstrap, hence models of type Feiv or Fepois are not supported.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodels\nlist[Feols] or FixestMulti\nA list of models for which the p-values should be computed, or a FixestMulti object. Models of type Feiv or Fepois are not supported.\nrequired\n\n\nparam\nstr\nThe parameter for which the p-values should be computed.\nrequired\n\n\nreps\nint\nThe number of bootstrap replications.\nrequired\n\n\nseed\nint\nThe seed for the random number generator.\nrequired\n\n\nsampling_method\nstr\nSampling method for computing resampled statistics. Users can choose either bootstrap(‚Äòwild-bootstrap‚Äô) or randomization inference(‚Äòri‚Äô)\n'wild-bootstrap'\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nA DataFrame containing estimation statistics, including the Romano-Wolf adjusted p-values.\n\n\n\n\n\n\nfrom pyfixest.estimation import feols\nfrom pyfixest.utils import get_data\nfrom pyfixest.multcomp import rwolf\n\ndata = get_data().dropna()\nfit = feols(\"Y ~ Y2 + X1 + X2\", data=data)\nrwolf(fit.to_list(), \"X1\", reps=9999, seed=123)\n\nfit1 = feols(\"Y ~ X1\", data=data)\nfit2 = feols(\"Y ~ X1 + X2\", data=data)\nrwolf_df = rwolf([fit1, fit2], \"X1\", reps=9999, seed=123)\nrwolf_df",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "estimation.rwolf"
    ]
  },
  {
    "objectID": "reference/estimation.rwolf.html#parameters",
    "href": "reference/estimation.rwolf.html#parameters",
    "title": "estimation.rwolf",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nmodels\nlist[Feols] or FixestMulti\nA list of models for which the p-values should be computed, or a FixestMulti object. Models of type Feiv or Fepois are not supported.\nrequired\n\n\nparam\nstr\nThe parameter for which the p-values should be computed.\nrequired\n\n\nreps\nint\nThe number of bootstrap replications.\nrequired\n\n\nseed\nint\nThe seed for the random number generator.\nrequired\n\n\nsampling_method\nstr\nSampling method for computing resampled statistics. Users can choose either bootstrap(‚Äòwild-bootstrap‚Äô) or randomization inference(‚Äòri‚Äô)\n'wild-bootstrap'",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "estimation.rwolf"
    ]
  },
  {
    "objectID": "reference/estimation.rwolf.html#returns",
    "href": "reference/estimation.rwolf.html#returns",
    "title": "estimation.rwolf",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\npd.DataFrame\nA DataFrame containing estimation statistics, including the Romano-Wolf adjusted p-values.",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "estimation.rwolf"
    ]
  },
  {
    "objectID": "reference/estimation.rwolf.html#examples",
    "href": "reference/estimation.rwolf.html#examples",
    "title": "estimation.rwolf",
    "section": "",
    "text": "from pyfixest.estimation import feols\nfrom pyfixest.utils import get_data\nfrom pyfixest.multcomp import rwolf\n\ndata = get_data().dropna()\nfit = feols(\"Y ~ Y2 + X1 + X2\", data=data)\nrwolf(fit.to_list(), \"X1\", reps=9999, seed=123)\n\nfit1 = feols(\"Y ~ X1\", data=data)\nfit2 = feols(\"Y ~ X1 + X2\", data=data)\nrwolf_df = rwolf([fit1, fit2], \"X1\", reps=9999, seed=123)\nrwolf_df",
    "crumbs": [
      "Documentation",
      "Estimation Functions",
      "estimation.rwolf"
    ]
  },
  {
    "objectID": "stargazer.html",
    "href": "stargazer.html",
    "title": "Regression Tables via pf.etable() and the Stargazer",
    "section": "",
    "text": "To produce regression tables, we have two options: pyfixest‚Äôs internal etable() function and the Stargazer Python package. The following examples illustrate how to use both options.\nContents:\nTo begin, we load some libraries and fit a set of regression models.\nimport numpy as np\nimport pylatex as pl  # for the latex table; note: not a dependency of pyfixest - needs manual installation\nfrom great_tables import loc, style\nfrom IPython.display import FileLink, display\nfrom stargazer.stargazer import LineLocation, Stargazer\n\nimport pyfixest as pf\n\n%load_ext autoreload\n%autoreload 2\n\ndata = pf.get_data()\n\nfit1 = pf.feols(\"Y ~ X1 + X2 | f1\", data=data)\nfit2 = pf.feols(\"Y ~ X1 + X2 | f1 + f2\", data=data)\nfit3 = pf.feols(\"Y ~ X1 *X2 | f1 + f2\", data=data)\nfit4 = pf.feols(\"Y2 ~ X1 + X2 | f1\", data=data)\nfit5 = pf.feols(\"Y2 ~ X1 + X2 | f1 + f2\", data=data)\nfit6 = pf.feols(\"Y2 ~ X1 *X2 | f1 + f2\", data=data)"
  },
  {
    "objectID": "stargazer.html#regression-tables-via-pf.etable",
    "href": "stargazer.html#regression-tables-via-pf.etable",
    "title": "Regression Tables via pf.etable() and the Stargazer",
    "section": "Regression Tables via pf.etable()",
    "text": "Regression Tables via pf.etable()\n\nBasic Usage\nWe can compare all regression models via the pyfixest-internal pf.etable() function:\n\npf.etable([fit1, fit2, fit3, fit4, fit5, fit6])\n\n\n\n\n\n\n  \n  \n    Y\n  \n  \n    Y2\n  \n\n\n  (1)\n  (2)\n  (3)\n  (4)\n  (5)\n  (6)\n\n\n  \n    coef\n  \n  \n    X1\n    -0.950***  (0.067)\n    -0.924***  (0.061)\n    -0.924***  (0.061)\n    -1.267***  (0.174)\n    -1.232***  (0.192)\n    -1.231***  (0.192)\n  \n  \n    X2\n    -0.174***  (0.018)\n    -0.174***  (0.015)\n    -0.185***  (0.025)\n    -0.131**  (0.042)\n    -0.118**  (0.042)\n    -0.074  (0.104)\n  \n  \n    X1:X2\n    \n    \n    0.011  (0.018)\n    \n    \n    -0.041  (0.081)\n  \n  \n    fe\n  \n  \n    f1\n    x\n    x\n    x\n    x\n    x\n    x\n  \n  \n    f2\n    -\n    x\n    x\n    -\n    x\n    x\n  \n  \n    modelstats\n  \n  \n    Observations\n    997\n    997\n    997\n    998\n    998\n    998\n  \n  \n    S.E. type\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n  \n  \n    R2\n    0.489\n    0.659\n    0.659\n    0.120\n    0.172\n    0.172\n  \n\n  \n  \n  \n    Significance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell:\nCoefficient \n (Std. Error)\n  \n\n\n\n\n\n\n        \n\n\n\n\nKeep and drop variables\netable allows us to do a few things out of the box. For example, we can only keep the variables that we‚Äôd like, which keeps all variables that fit the provided regex match.\n\npf.etable([fit1, fit2, fit3, fit4, fit5, fit6], keep=\"X1\")\n\n\n\n\n\n\n  \n  \n    Y\n  \n  \n    Y2\n  \n\n\n  (1)\n  (2)\n  (3)\n  (4)\n  (5)\n  (6)\n\n\n  \n    coef\n  \n  \n    X1\n    -0.950***  (0.067)\n    -0.924***  (0.061)\n    -0.924***  (0.061)\n    -1.267***  (0.174)\n    -1.232***  (0.192)\n    -1.231***  (0.192)\n  \n  \n    X1:X2\n    \n    \n    0.011  (0.018)\n    \n    \n    -0.041  (0.081)\n  \n  \n    fe\n  \n  \n    f1\n    x\n    x\n    x\n    x\n    x\n    x\n  \n  \n    f2\n    -\n    x\n    x\n    -\n    x\n    x\n  \n  \n    modelstats\n  \n  \n    Observations\n    997\n    997\n    997\n    998\n    998\n    998\n  \n  \n    S.E. type\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n  \n  \n    R2\n    0.489\n    0.659\n    0.659\n    0.120\n    0.172\n    0.172\n  \n\n  \n  \n  \n    Significance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell:\nCoefficient \n (Std. Error)\n  \n\n\n\n\n\n\n        \n\n\nWe can use the exact_match argument to select a specific set of variables:\n\npf.etable([fit1, fit2, fit3, fit4, fit5, fit6], keep=[\"X1\", \"X2\"], exact_match=True)\n\n\n\n\n\n\n  \n  \n    Y\n  \n  \n    Y2\n  \n\n\n  (1)\n  (2)\n  (3)\n  (4)\n  (5)\n  (6)\n\n\n  \n    coef\n  \n  \n    X1\n    -0.950***  (0.067)\n    -0.924***  (0.061)\n    -0.924***  (0.061)\n    -1.267***  (0.174)\n    -1.232***  (0.192)\n    -1.231***  (0.192)\n  \n  \n    X2\n    -0.174***  (0.018)\n    -0.174***  (0.015)\n    -0.185***  (0.025)\n    -0.131**  (0.042)\n    -0.118**  (0.042)\n    -0.074  (0.104)\n  \n  \n    fe\n  \n  \n    f1\n    x\n    x\n    x\n    x\n    x\n    x\n  \n  \n    f2\n    -\n    x\n    x\n    -\n    x\n    x\n  \n  \n    modelstats\n  \n  \n    Observations\n    997\n    997\n    997\n    998\n    998\n    998\n  \n  \n    S.E. type\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n  \n  \n    R2\n    0.489\n    0.659\n    0.659\n    0.120\n    0.172\n    0.172\n  \n\n  \n  \n  \n    Significance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell:\nCoefficient \n (Std. Error)\n  \n\n\n\n\n\n\n        \n\n\nWe can also easily drop variables via the drop argument:\n\npf.etable([fit1, fit2, fit3, fit4, fit5, fit6], drop=[\"X1\"])\n\n\n\n\n\n\n  \n  \n    Y\n  \n  \n    Y2\n  \n\n\n  (1)\n  (2)\n  (3)\n  (4)\n  (5)\n  (6)\n\n\n  \n    coef\n  \n  \n    X2\n    -0.174***  (0.018)\n    -0.174***  (0.015)\n    -0.185***  (0.025)\n    -0.131**  (0.042)\n    -0.118**  (0.042)\n    -0.074  (0.104)\n  \n  \n    fe\n  \n  \n    f1\n    x\n    x\n    x\n    x\n    x\n    x\n  \n  \n    f2\n    -\n    x\n    x\n    -\n    x\n    x\n  \n  \n    modelstats\n  \n  \n    Observations\n    997\n    997\n    997\n    998\n    998\n    998\n  \n  \n    S.E. type\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n  \n  \n    R2\n    0.489\n    0.659\n    0.659\n    0.120\n    0.172\n    0.172\n  \n\n  \n  \n  \n    Significance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell:\nCoefficient \n (Std. Error)\n  \n\n\n\n\n\n\n        \n\n\n\n\nHide fixed effects or SE-type rows\nWe can hide the rows showing the relevant fixed effects and those showing the S.E. type by setting show_fe=False and show_setype=False (for instance when the set of fixed effects or the estimation method for the std. errors is the same for all models and you want to describe this in the text or table notes rather than displaying it in the table).\n\npf.etable([fit1, fit2, fit3, fit4, fit5, fit6], show_fe=False, show_se_type=False)\n\n\n\n\n\n\n  \n  \n    Y\n  \n  \n    Y2\n  \n\n\n  (1)\n  (2)\n  (3)\n  (4)\n  (5)\n  (6)\n\n\n  \n    coef\n  \n  \n    X1\n    -0.950***  (0.067)\n    -0.924***  (0.061)\n    -0.924***  (0.061)\n    -1.267***  (0.174)\n    -1.232***  (0.192)\n    -1.231***  (0.192)\n  \n  \n    X2\n    -0.174***  (0.018)\n    -0.174***  (0.015)\n    -0.185***  (0.025)\n    -0.131**  (0.042)\n    -0.118**  (0.042)\n    -0.074  (0.104)\n  \n  \n    X1:X2\n    \n    \n    0.011  (0.018)\n    \n    \n    -0.041  (0.081)\n  \n  \n    modelstats\n  \n  \n    Observations\n    997\n    997\n    997\n    998\n    998\n    998\n  \n  \n    R2\n    0.489\n    0.659\n    0.659\n    0.120\n    0.172\n    0.172\n  \n\n  \n  \n  \n    Significance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell:\nCoefficient \n (Std. Error)\n  \n\n\n\n\n\n\n        \n\n\n\n\nDisplay p-values or confidence intervals\nBy default, pf.etable() reports standard errors. But we can also ask to output p-values or confidence intervals via the coef_fmt function argument.\n\npf.etable([fit1, fit2, fit3, fit4, fit5, fit6], coef_fmt=\"b \\n (se) \\n [p]\")\n\n\n\n\n\n\n  \n  \n    Y\n  \n  \n    Y2\n  \n\n\n  (1)\n  (2)\n  (3)\n  (4)\n  (5)\n  (6)\n\n\n  \n    coef\n  \n  \n    X1\n    -0.950***  (0.067)  [0.000]\n    -0.924***  (0.061)  [0.000]\n    -0.924***  (0.061)  [0.000]\n    -1.267***  (0.174)  [0.000]\n    -1.232***  (0.192)  [0.000]\n    -1.231***  (0.192)  [0.000]\n  \n  \n    X2\n    -0.174***  (0.018)  [0.000]\n    -0.174***  (0.015)  [0.000]\n    -0.185***  (0.025)  [0.000]\n    -0.131**  (0.042)  [0.005]\n    -0.118**  (0.042)  [0.008]\n    -0.074  (0.104)  [0.482]\n  \n  \n    X1:X2\n    \n    \n    0.011  (0.018)  [0.565]\n    \n    \n    -0.041  (0.081)  [0.618]\n  \n  \n    fe\n  \n  \n    f1\n    x\n    x\n    x\n    x\n    x\n    x\n  \n  \n    f2\n    -\n    x\n    x\n    -\n    x\n    x\n  \n  \n    modelstats\n  \n  \n    Observations\n    997\n    997\n    997\n    998\n    998\n    998\n  \n  \n    S.E. type\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n  \n  \n    R2\n    0.489\n    0.659\n    0.659\n    0.120\n    0.172\n    0.172\n  \n\n  \n  \n  \n    Significance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell:\nCoefficient \n (Std. Error) \n [p-value]\n  \n\n\n\n\n\n\n        \n\n\n\n\nSignificance levels and rounding\nAdditionally, we can also overwrite the defaults for the reported significance levels and control the rounding of results via the signif_code and digits function arguments:\n\npf.etable([fit1, fit2, fit3, fit4, fit5, fit6], signif_code=[0.01, 0.05, 0.1], digits=5)\n\n\n\n\n\n\n  \n  \n    Y\n  \n  \n    Y2\n  \n\n\n  (1)\n  (2)\n  (3)\n  (4)\n  (5)\n  (6)\n\n\n  \n    coef\n  \n  \n    X1\n    -0.94953***  (0.06652)\n    -0.92405***  (0.06093)\n    -0.92417***  (0.06094)\n    -1.26655***  (0.17359)\n    -1.23153***  (0.19228)\n    -1.23100***  (0.19167)\n  \n  \n    X2\n    -0.17423***  (0.01840)\n    -0.17411***  (0.01461)\n    -0.18550***  (0.02516)\n    -0.13056***  (0.04239)\n    -0.11767***  (0.04152)\n    -0.07369  (0.10356)\n  \n  \n    X1:X2\n    \n    \n    0.01057  (0.01818)\n    \n    \n    -0.04082  (0.08093)\n  \n  \n    fe\n  \n  \n    f1\n    x\n    x\n    x\n    x\n    x\n    x\n  \n  \n    f2\n    -\n    x\n    x\n    -\n    x\n    x\n  \n  \n    modelstats\n  \n  \n    Observations\n    997\n    997\n    997\n    998\n    998\n    998\n  \n  \n    S.E. type\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n  \n  \n    R2\n    0.48899\n    0.65904\n    0.65916\n    0.12017\n    0.17151\n    0.17180\n  \n\n  \n  \n  \n    Significance levels: * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01. Format of coefficient cell:\nCoefficient \n (Std. Error)\n  \n\n\n\n\n\n\n        \n\n\n\n\nOther output formats\nBy default, pf.etable() returns a GT object (see the Great Tables package), but you can also opt to pandas styler, markdown, or latex output via the type argument.\n\n# Pandas styler output:\npf.etable(\n    [fit1, fit2, fit3, fit4, fit5, fit6],\n    signif_code=[0.01, 0.05, 0.1],\n    digits=5,\n    type=\"df\",\n)\n\n\n\n  Significance levels: * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01. Format of coefficient cell:\nCoefficient \n (Std. Error)\n  \n    \n      \n      Y\n      Y2\n    \n    \n      \n      (1)\n      (2)\n      (3)\n      (4)\n      (5)\n      (6)\n    \n  \n  \n    \n      X1\n      -0.94953***  (0.06652)\n      -0.92405***  (0.06093)\n      -0.92417***  (0.06094)\n      -1.26655***  (0.17359)\n      -1.23153***  (0.19228)\n      -1.23100***  (0.19167)\n    \n    \n      X2\n      -0.17423***  (0.01840)\n      -0.17411***  (0.01461)\n      -0.18550***  (0.02516)\n      -0.13056***  (0.04239)\n      -0.11767***  (0.04152)\n      -0.07369  (0.10356)\n    \n    \n      X1:X2\n      \n      \n      0.01057  (0.01818)\n      \n      \n      -0.04082  (0.08093)\n    \n    \n      f1\n      x\n      x\n      x\n      x\n      x\n      x\n    \n    \n      f2\n      -\n      x\n      x\n      -\n      x\n      x\n    \n    \n      Observations\n      997\n      997\n      997\n      998\n      998\n      998\n    \n    \n      S.E. type\n      by: f1\n      by: f1\n      by: f1\n      by: f1\n      by: f1\n      by: f1\n    \n    \n      R2\n      0.48899\n      0.65904\n      0.65916\n      0.12017\n      0.17151\n      0.17180\n    \n  \n\n\n\n\n# Markdown output:\npf.etable(\n    [fit1, fit2, fit3, fit4, fit5, fit6],\n    signif_code=[0.01, 0.05, 0.1],\n    digits=5,\n    type=\"md\",\n)\n\n                      est1          est2          est3          est4          est5          est6\n------------  ------------  ------------  ------------  ------------  ------------  ------------\ndepvar                   Y             Y             Y            Y2            Y2            Y2\n------------------------------------------------------------------------------------------------\nX1            -0.94953***   -0.92405***   -0.92417***   -1.26655***   -1.23153***   -1.23100***\n                 (0.06652)     (0.06093)     (0.06094)     (0.17359)     (0.19228)     (0.19167)\nX2            -0.17423***   -0.17411***   -0.18550***   -0.13056***   -0.11767***      -0.07369\n                 (0.01840)     (0.01461)     (0.02516)     (0.04239)     (0.04152)     (0.10356)\nX1:X2                                         0.01057                                  -0.04082\n                                             (0.01818)                                 (0.08093)\n------------------------------------------------------------------------------------------------\nf1                       x             x             x             x             x             x\nf2                       -             x             x             -             x             x\n------------------------------------------------------------------------------------------------\nObservations           997           997           997           998           998           998\nS.E. type           by: f1        by: f1        by: f1        by: f1        by: f1        by: f1\nR2                 0.48899       0.65904       0.65916       0.12017       0.17151       0.17180\n------------------------------------------------------------------------------------------------\nSignificance levels: * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\nTo obtain latex output use format = \"tex\". If you want to save the table as a tex file, you can use the filename= argument to specify the respective path where it should be saved. If you want the latex code to be displayed in the notebook, you can use the print_tex=True argument. Etable will use latex packages booktabs, threeparttable and makecell for the table layout, so don‚Äôt forget to include these packages in your latex document.\n\n# LaTex output (include latex packages booktabs, threeparttable, and makecell in your document):\ntab = pf.etable(\n    [fit1, fit2, fit3, fit4, fit5, fit6],\n    signif_code=[0.01, 0.05, 0.1],\n    digits=2,\n    type=\"tex\",\n    print_tex=True,\n)\n\n\\renewcommand\\cellalign{t}\n\\begin{threeparttable}\n\\begin{tabular}{lcccccc}\n\\toprule\n & \\multicolumn{3}{c}{Y} & \\multicolumn{3}{c}{Y2} \\\\\n\\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \n & (1) & (2) & (3) & (4) & (5) & (6) \\\\\n\\midrule\nX1 & \\makecell{-0.95*** \\\\ (0.07)} & \\makecell{-0.92*** \\\\ (0.06)} & \\makecell{-0.92*** \\\\ (0.06)} & \\makecell{-1.27*** \\\\ (0.17)} & \\makecell{-1.23*** \\\\ (0.19)} & \\makecell{-1.23*** \\\\ (0.19)} \\\\\nX2 & \\makecell{-0.17*** \\\\ (0.02)} & \\makecell{-0.17*** \\\\ (0.01)} & \\makecell{-0.19*** \\\\ (0.03)} & \\makecell{-0.13*** \\\\ (0.04)} & \\makecell{-0.12*** \\\\ (0.04)} & \\makecell{-0.07 \\\\ (0.10)} \\\\\nX1:X2 &  &  & \\makecell{0.01 \\\\ (0.02)} &  &  & \\makecell{-0.04 \\\\ (0.08)} \\\\\n\\midrule\nf1 & x & x & x & x & x & x \\\\\nf2 & - & x & x & - & x & x \\\\\n\\midrule\nObservations & 997 & 997 & 997 & 998 & 998 & 998 \\\\\nS.E. type & by: f1 & by: f1 & by: f1 & by: f1 & by: f1 & by: f1 \\\\\n$R^2$ & 0.49 & 0.66 & 0.66 & 0.12 & 0.17 & 0.17 \\\\\n\\bottomrule\n\\end{tabular}\n\\footnotesize Significance levels: $*$ p $&lt;$ 0.1, $**$ p $&lt;$ 0.05, $***$ p $&lt;$ 0.01. Format of coefficient cell: Coefficient \n (Std. Error)\n\\end{threeparttable}\n\n\nThe following code generates a pdf including the regression table which you can display clicking on the link below the cell:\n\n## Use pylatex to create a tex file with the table\n\n\ndef make_pdf(tab, file):\n    \"Create a PDF document with tex table.\"\n    doc = pl.Document()\n    doc.packages.append(pl.Package(\"booktabs\"))\n    doc.packages.append(pl.Package(\"threeparttable\"))\n    doc.packages.append(pl.Package(\"makecell\"))\n\n    with (\n        doc.create(pl.Section(\"A PyFixest LateX Table\")),\n        doc.create(pl.Table(position=\"htbp\")) as table,\n    ):\n        table.append(pl.NoEscape(tab))\n\n    doc.generate_pdf(file, clean_tex=False)\n\n\n# Compile latex to pdf & display a button with the hyperlink to the pdf\nmake_pdf(tab, \"latexdocs/SampleTableDoc\")\ndisplay(FileLink(\"latexdocs/SampleTableDoc.pdf\"))\n\nlatexdocs/SampleTableDoc.pdf\n\n\n\n\nCustom Styling with Great Tables\nYou can use the rich set of methods offered by Great Tables to further customize the table display.\n\n(\n    pf.etable([fit1, fit2, fit3, fit4, fit5, fit6])\n    .tab_options(\n        column_labels_background_color=\"cornsilk\",\n        stub_background_color=\"whitesmoke\",\n    )\n    .tab_style(\n        style=style.fill(color=\"mistyrose\"),\n        locations=loc.body(columns=\"(3)\", rows=[\"X2\"]),\n    )\n)\n\n\n\n\n\n\n  \n  \n    Y\n  \n  \n    Y2\n  \n\n\n  (1)\n  (2)\n  (3)\n  (4)\n  (5)\n  (6)\n\n\n  \n    coef\n  \n  \n    X1\n    -0.950***  (0.067)\n    -0.924***  (0.061)\n    -0.924***  (0.061)\n    -1.267***  (0.174)\n    -1.232***  (0.192)\n    -1.231***  (0.192)\n  \n  \n    X2\n    -0.174***  (0.018)\n    -0.174***  (0.015)\n    -0.185***  (0.025)\n    -0.131**  (0.042)\n    -0.118**  (0.042)\n    -0.074  (0.104)\n  \n  \n    X1:X2\n    \n    \n    0.011  (0.018)\n    \n    \n    -0.041  (0.081)\n  \n  \n    fe\n  \n  \n    f1\n    x\n    x\n    x\n    x\n    x\n    x\n  \n  \n    f2\n    -\n    x\n    x\n    -\n    x\n    x\n  \n  \n    modelstats\n  \n  \n    Observations\n    997\n    997\n    997\n    998\n    998\n    998\n  \n  \n    S.E. type\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n  \n  \n    R2\n    0.489\n    0.659\n    0.659\n    0.120\n    0.172\n    0.172\n  \n\n  \n  \n  \n    Significance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell:\nCoefficient \n (Std. Error)\n  \n\n\n\n\n\n\n        \n\n\n\n\nRename variables\nYou can also rename variables if you want to have a more readable output. Just pass a dictionary to the labels argument. Note that interaction terms will also be relabeled using the specified labels for the interacted variables (if you want to manually relabel an interaction term differently, add it to the dictionary).\n\nlabels = {\n    \"Y\": \"Wage\",\n    \"Y2\": \"Wealth\",\n    \"X1\": \"Age\",\n    \"X2\": \"Years of Schooling\",\n    \"f1\": \"Industry\",\n    \"f2\": \"Year\",\n}\n\npf.etable([fit1, fit2, fit3, fit4, fit5, fit6], labels=labels)\n\n\n\n\n\n\n  \n  \n    Wage\n  \n  \n    Wealth\n  \n\n\n  (1)\n  (2)\n  (3)\n  (4)\n  (5)\n  (6)\n\n\n  \n    coef\n  \n  \n    Age\n    -0.950***  (0.067)\n    -0.924***  (0.061)\n    -0.924***  (0.061)\n    -1.267***  (0.174)\n    -1.232***  (0.192)\n    -1.231***  (0.192)\n  \n  \n    Years of Schooling\n    -0.174***  (0.018)\n    -0.174***  (0.015)\n    -0.185***  (0.025)\n    -0.131**  (0.042)\n    -0.118**  (0.042)\n    -0.074  (0.104)\n  \n  \n    Age x Years of Schooling\n    \n    \n    0.011  (0.018)\n    \n    \n    -0.041  (0.081)\n  \n  \n    fe\n  \n  \n    Industry\n    x\n    x\n    x\n    x\n    x\n    x\n  \n  \n    Year\n    -\n    x\n    x\n    -\n    x\n    x\n  \n  \n    modelstats\n  \n  \n    Observations\n    997\n    997\n    997\n    998\n    998\n    998\n  \n  \n    S.E. type\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n  \n  \n    R2\n    0.489\n    0.659\n    0.659\n    0.120\n    0.172\n    0.172\n  \n\n  \n  \n  \n    Significance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell:\nCoefficient \n (Std. Error)\n  \n\n\n\n\n\n\n        \n\n\nIf you want to label the rows indicating the inclusion of fixed effects not with the variable label but with a custom label, you can pass on a separate dictionary to the felabels argument.\n\npf.etable(\n    [fit1, fit2, fit3, fit4, fit5, fit6],\n    labels=labels,\n    felabels={\"f1\": \"Industry Fixed Effects\", \"f2\": \"Year Fixed Effects\"},\n)\n\n\n\n\n\n\n  \n  \n    Wage\n  \n  \n    Wealth\n  \n\n\n  (1)\n  (2)\n  (3)\n  (4)\n  (5)\n  (6)\n\n\n  \n    coef\n  \n  \n    Age\n    -0.950***  (0.067)\n    -0.924***  (0.061)\n    -0.924***  (0.061)\n    -1.267***  (0.174)\n    -1.232***  (0.192)\n    -1.231***  (0.192)\n  \n  \n    Years of Schooling\n    -0.174***  (0.018)\n    -0.174***  (0.015)\n    -0.185***  (0.025)\n    -0.131**  (0.042)\n    -0.118**  (0.042)\n    -0.074  (0.104)\n  \n  \n    Age x Years of Schooling\n    \n    \n    0.011  (0.018)\n    \n    \n    -0.041  (0.081)\n  \n  \n    fe\n  \n  \n    Industry Fixed Effects\n    x\n    x\n    x\n    x\n    x\n    x\n  \n  \n    Year Fixed Effects\n    -\n    x\n    x\n    -\n    x\n    x\n  \n  \n    modelstats\n  \n  \n    Observations\n    997\n    997\n    997\n    998\n    998\n    998\n  \n  \n    S.E. type\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n  \n  \n    R2\n    0.489\n    0.659\n    0.659\n    0.120\n    0.172\n    0.172\n  \n\n  \n  \n  \n    Significance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell:\nCoefficient \n (Std. Error)\n  \n\n\n\n\n\n\n        \n\n\n\n\nCustom model headlines\nYou can also add custom headers for each model by passing a list of strings to the model_headers argument.\n\npf.etable(\n    [fit1, fit2, fit3, fit4, fit5, fit6],\n    labels=labels,\n    model_heads=[\"US\", \"China\", \"EU\", \"US\", \"China\", \"EU\"],\n)\n\n\n\n\n\n\n  \n    ¬†\n  \n  \n    Wage\n  \n  \n    Wealth\n  \n\n\n  \n  \n    US\n  \n  \n    China\n  \n  \n    EU\n  \n  \n    US\n  \n  \n    China\n  \n  \n    EU\n  \n\n\n  (1)\n  (2)\n  (3)\n  (4)\n  (5)\n  (6)\n\n\n  \n    coef\n  \n  \n    Age\n    -0.950***  (0.067)\n    -0.924***  (0.061)\n    -0.924***  (0.061)\n    -1.267***  (0.174)\n    -1.232***  (0.192)\n    -1.231***  (0.192)\n  \n  \n    Years of Schooling\n    -0.174***  (0.018)\n    -0.174***  (0.015)\n    -0.185***  (0.025)\n    -0.131**  (0.042)\n    -0.118**  (0.042)\n    -0.074  (0.104)\n  \n  \n    Age x Years of Schooling\n    \n    \n    0.011  (0.018)\n    \n    \n    -0.041  (0.081)\n  \n  \n    fe\n  \n  \n    Industry\n    x\n    x\n    x\n    x\n    x\n    x\n  \n  \n    Year\n    -\n    x\n    x\n    -\n    x\n    x\n  \n  \n    modelstats\n  \n  \n    Observations\n    997\n    997\n    997\n    998\n    998\n    998\n  \n  \n    S.E. type\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n  \n  \n    R2\n    0.489\n    0.659\n    0.659\n    0.120\n    0.172\n    0.172\n  \n\n  \n  \n  \n    Significance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell:\nCoefficient \n (Std. Error)\n  \n\n\n\n\n\n\n        \n\n\nOr change the ordering of headlines having headlines first and then dependent variables using the head_order argument. ‚Äúhd‚Äù stands for headlines then dependent variables, ‚Äúdh‚Äù for dependent variables then headlines. Assigning ‚Äúd‚Äù or ‚Äúh‚Äù can be used to only show dependent variables or only headlines. When head_order=‚Äú‚Äù only model numbers are shown.\n\npf.etable(\n    [fit1, fit4, fit2, fit5, fit3, fit6],\n    labels=labels,\n    model_heads=[\"US\", \"US\", \"China\", \"China\", \"EU\", \"EU\"],\n    head_order=\"hd\",\n)\n\n\n\n\n\n\n  \n    ¬†\n  \n  \n    US\n  \n  \n    China\n  \n  \n    EU\n  \n\n\n  \n  \n    Wage\n  \n  \n    Wealth\n  \n  \n    Wage\n  \n  \n    Wealth\n  \n  \n    Wage\n  \n  \n    Wealth\n  \n\n\n  (1)\n  (2)\n  (3)\n  (4)\n  (5)\n  (6)\n\n\n  \n    coef\n  \n  \n    Age\n    -0.950***  (0.067)\n    -1.267***  (0.174)\n    -0.924***  (0.061)\n    -1.232***  (0.192)\n    -0.924***  (0.061)\n    -1.231***  (0.192)\n  \n  \n    Years of Schooling\n    -0.174***  (0.018)\n    -0.131**  (0.042)\n    -0.174***  (0.015)\n    -0.118**  (0.042)\n    -0.185***  (0.025)\n    -0.074  (0.104)\n  \n  \n    Age x Years of Schooling\n    \n    \n    \n    \n    0.011  (0.018)\n    -0.041  (0.081)\n  \n  \n    fe\n  \n  \n    Industry\n    x\n    x\n    x\n    x\n    x\n    x\n  \n  \n    Year\n    -\n    -\n    x\n    x\n    x\n    x\n  \n  \n    modelstats\n  \n  \n    Observations\n    997\n    998\n    997\n    998\n    997\n    998\n  \n  \n    S.E. type\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n  \n  \n    R2\n    0.489\n    0.120\n    0.659\n    0.172\n    0.659\n    0.172\n  \n\n  \n  \n  \n    Significance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell:\nCoefficient \n (Std. Error)\n  \n\n\n\n\n\n\n        \n\n\nRemove the dependent variables from the headers:\n\npf.etable(\n    [fit1, fit4, fit2, fit5, fit3, fit6],\n    labels=labels,\n    model_heads=[\"US\", \"US\", \"China\", \"China\", \"EU\", \"EU\"],\n    head_order=\"\",\n)\n\n\n\n\n\n\n  \n  (1)\n  (2)\n  (3)\n  (4)\n  (5)\n  (6)\n\n\n  \n    coef\n  \n  \n    Age\n    -0.950***  (0.067)\n    -1.267***  (0.174)\n    -0.924***  (0.061)\n    -1.232***  (0.192)\n    -0.924***  (0.061)\n    -1.231***  (0.192)\n  \n  \n    Years of Schooling\n    -0.174***  (0.018)\n    -0.131**  (0.042)\n    -0.174***  (0.015)\n    -0.118**  (0.042)\n    -0.185***  (0.025)\n    -0.074  (0.104)\n  \n  \n    Age x Years of Schooling\n    \n    \n    \n    \n    0.011  (0.018)\n    -0.041  (0.081)\n  \n  \n    fe\n  \n  \n    Industry\n    x\n    x\n    x\n    x\n    x\n    x\n  \n  \n    Year\n    -\n    -\n    x\n    x\n    x\n    x\n  \n  \n    modelstats\n  \n  \n    Observations\n    997\n    998\n    997\n    998\n    997\n    998\n  \n  \n    S.E. type\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n  \n  \n    R2\n    0.489\n    0.120\n    0.659\n    0.172\n    0.659\n    0.172\n  \n\n  \n  \n  \n    Significance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell:\nCoefficient \n (Std. Error)\n  \n\n\n\n\n\n\n        \n\n\n\n\nFurther custom model information\nYou can add further custom model statistics/information to the bottom of the table by using the custom_stats argument to which you pass a dictionary with the name of the row and lists of values. The length of the lists must be equal to the number of models.\n\npf.etable(\n    [fit1, fit2, fit3, fit4, fit5, fit6],\n    labels=labels,\n    custom_model_stats={\n        \"Number of Clusters\": [42, 42, 42, 37, 37, 37],\n        \"Additional Info\": [\"A\", \"A\", \"B\", \"B\", \"C\", \"C\"],\n    },\n)\n\n\n\n\n\n\n  \n  \n    Wage\n  \n  \n    Wealth\n  \n\n\n  (1)\n  (2)\n  (3)\n  (4)\n  (5)\n  (6)\n\n\n  \n    coef\n  \n  \n    Age\n    -0.950***  (0.067)\n    -0.924***  (0.061)\n    -0.924***  (0.061)\n    -1.267***  (0.174)\n    -1.232***  (0.192)\n    -1.231***  (0.192)\n  \n  \n    Years of Schooling\n    -0.174***  (0.018)\n    -0.174***  (0.015)\n    -0.185***  (0.025)\n    -0.131**  (0.042)\n    -0.118**  (0.042)\n    -0.074  (0.104)\n  \n  \n    Age x Years of Schooling\n    \n    \n    0.011  (0.018)\n    \n    \n    -0.041  (0.081)\n  \n  \n    fe\n  \n  \n    Industry\n    x\n    x\n    x\n    x\n    x\n    x\n  \n  \n    Year\n    -\n    x\n    x\n    -\n    x\n    x\n  \n  \n    modelstats\n  \n  \n    Number of Clusters\n    42\n    42\n    42\n    37\n    37\n    37\n  \n  \n    Additional Info\n    A\n    A\n    B\n    B\n    C\n    C\n  \n  \n    Observations\n    997\n    997\n    997\n    998\n    998\n    998\n  \n  \n    S.E. type\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n  \n  \n    R2\n    0.489\n    0.659\n    0.659\n    0.120\n    0.172\n    0.172\n  \n\n  \n  \n  \n    Significance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell:\nCoefficient \n (Std. Error)\n  \n\n\n\n\n\n\n        \n\n\n\n\nCustom table notes\nYou can replace the default table notes with your own notes using the notes argument.\n\nmynotes = \"Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.\"\npf.etable(\n    [fit1, fit4, fit2, fit5, fit3, fit6],\n    labels=labels,\n    model_heads=[\"US\", \"US\", \"China\", \"China\", \"EU\", \"EU\"],\n    head_order=\"hd\",\n    notes=mynotes,\n)\n\n\n\n\n\n\n  \n    ¬†\n  \n  \n    US\n  \n  \n    China\n  \n  \n    EU\n  \n\n\n  \n  \n    Wage\n  \n  \n    Wealth\n  \n  \n    Wage\n  \n  \n    Wealth\n  \n  \n    Wage\n  \n  \n    Wealth\n  \n\n\n  (1)\n  (2)\n  (3)\n  (4)\n  (5)\n  (6)\n\n\n  \n    coef\n  \n  \n    Age\n    -0.950***  (0.067)\n    -1.267***  (0.174)\n    -0.924***  (0.061)\n    -1.232***  (0.192)\n    -0.924***  (0.061)\n    -1.231***  (0.192)\n  \n  \n    Years of Schooling\n    -0.174***  (0.018)\n    -0.131**  (0.042)\n    -0.174***  (0.015)\n    -0.118**  (0.042)\n    -0.185***  (0.025)\n    -0.074  (0.104)\n  \n  \n    Age x Years of Schooling\n    \n    \n    \n    \n    0.011  (0.018)\n    -0.041  (0.081)\n  \n  \n    fe\n  \n  \n    Industry\n    x\n    x\n    x\n    x\n    x\n    x\n  \n  \n    Year\n    -\n    -\n    x\n    x\n    x\n    x\n  \n  \n    modelstats\n  \n  \n    Observations\n    997\n    998\n    997\n    998\n    997\n    998\n  \n  \n    S.E. type\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n    by: f1\n  \n  \n    R2\n    0.489\n    0.120\n    0.659\n    0.172\n    0.659\n    0.172\n  \n\n  \n  \n  \n    Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.\n  \n\n\n\n\n\n\n        \n\n\n\n\nPublication-ready LaTex tables\nWith few lines of code you thus obtain a publication-ready latex table:\n\ntab = pf.etable(\n    [fit1, fit4, fit2, fit5, fit3, fit6],\n    labels=labels,\n    model_heads=[\"US\", \"US\", \"China\", \"China\", \"EU\", \"EU\"],\n    head_order=\"hd\",\n    type=\"tex\",\n    notes=mynotes,\n    show_fe=True,\n    show_se_type=False,\n    custom_model_stats={\n        \"Number of Clusters\": [42, 42, 42, 37, 37, 37],\n    },\n)\n\n# Compile latex to pdf & display a button with the hyperlink to the pdf\nmake_pdf(tab, \"latexdocs/SampleTableDoc2\")\ndisplay(FileLink(\"latexdocs/SampleTableDoc2.pdf\"))\n\nlatexdocs/SampleTableDoc2.pdf\n\n\n\n\nRendering Tables in Quarto\nWhen you use quarto you can include latex tables generated by pf.etable when rendering the qmd file as pdf. Just specify output: asis in the code block options of the respective chunk and print the LaTex string returned by etable. Don‚Äôt forget to include the \\usepackage commands for necessary latex packages in the YAML block.\nHere you find a sample qmd file and the rendered PDF."
  },
  {
    "objectID": "stargazer.html#regression-tables-via-stargazer",
    "href": "stargazer.html#regression-tables-via-stargazer",
    "title": "Regression Tables via pf.etable() and the Stargazer",
    "section": "Regression Tables via Stargazer",
    "text": "Regression Tables via Stargazer\nWe have opened a PR for pyfixest support for the excellent Stargazer project. Until it is merged, you can download the dev version from py-econometrics by typing\npip install git+https://github.com/py-econometrics/stargazer.git\nStargazer is particularly useful if you need highly customizable regression tables (beyond the scope of pf.etable()), or if you want to compare models from statsmodels or linearmodels with pyfixest.\nAfter installing stargazer, we can produce a summary table via the Stargazer class:\n\nstargazer_table = Stargazer([fit1, fit2, fit3, fit4, fit5, fit6])\nstargazer_table\n\n\n(1)(2)(3)(4)(5)(6)\n\n\nX1-0.950***-0.924***-0.924***-1.267***-1.232***-1.231***\n(0.067)(0.061)(0.061)(0.174)(0.192)(0.192)\nX1:X20.011-0.041\n(0.018)(0.081)\nX2-0.174***-0.174***-0.185***-0.131***-0.118***-0.074\n(0.018)(0.015)(0.025)(0.042)(0.042)(0.104)\n\n\nObservations997997997998998998R20.4890.6590.6590.1200.1720.172\nNote:*p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nWe can easily add custom statisics. For example, assume that we want to correct for multiple testing via the Romano-Wolf correction. We can do this as follows:\n\nrwolf_res = pf.rwolf(\n    [fit1, fit2, fit3, fit4, fit5, fit6], param=\"X1\", seed=123, reps=9999\n)\nrwolf_pvalues = np.round(rwolf_res.xs(\"RW Pr(&gt;|t|)\"), 3).to_list()\n\n\nstargazer_table.add_line(\n    \"Fixed Effects\",\n    [x._fixef for x in [fit1, fit2, fit3, fit4, fit5, fit6]],\n    LineLocation.FOOTER_TOP,\n)\nstargazer_table.add_line(\n    \"X1: Romano-Wolf P-Value\", rwolf_pvalues, LineLocation.FOOTER_TOP\n)\nstargazer_table\n\n\n(1)(2)(3)(4)(5)(6)\n\n\nX1-0.950***-0.924***-0.924***-1.267***-1.232***-1.231***\n(0.067)(0.061)(0.061)(0.174)(0.192)(0.192)\nX1:X20.011-0.041\n(0.018)(0.081)\nX2-0.174***-0.174***-0.185***-0.131***-0.118***-0.074\n(0.018)(0.015)(0.025)(0.042)(0.042)(0.104)\n\n\nFixed Effectsf1f1+f2f1+f2f1f1+f2f1+f2X1: Romano-Wolf P-Value0.00.00.00.00.00.0Observations997997997998998998R20.4890.6590.6590.1200.1720.172\nNote:*p&lt;0.1; **p&lt;0.05; ***p&lt;0.01"
  },
  {
    "objectID": "replicating-the-effect.html",
    "href": "replicating-the-effect.html",
    "title": "Replicating Examples from ‚ÄúThe Effect‚Äù",
    "section": "",
    "text": "This notebook replicates code examples from Nick Huntington-Klein‚Äôs book on causal inference, The Effect.\nfrom causaldata import Mroz, gapminder, organ_donations, restaurant_inspections\n\nimport pyfixest as pf\n\n%load_ext watermark\n%watermark --iversions\n\n\n            \n            \n            \n\n\n\n            \n            \n            \n\n\ncausaldata: 0.1.3\npyfixest  : 0.22.0"
  },
  {
    "objectID": "replicating-the-effect.html#chapter-4-describing-relationships",
    "href": "replicating-the-effect.html#chapter-4-describing-relationships",
    "title": "Replicating Examples from ‚ÄúThe Effect‚Äù",
    "section": "Chapter 4: Describing Relationships",
    "text": "Chapter 4: Describing Relationships\n\n# Read in data\ndt = Mroz.load_pandas().data\n# Keep just working women\ndt = dt.query(\"lfp\")\n# Create unlogged earnings\ndt.loc[:, \"earn\"] = dt[\"lwg\"].apply(\"exp\")\n\n# 5. Run multiple linear regression models by succesively adding controls\nfit = pf.feols(fml=\"lwg ~ csw(inc, wc, k5)\", data=dt, vcov=\"iid\")\nfit.summary()\n\n###\n\nEstimation:  OLS\nDep. var.: lwg, Fixed effects: \nInference:  iid\nObservations:  428\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| Intercept     |      1.007 |        0.071 |    14.180 |      0.000 |  0.868 |   1.147 |\n| inc           |      0.010 |        0.003 |     2.947 |      0.003 |  0.003 |   0.016 |\n---\nRMSE: 0.715 R2: 0.02 \n###\n\nEstimation:  OLS\nDep. var.: lwg, Fixed effects: \nInference:  iid\nObservations:  428\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| Intercept     |      0.972 |        0.070 |    13.909 |      0.000 |  0.834 |   1.109 |\n| inc           |      0.005 |        0.003 |     1.640 |      0.102 | -0.001 |   0.012 |\n| wc            |      0.342 |        0.075 |     4.595 |      0.000 |  0.196 |   0.489 |\n---\nRMSE: 0.698 R2: 0.066 \n###\n\nEstimation:  OLS\nDep. var.: lwg, Fixed effects: \nInference:  iid\nObservations:  428\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| Intercept     |      0.982 |        0.071 |    13.819 |      0.000 |  0.843 |   1.122 |\n| inc           |      0.005 |        0.003 |     1.590 |      0.113 | -0.001 |   0.012 |\n| wc            |      0.349 |        0.075 |     4.656 |      0.000 |  0.202 |   0.497 |\n| k5            |     -0.072 |        0.087 |    -0.825 |      0.410 | -0.243 |   0.099 |\n---\nRMSE: 0.697 R2: 0.068 \n\n\nC:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_14196\\865424107.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  dt.loc[:, \"earn\"] = dt[\"lwg\"].apply(\"exp\")"
  },
  {
    "objectID": "replicating-the-effect.html#chapter-13-regression",
    "href": "replicating-the-effect.html#chapter-13-regression",
    "title": "Replicating Examples from ‚ÄúThe Effect‚Äù",
    "section": "Chapter 13: Regression",
    "text": "Chapter 13: Regression\n\nExample 1\n\nres = restaurant_inspections.load_pandas().data\nres.inspection_score = res.inspection_score.astype(float)\nres.NumberofLocations = res.NumberofLocations.astype(float)\nres.dtypes\n\nfit = pf.feols(fml=\"inspection_score ~ NumberofLocations\", data=res)\npf.summary(fit)\n\n###\n\nEstimation:  OLS\nDep. var.: inspection_score, Fixed effects: \nInference:  iid\nObservations:  27178\n\n| Coefficient       |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:------------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| Intercept         |     94.866 |        0.046 |  2049.047 |      0.000 | 94.775 |  94.956 |\n| NumberofLocations |     -0.019 |        0.000 |   -43.321 |      0.000 | -0.020 |  -0.018 |\n---\nRMSE: 6.051 R2: 0.065 \n\n\n\n\nExample 2\n\ndf = restaurant_inspections.load_pandas().data\n\nfit1 = pf.feols(\n    fml=\"inspection_score ~ NumberofLocations + I(NumberofLocations^2) + Year\", data=df\n)\nfit2 = pf.feols(fml=\"inspection_score ~ NumberofLocations*Weekend + Year\", data=df)\n\npf.etable([fit1, fit2])\n\n\n\n\n\n\nTable¬†1: Significance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell: Coefficient (Std. Error)\n\n\n\n\n\n\nest1\nest2\n\n\n\n\ndepvar\ninspection_score\ninspection_score\n\n\nIntercept\n225.504*** (12.409)\n225.126*** (12.415)\n\n\nNumberofLocations\n-0.075*** (0.019)\n-0.019*** (0.000)\n\n\nI(NumberofLocations ^ 2)\n0.056** (0.019)\n\n\n\nYear\n-0.065*** (0.006)\n-0.065*** (0.006)\n\n\nWeekend\n\n1.759*** (0.488)\n\n\nNumberofLocations:Weekend\n\n-0.010 (0.008)\n\n\nR2\n0.069\n0.069\n\n\nS.E. type\niid\niid\n\n\nObservations\n27178\n27178\n\n\n\n\n\n\n\n\n\n\nExample 3: HC Standard Errors\n\npf.feols(fml=\"inspection_score ~ Year + Weekend\", data=df, vcov=\"HC3\").summary()\n\n###\n\nEstimation:  OLS\nDep. var.: inspection_score, Fixed effects: \nInference:  HC3\nObservations:  27178\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |    2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|--------:|\n| Intercept     |    185.380 |       12.150 |    15.257 |      0.000 | 161.565 | 209.195 |\n| Year          |     -0.046 |        0.006 |    -7.551 |      0.000 |  -0.057 |  -0.034 |\n| Weekend       |      2.057 |        0.353 |     5.829 |      0.000 |   1.365 |   2.749 |\n---\nRMSE: 6.248 R2: 0.003 \n\n\n\n\nExample 4: Clustered Standard Errors\n\npf.feols(\n    fml=\"inspection_score ~ Year + Weekend\", data=df, vcov={\"CRV1\": \"Weekend\"}\n).tidy()\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n2.5%\n97.5%\n\n\nCoefficient\n\n\n\n\n\n\n\n\n\n\nIntercept\n185.380033\n3.264345\n56.789343\n0.011209\n143.902592\n226.857474\n\n\nYear\n-0.045640\n0.001624\n-28.107556\n0.022640\n-0.066272\n-0.025008\n\n\nWeekend\n2.057166\n0.001401\n1468.256799\n0.000434\n2.039364\n2.074969\n\n\n\n\n\n\n\n\n\nExample 5: Bootstrap Inference\n\nfit = pf.feols(fml=\"inspection_score ~ Year + Weekend\", data=df)\nfit.wildboottest(reps=999, param=\"Year\")\n\nparam                Year\nt value          -7.55233\nPr(&gt;|t|)              0.0\nbootstrap_type         11\ninference              HC\nimpose_null          True\ndtype: object"
  },
  {
    "objectID": "replicating-the-effect.html#chapter-16-fixed-effects",
    "href": "replicating-the-effect.html#chapter-16-fixed-effects",
    "title": "Replicating Examples from ‚ÄúThe Effect‚Äù",
    "section": "Chapter 16: Fixed Effects",
    "text": "Chapter 16: Fixed Effects\n\nExample 1\ntba\n\n\nExample 2\n\ngm = gapminder.load_pandas().data\ngm[\"logGDPpercap\"] = gm[\"gdpPercap\"].apply(\"log\")\n\nfit = pf.feols(fml=\"lifeExp ~ C(country) + np.log(gdpPercap)\", data=gm)\nfit.tidy().head()\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n2.5%\n97.5%\n\n\nCoefficient\n\n\n\n\n\n\n\n\n\n\nIntercept\n-27.773459\n2.500533\n-11.107015\n0.000000e+00\n-32.678217\n-22.868701\n\n\nC(country)[T.Albania]\n17.782625\n2.195160\n8.100835\n1.110223e-15\n13.476853\n22.088397\n\n\nC(country)[T.Algeria]\n5.241055\n2.214496\n2.366704\n1.806875e-02\n0.897356\n9.584755\n\n\nC(country)[T.Angola]\n-13.907122\n2.201727\n-6.316460\n3.481857e-10\n-18.225777\n-9.588468\n\n\nC(country)[T.Argentina]\n8.132158\n2.272781\n3.578065\n3.567229e-04\n3.674133\n12.590183\n\n\n\n\n\n\n\n\n\nExample 3: TWFE\n\n# Set our individual and time (index) for our data\nfit = pf.feols(fml=\"lifeExp ~ np.log(gdpPercap) | country + year\", data=gm)\nfit.summary()\n\n###\n\nEstimation:  OLS\nDep. var.: lifeExp, Fixed effects: country+year\nInference:  CRV1\nObservations:  1704\n\n| Coefficient       |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:------------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| np.log(gdpPercap) |      1.450 |        0.677 |     2.141 |      0.034 |  0.111 |   2.788 |\n---\nRMSE: 3.267 R2: 0.936 R2 Within: 0.019"
  },
  {
    "objectID": "replicating-the-effect.html#chapter-18-difference-in-differences",
    "href": "replicating-the-effect.html#chapter-18-difference-in-differences",
    "title": "Replicating Examples from ‚ÄúThe Effect‚Äù",
    "section": "Chapter 18: Difference-in-Differences",
    "text": "Chapter 18: Difference-in-Differences\n\nExample 1\n\nod = organ_donations.load_pandas().data\n\n# Create Treatment Variable\nod[\"California\"] = od[\"State\"] == \"California\"\nod[\"After\"] = od[\"Quarter_Num\"] &gt; 3\nod[\"Treated\"] = 1 * (od[\"California\"] & od[\"After\"])\n\ndid = pf.feols(fml=\"Rate ~ Treated | State + Quarter\", data=od)\ndid.summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Rate, Fixed effects: State+Quarter\nInference:  CRV1\nObservations:  162\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| Treated       |     -0.022 |        0.006 |    -3.733 |      0.001 | -0.035 |  -0.010 |\n---\nRMSE: 0.022 R2: 0.979 R2 Within: 0.009 \n\n\n\n\nExample 3: Dynamic Treatment Effect\n\nod = organ_donations.load_pandas().data\n\n# Create Treatment Variable\nod[\"California\"] = od[\"State\"] == \"California\"\n# od[\"Quarter_Num\"] = pd.Categorical(od.Quarter_Num)\nod[\"California\"] = od.California.astype(float)\n\ndid2 = pf.feols(\n    fml=\"Rate ~ i(Quarter_Num, California,ref=3) | State + Quarter_Num\", data=od\n)\n\ndid2.tidy()\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n2.5%\n97.5%\n\n\nCoefficient\n\n\n\n\n\n\n\n\n\n\nC(Quarter_Num, contr.treatment(base=3))[T.1]:California\n-0.002942\n0.004986\n-0.590105\n0.560215\n-0.013191\n0.007307\n\n\nC(Quarter_Num, contr.treatment(base=3))[T.2]:California\n0.006296\n0.002222\n2.833502\n0.008782\n0.001729\n0.010864\n\n\nC(Quarter_Num, contr.treatment(base=3))[T.4]:California\n-0.021565\n0.004937\n-4.368464\n0.000178\n-0.031713\n-0.011418\n\n\nC(Quarter_Num, contr.treatment(base=3))[T.5]:California\n-0.020292\n0.004387\n-4.625529\n0.000090\n-0.029310\n-0.011275\n\n\nC(Quarter_Num, contr.treatment(base=3))[T.6]:California\n-0.022165\n0.009820\n-2.257160\n0.032627\n-0.042351\n-0.001980"
  },
  {
    "objectID": "difference-in-differences.html",
    "href": "difference-in-differences.html",
    "title": "Difference-in-Differences Estimation",
    "section": "",
    "text": "PyFixest supports event study designs via the canonical two-way fixed effects design, the 2-Step imputation estimator, and local projections.\nSee also NBER SI methods lectures on Linear Panel Event Studies.\n\nfrom importlib import resources\n\nimport pandas as pd\n\nimport pyfixest as pf\nfrom pyfixest.did.estimation import did2s, lpdid\nfrom pyfixest.did.visualize import panelview\nfrom pyfixest.report.utils import rename_event_study_coefs\nfrom pyfixest.utils.dgps import get_sharkfin\n\n%load_ext watermark\n%watermark --iversions\n\n\n            \n            \n            \n\n\n\n            \n            \n            \n\n\npyfixest: 0.24.0\npandas  : 2.2.2\n\n\n\n\n# one-shot adoption data - parallel trends is true\ndf_one_cohort = get_sharkfin()\ndf_one_cohort.head()\n\n\n\n\n\n\n\n\nunit\nyear\ntreat\nY\never_treated\n\n\n\n\n0\n0\n0\n0\n1.629307\n0\n\n\n1\n0\n1\n0\n0.825902\n0\n\n\n2\n0\n2\n0\n0.208988\n0\n\n\n3\n0\n3\n0\n-0.244739\n0\n\n\n4\n0\n4\n0\n0.804665\n0\n\n\n\n\n\n\n\n\n# multi-cohort adoption data\ndf_multi_cohort = pd.read_csv(\n    resources.files(\"pyfixest.did.data\").joinpath(\"df_het.csv\")\n)\ndf_multi_cohort.head()\n\n\n\n\n\n\n\n\nunit\nstate\ngroup\nunit_fe\ng\nyear\nyear_fe\ntreat\nrel_year\nrel_year_binned\nerror\nte\nte_dynamic\ndep_var\n\n\n\n\n0\n1\n33\nGroup 2\n7.043016\n2010\n1990\n0.066159\nFalse\n-20.0\n-6\n-0.086466\n0\n0.0\n7.022709\n\n\n1\n1\n33\nGroup 2\n7.043016\n2010\n1991\n-0.030980\nFalse\n-19.0\n-6\n0.766593\n0\n0.0\n7.778628\n\n\n2\n1\n33\nGroup 2\n7.043016\n2010\n1992\n-0.119607\nFalse\n-18.0\n-6\n1.512968\n0\n0.0\n8.436377\n\n\n3\n1\n33\nGroup 2\n7.043016\n2010\n1993\n0.126321\nFalse\n-17.0\n-6\n0.021870\n0\n0.0\n7.191207\n\n\n4\n1\n33\nGroup 2\n7.043016\n2010\n1994\n-0.106921\nFalse\n-16.0\n-6\n-0.017603\n0\n0.0\n6.918492\n\n\n\n\n\n\n\n\nExamining Treatment Timing\nBefore any DiD estimation, we need to examine the treatment timing, since it is crucial to our choice of estimator.\n\npanelview(\n    df_one_cohort,\n    unit=\"unit\",\n    time=\"year\",\n    treat=\"treat\",\n    collapse_to_cohort=True,\n    sort_by_timing=True,\n    ylab=\"Cohort\",\n    xlab=\"Year\",\n    title=\"Treatment Assignment Cohorts\",\n)\n\n\n\n\n\n\n\n\n\npanelview(\n    df_multi_cohort,\n    unit=\"unit\",\n    time=\"year\",\n    treat=\"treat\",\n    collapse_to_cohort=True,\n    sort_by_timing=True,\n    ylab=\"Cohort\",\n    xlab=\"Year\",\n    title=\"Treatment Assignment Cohorts\",\n)\n\n\n\n\n\n\n\n\nWe immediately see that we have staggered adoption of treatment in the second case, which implies that a naive application of 2WFE might yield biased estimates under substantial effect heterogeneity.\nWe can also plot treatment assignment in a disaggregated fashion, which gives us a sense of cohort sizes.\n\npanelview(\n    df_multi_cohort,\n    unit=\"unit\",\n    time=\"year\",\n    treat=\"treat\",\n    sort_by_timing=True,\n    ylab=\"Unit\",\n    xlab=\"Year\",\n    title=\"Treatment Assignment (all units)\",\n)\n\n\n\n\n\n\n\n\n\n\nOne-shot adoption: Static and Dynamic Specifications\n\nfit_static_twfe = pf.feols(\n    \"Y ~ treat | unit + year\",\n    df_one_cohort,\n    vcov={\"CRV1\": \"unit\"},\n)\nfit_static_twfe.summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: unit+year\nInference:  CRV1\nObservations:  30000\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| treat         |      0.206 |        0.052 |     3.929 |      0.000 |  0.103 |   0.308 |\n---\nRMSE: 0.701 R2: 0.905 R2 Within: 0.003 \n\n\nSince this is a single-cohort dataset, this estimate is consistent for the ATT under parallel trends. We can estimate heterogeneous effects by time by interacting time with the treated group:\n\nfit_dynamic_twfe = pf.feols(\n    \"Y ~ i(year, ever_treated,  ref = 14) | unit + year\",\n    df_one_cohort,\n    vcov={\"CRV1\": \"unit\"},\n)\n\n\nfit_dynamic_twfe.iplot(\n    coord_flip=False,\n    title=\"Event Study\",\n    figsize=[1200, 400],\n    yintercept=0,\n    xintercept=13.5,\n    labels=rename_event_study_coefs(fit_dynamic_twfe._coefnames),\n)\n\n   \n   \n\n\nEvent study plots like this are very informative, as they allow us to visually inspect the parallel trends assumption and also the dynamic effects of the treatment.\nBased on a cursory glance, one would conclude that parallel trends does not hold because one of the pre-treatment coefficient has a confidence interval that does not include zero. However, we know that parallel trends is true because the treatment is randomly assigned in the underlying DGP.\n\nPointwise vs Simultaneous Inference in Event Studies\nThis is an example of a false positive in testing for pre-trends produced by pointwise inference (where each element of the coefficient vector is tested separately).\nAs an alternative, we can use simultaneous confidence bands of the form \\([a, b] = ([a_k, b_k])_{k=1}^K\\) such that\n\\[\nP(\\beta \\in [a, b]) = P(\\beta_k \\in [a_k, b_k] \\forall k) \\rightarrow 1 - \\alpha\n\\]\nThese bands can be constructed by using a carefully chosen critical value \\(c\\) that accounts for the covariance between coefficients using the multiplier bootstrap. In pointwise inference, the critical value is \\(c = z_{1 - \\alpha/2} = 1.96\\) for \\(\\alpha = 0.05\\); the corresponding critical value for simultaneous inference is typically larger. These are also known as sup-t bands in the literature (see lec 3 of the NBER SI methods lectures linked above).\nThis is implemented in the confint(joint=True) method in the feols class. If we pass the joint='both' argument to iplot, we get the simultaneous confidence bands (for all event study coefficients) in addition to the pointwise confidence intervals. Note that simultaneous inference for all event study coefficients may be overly conservative, especially when the number of coefficients is large; one may instead choose to perform joint inference for all pre-treatment coefficients and all post-treatment coefficients separately.\n\nfit_dynamic_twfe.iplot(\n    coord_flip=False,\n    title=\"Event Study\",\n    figsize=[1200, 400],\n    yintercept=0,\n    xintercept=13.5,\n    joint=\"both\",\n    labels=rename_event_study_coefs(fit_dynamic_twfe._coefnames),\n)\n\n   \n   \n\n\nThe joint confidence bands are wider than the pointwise confidence intervals, and they include zero for all pre-treatment coefficients. This is consistent with the parallel trends assumption.\n\n\n\nEvent Study under Staggered Adoption via feols(), did2s() and lpdid()\nWe can estimate a simple two-way fixed effects DiD regression via feols():\n\nfit_twfe = pf.feols(\n    \"dep_var ~ i(rel_year, ref=-1.0) | state + year\",\n    df_multi_cohort,\n    vcov={\"CRV1\": \"state\"},\n)\n\nTo do the same via Gardners 2-stage estimator, we employ the the did2s() function:\n\nfit_did2s = did2s(\n    df_multi_cohort,\n    yname=\"dep_var\",\n    first_stage=\"~ 0 | state + year\",\n    second_stage=\"~i(rel_year,ref=-1.0)\",\n    treatment=\"treat\",\n    cluster=\"state\",\n)\n\nLast, we can estimate the ATT for each time period via local projections by using the lpdid() function:\n\nfit_lpdid = lpdid(\n    data=df_multi_cohort,\n    yname=\"dep_var\",\n    gname=\"g\",\n    tname=\"year\",\n    idname=\"unit\",\n    vcov={\"CRV1\": \"state\"},\n    pre_window=-20,\n    post_window=20,\n    att=False,\n)\n\nLet‚Äôs look at some results:\n\nfigsize = [1200, 400]\n\n\nfit_twfe.iplot(\n    coord_flip=False,\n    title=\"TWFE-Estimator\",\n    figsize=figsize,\n    xintercept=18.5,\n    yintercept=0,\n    labels=rename_event_study_coefs(fit_twfe._coefnames),  # rename coefficients\n).show()\n\n   \n   \n\n\n\nfit_did2s.iplot(\n    coord_flip=False,\n    title=\"DID2s-Estimator\",\n    figsize=figsize,\n    xintercept=18.5,\n    yintercept=0,\n    labels=rename_event_study_coefs(fit_twfe._coefnames),\n).show()\n\n   \n   \n\n\n\nfit_lpdid.iplot(\n    coord_flip=False,\n    title=\"Local-Projections-Estimator\",\n    figsize=figsize,\n    yintercept=0,\n    xintercept=18.5,\n).show()\n\n   \n   \n\n\nWhat if we are not interested in the ATT per treatment period, but in a pooled effects?\n\nfit_twfe = pf.feols(\n    \"dep_var ~ i(treat) | unit + year\",\n    df_multi_cohort,\n    vcov={\"CRV1\": \"state\"},\n)\n\nfit_did2s = did2s(\n    df_multi_cohort,\n    yname=\"dep_var\",\n    first_stage=\"~ 0 | unit + year\",\n    second_stage=\"~i(treat)\",\n    treatment=\"treat\",\n    cluster=\"state\",\n)\n\nfit_lpdid = lpdid(\n    data=df_multi_cohort,\n    yname=\"dep_var\",\n    gname=\"g\",\n    tname=\"year\",\n    idname=\"unit\",\n    vcov={\"CRV1\": \"state\"},\n    pre_window=-20,\n    post_window=20,\n    att=True,\n)\npd.concat(\n    [\n        fit_twfe.tidy().assign(estimator=\"TWFE\"),\n        fit_did2s.tidy().assign(estimator=\"DID2s\"),\n        fit_lpdid.tidy().assign(estimator=\"LPDID\").drop(\"N\", axis=1),\n    ],\n    axis=0,\n)\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n2.5%\n97.5%\nestimator\n\n\n\n\nC(treat)[T.True]\n1.982540\n0.019331\n102.556180\n0.0\n1.943439\n2.021642\nTWFE\n\n\nC(treat)[T.True]\n2.230482\n0.024709\n90.271437\n0.0\n2.182054\n2.278910\nDID2s\n\n\ntreat_diff\n2.506746\n0.071357\n35.129648\n0.0\n2.362413\n2.651080\nLPDID"
  },
  {
    "objectID": "quickstart.html",
    "href": "quickstart.html",
    "title": "Getting Started with PyFixest",
    "section": "",
    "text": "A fixed effect model is a statistical model that includes fixed effects, which are parameters that are estimated to be constant across different groups.\nExample [Panel Data]: In the context of panel data, fixed effects are parameters that are constant across different individuals or time. The typical model example is given by the following equation:\n\\[\nY_{it} = \\beta X_{it} + \\alpha_i + \\psi_t + \\varepsilon_{it}\n\\]\nwhere \\(Y_{it}\\) is the dependent variable for individual \\(i\\) at time \\(t\\), \\(X_{it}\\) is the independent variable, \\(\\beta\\) is the coefficient of the independent variable, \\(\\alpha_i\\) is the individual fixed effect, \\(\\psi_t\\) is the time fixed effect, and \\(\\varepsilon_{it}\\) is the error term. The individual fixed effect \\(\\alpha_i\\) is a parameter that is constant across time for each individual, while the time fixed effect \\(\\psi_t\\) is a parameter that is constant across individuals for each time period.\nNote however that, despite the fact that fixed effects are commonly used in panel setting, one does not need a panel data set to work with fixed effects. For example, cluster randomized trials with cluster fixed effects, or wage regressions with worker and firm fixed effects.\nIn this ‚Äúquick start‚Äù guide, we will show you how to estimate a fixed effect model using the PyFixest package. We do not go into the details of the theory behind fixed effect models, but we focus on how to estimate them using PyFixest."
  },
  {
    "objectID": "quickstart.html#what-is-a-fixed-effect-model",
    "href": "quickstart.html#what-is-a-fixed-effect-model",
    "title": "Getting Started with PyFixest",
    "section": "",
    "text": "A fixed effect model is a statistical model that includes fixed effects, which are parameters that are estimated to be constant across different groups.\nExample [Panel Data]: In the context of panel data, fixed effects are parameters that are constant across different individuals or time. The typical model example is given by the following equation:\n\\[\nY_{it} = \\beta X_{it} + \\alpha_i + \\psi_t + \\varepsilon_{it}\n\\]\nwhere \\(Y_{it}\\) is the dependent variable for individual \\(i\\) at time \\(t\\), \\(X_{it}\\) is the independent variable, \\(\\beta\\) is the coefficient of the independent variable, \\(\\alpha_i\\) is the individual fixed effect, \\(\\psi_t\\) is the time fixed effect, and \\(\\varepsilon_{it}\\) is the error term. The individual fixed effect \\(\\alpha_i\\) is a parameter that is constant across time for each individual, while the time fixed effect \\(\\psi_t\\) is a parameter that is constant across individuals for each time period.\nNote however that, despite the fact that fixed effects are commonly used in panel setting, one does not need a panel data set to work with fixed effects. For example, cluster randomized trials with cluster fixed effects, or wage regressions with worker and firm fixed effects.\nIn this ‚Äúquick start‚Äù guide, we will show you how to estimate a fixed effect model using the PyFixest package. We do not go into the details of the theory behind fixed effect models, but we focus on how to estimate them using PyFixest."
  },
  {
    "objectID": "quickstart.html#read-sample-data",
    "href": "quickstart.html#read-sample-data",
    "title": "Getting Started with PyFixest",
    "section": "Read Sample Data",
    "text": "Read Sample Data\nIn a first step, we load the module and some synthetic example data:\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom lets_plot import LetsPlot\n\nimport pyfixest as pf\nfrom pyfixest.did.estimation import did2s\nfrom pyfixest.did.event_study import event_study\n\nLetsPlot.setup_html()\n\nplt.style.use(\"seaborn-v0_8\")\n\n%load_ext watermark\n%config InlineBackend.figure_format = \"retina\"\n%watermark --iversions\n\n\n            \n            \n            \n\n\n\n            \n            \n            \n\n\n\n            \n            \n            \n\n\npandas    : 2.2.2\nmatplotlib: 3.9.0\npyfixest  : 0.24.0\nnumpy     : 1.26.4\n\n\n\n\ndata = pf.get_data()\n\ndata.head()\n\n\n\n\n\n\n\n\nY\nY2\nX1\nX2\nf1\nf2\nf3\ngroup_id\nZ1\nZ2\nweights\n\n\n\n\n0\nNaN\n2.357103\n0.0\n0.457858\n15.0\n0.0\n7.0\n9.0\n-0.330607\n1.054826\n0.661478\n\n\n1\n-1.458643\n5.163147\nNaN\n-4.998406\n6.0\n21.0\n4.0\n8.0\nNaN\n-4.113690\n0.772732\n\n\n2\n0.169132\n0.751140\n2.0\n1.558480\nNaN\n1.0\n7.0\n16.0\n1.207778\n0.465282\n0.990929\n\n\n3\n3.319513\n-2.656368\n1.0\n1.560402\n1.0\n10.0\n11.0\n3.0\n2.869997\n0.467570\n0.021123\n\n\n4\n0.134420\n-1.866416\n2.0\n-3.472232\n19.0\n20.0\n6.0\n14.0\n0.835819\n-3.115669\n0.790815\n\n\n\n\n\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 11 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   Y         999 non-null    float64\n 1   Y2        1000 non-null   float64\n 2   X1        999 non-null    float64\n 3   X2        1000 non-null   float64\n 4   f1        999 non-null    float64\n 5   f2        1000 non-null   float64\n 6   f3        1000 non-null   float64\n 7   group_id  1000 non-null   float64\n 8   Z1        999 non-null    float64\n 9   Z2        1000 non-null   float64\n 10  weights   1000 non-null   float64\ndtypes: float64(11)\nmemory usage: 86.1 KB\n\n\nWe see that some of our columns have missing data."
  },
  {
    "objectID": "quickstart.html#ols-estimation",
    "href": "quickstart.html#ols-estimation",
    "title": "Getting Started with PyFixest",
    "section": "OLS Estimation",
    "text": "OLS Estimation\nWe are interested in the relation between the dependent variable Y and the independent variables X1 using a fixed effect model for group_id. Let‚Äôs see how the data looks like:\n\nax = data.plot(kind=\"scatter\", x=\"X1\", y=\"Y\", c=\"group_id\", colormap=\"viridis\")\n\n\n\n\n\n\n\n\nWe can estimate a fixed effects regression via the feols() function. feols() has three arguments: a two-sided model formula, the data, and optionally, the type of inference.\n\nfit = pf.feols(fml=\"Y ~ X1 | group_id\", data=data, vcov=\"HC1\")\ntype(fit)\n\npyfixest.estimation.feols_.Feols\n\n\nThe first part of the formula contains the dependent variable and ‚Äúregular‚Äù covariates, while the second part contains fixed effects.\nfeols() returns an instance of the Fixest class.\nTo inspect the results, we can use a summary function or method:\n\nfit.summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: group_id\nInference:  HC1\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -1.019 |        0.082 |   -12.352 |      0.000 | -1.181 |  -0.857 |\n---\nRMSE: 2.141 R2: 0.137 R2 Within: 0.126 \n\n\nAlternatively, the .summarize module contains a summary function, which can be applied on instances of regression model objects or lists of regression model objects.\n\npf.summary(fit)\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: group_id\nInference:  HC1\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -1.019 |        0.082 |   -12.352 |      0.000 | -1.181 |  -0.857 |\n---\nRMSE: 2.141 R2: 0.137 R2 Within: 0.126 \n\n\nYou can access individual elements of the summary via dedicated methods: .tidy() returns a ‚Äútidy‚Äù pd.DataFrame, .coef() returns estimated parameters, and se() estimated standard errors. Other methods include pvalue(), confint() and tstat().\n\nfit.coef()\n\nCoefficient\nX1   -1.019009\nName: Estimate, dtype: float64\n\n\n\nfit.se()\n\nCoefficient\nX1    0.082498\nName: Std. Error, dtype: float64"
  },
  {
    "objectID": "quickstart.html#how-to-interpret-the-results",
    "href": "quickstart.html#how-to-interpret-the-results",
    "title": "Getting Started with PyFixest",
    "section": "How to interpret the results?",
    "text": "How to interpret the results?\nLet‚Äôs have a quick d-tour on the intuition behind fixed effects models using the example above. To do so, let us begin by comparing it with a simple OLS model.\n\nfit_simple = pf.feols(\"Y ~ X1\", data=data, vcov=\"HC1\")\n\nfit_simple.summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: \nInference:  HC1\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| Intercept     |      0.919 |        0.112 |     8.223 |      0.000 |  0.699 |   1.138 |\n| X1            |     -1.000 |        0.082 |   -12.134 |      0.000 | -1.162 |  -0.838 |\n---\nRMSE: 2.158 R2: 0.123 \n\n\nWe see that the X1 coefficient is -1.0, which is less than the value from the OLS model above (which was 0.949). Where is the difference coming from? Well, in the fixed effect model we are interested in controlling for the feature group_id. One possibility to do this is by adding a simple dummy variable for each level of group_id.\n\nfit_dummy = pf.feols(\"Y ~ X1 + C(group_id) \", data=data, vcov=\"HC1\")\n\nfit_dummy.summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: \nInference:  HC1\nObservations:  998\n\n| Coefficient         |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| Intercept           |      0.760 |        0.288 |     2.640 |      0.008 |  0.195 |   1.326 |\n| X1                  |     -1.019 |        0.083 |   -12.234 |      0.000 | -1.182 |  -0.856 |\n| C(group_id)[T.1.0]  |      0.380 |        0.451 |     0.844 |      0.399 | -0.504 |   1.264 |\n| C(group_id)[T.2.0]  |      0.084 |        0.389 |     0.216 |      0.829 | -0.680 |   0.848 |\n| C(group_id)[T.3.0]  |      0.790 |        0.415 |     1.904 |      0.057 | -0.024 |   1.604 |\n| C(group_id)[T.4.0]  |     -0.189 |        0.388 |    -0.487 |      0.626 | -0.950 |   0.572 |\n| C(group_id)[T.5.0]  |      0.537 |        0.388 |     1.385 |      0.166 | -0.224 |   1.297 |\n| C(group_id)[T.6.0]  |      0.307 |        0.398 |     0.771 |      0.441 | -0.474 |   1.087 |\n| C(group_id)[T.7.0]  |      0.015 |        0.422 |     0.035 |      0.972 | -0.814 |   0.844 |\n| C(group_id)[T.8.0]  |      0.382 |        0.406 |     0.941 |      0.347 | -0.415 |   1.179 |\n| C(group_id)[T.9.0]  |      0.219 |        0.417 |     0.526 |      0.599 | -0.599 |   1.037 |\n| C(group_id)[T.10.0] |     -0.363 |        0.422 |    -0.861 |      0.390 | -1.191 |   0.465 |\n| C(group_id)[T.11.0] |      0.201 |        0.387 |     0.520 |      0.603 | -0.559 |   0.961 |\n| C(group_id)[T.12.0] |     -0.110 |        0.410 |    -0.268 |      0.788 | -0.915 |   0.694 |\n| C(group_id)[T.13.0] |      0.126 |        0.440 |     0.287 |      0.774 | -0.736 |   0.989 |\n| C(group_id)[T.14.0] |      0.353 |        0.416 |     0.848 |      0.397 | -0.464 |   1.170 |\n| C(group_id)[T.15.0] |      0.469 |        0.398 |     1.179 |      0.239 | -0.312 |   1.249 |\n| C(group_id)[T.16.0] |     -0.135 |        0.396 |    -0.340 |      0.734 | -0.913 |   0.643 |\n| C(group_id)[T.17.0] |     -0.005 |        0.401 |    -0.013 |      0.989 | -0.792 |   0.781 |\n| C(group_id)[T.18.0] |      0.283 |        0.403 |     0.702 |      0.483 | -0.508 |   1.074 |\n---\nRMSE: 2.141 R2: 0.137 \n\n\nThis is does not scale well! Imagine you have 1000 different levels of group_id. You would need to add 1000 dummy variables to your model. This is where fixed effect models come in handy. They allow you to control for these fixed effects without adding all these dummy variables. The way to do it is by a demeaning procedure. The idea is to subtract the average value of each level of group_id from the respective observations. This way, we control for the fixed effects without adding all these dummy variables. Let‚Äôs try to do this manually:\n\ndef _demean_column(df: pd.DataFrame, column: str, by: str) -&gt; pd.Series:\n    return df[column] - df.groupby(by)[column].transform(\"mean\")\n\n\nfit_demeaned = pf.feols(\n    fml=\"Y_demeaned ~ X1_demeaned\",\n    data=data.assign(\n        Y_demeaned=lambda df: _demean_column(df, \"Y\", \"group_id\"),\n        X1_demeaned=lambda df: _demean_column(df, \"X1\", \"group_id\"),\n    ),\n    vcov=\"HC1\",\n)\n\nfit_demeaned.summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Y_demeaned, Fixed effects: \nInference:  HC1\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| Intercept     |      0.003 |        0.068 |     0.041 |      0.968 | -0.130 |   0.136 |\n| X1_demeaned   |     -1.019 |        0.083 |   -12.345 |      0.000 | -1.181 |  -0.857 |\n---\nRMSE: 2.141 R2: 0.126 \n\n\nWe get the same results as the fixed effect model Y1 ~ X | group_id above. The PyFixest package uses a more efficient algorithm to estimate the fixed effect model, but the intuition is the same.\nUpdating Coefficients\nYou can update the coefficients of a model object via the update() method, which may be useful in an online learning setting where data arrives sequentially.\nTo see this in action, let us first fit a model on a subset of the data:\n\ndata_subsample = data.sample(frac=0.5)\nm = pf.feols(\"Y ~ X1 + X2\", data=data_subsample)\n# current coefficient vector\nm._beta_hat\n\narray([ 1.02366347, -1.11298171, -0.21211311])\n\n\nThen sample 5 new observations and update the model with the new data. The update rule is\n\\[\n\\hat{\\beta}_{n+1} = \\hat{\\beta}_n + (X_{n+1}' X_{n+1})^{-1} x_{n+1} + (y_{n+1} - x_{n+1} \\hat{\\beta}_n)\n\\]\nfor a new observation \\((x_{n+1}, y_{n+1})\\).\n\nnew_points_id = np.random.choice(list(set(data.index) - set(data_subsample.index)), 5)\nX_new, y_new = (\n    np.c_[np.ones(len(new_points_id)), data.loc[new_points_id][[\"X1\", \"X2\"]].values],\n    data.loc[new_points_id][\"Y\"].values,\n)\nm.update(X_new, y_new)\n\narray([ 0.96014103, -1.0794788 , -0.21216075])\n\n\nWe verify that we get the same results if we had estimated the model on the appended data.\n\npf.feols(\n    \"Y ~ X1 + X2\", data=data.loc[data_subsample.index.append(pd.Index(new_points_id))]\n).coef().values\n\narray([ 0.96014103, -1.0794788 , -0.21216075])"
  },
  {
    "objectID": "quickstart.html#standard-errors-and-inference",
    "href": "quickstart.html#standard-errors-and-inference",
    "title": "Getting Started with PyFixest",
    "section": "Standard Errors and Inference",
    "text": "Standard Errors and Inference\nSupported covariance types are ‚Äúiid‚Äù, ‚ÄúHC1-3‚Äù, CRV1 and CRV3 (up to two-way clustering).\nWhy do we have so many different types of standard errors?\nThe standard errors of the coefficients are crucial for inference. They tell us how certain we can be about the estimated coefficients. In the presence of heteroskedasticity (a situation which typically arises with cross-sectional data), the standard OLS standard errors are biased. The pyfixest package provides several types of standard errors that are robust to heteroskedasticity.\n\niid: assumes that the error variance is spherical, i.e.¬†errors are homoskedastic and not correlated (independent and identically distributed errors have a spherical error variance).\nHC1-3: heteroskedasticity-robust standard errors according to White (1980) and MacKinnon and White (1985). See Econometric Computing with HC and HAC Covariance Matrix Estimators from the sandwich package for more details.\nCRV1 and CRV3: cluster robust standard errors according to Cameron, Gelbach, and Miller (2011). See A Practitioner‚Äôs Guide to Cluster-Robust Inference. For CRV1 and CRV3 one should pass a dictionaty of the form {\"CRV1\": \"clustervar\"}.\n\nInference can be adjusted ‚Äúon-the-fly‚Äù via the .vcov() method:\n\nfit.vcov({\"CRV1\": \"group_id + f2\"}).summary()\n\nfit.vcov({\"CRV3\": \"group_id\"}).summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: group_id\nInference:  CRV1\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -1.019 |        0.121 |    -8.450 |      0.000 | -1.272 |  -0.766 |\n---\nRMSE: 2.141 R2: 0.137 R2 Within: 0.126 \n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: group_id\nInference:  CRV3\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -1.019 |        0.125 |    -8.179 |      0.000 | -1.281 |  -0.757 |\n---\nRMSE: 2.141 R2: 0.137 R2 Within: 0.126 \n\n\nThe estimated covariance matrix is available as an attribute of the Feols object called ._vcov.\nInference via the Wild Bootstrap\nIt is also possible to run a wild (cluster) bootstrap after estimation (via the wildboottest module, see MacKinnon, J. G., Nielsen, M. √ò., & Webb, M. D. (2023). Fast and reliable jackknife and bootstrap methods for cluster-robust inference. Journal of Applied Econometrics, 38(5), 671‚Äì694.):\n\nfit2 = pf.feols(fml=\"Y ~ X1\", data=data, vcov={\"CRV1\": \"group_id\"})\nfit2.wildboottest(param=\"X1\", reps=999)\n\nparam                             X1\nt value           -8.567586579080423\nPr(&gt;|t|)                         0.0\nbootstrap_type                    11\ninference              CRV(group_id)\nimpose_null                     True\ndtype: object\n\n\nThe Causal Cluster Variance Estimator\nAdditionally, PyFixest supports the causal cluster variance estimator following Abadie et al.¬†(2023). Let‚Äôs look into it with another data set:\n\ndf = pd.read_stata(\"http://www.damianclarke.net/stata/census2000_5pc.dta\")\n\ndf.head()\n\n\n\n\n\n\n\n\nln_earnings\neduc\nhours\nstate\ncollege\n\n\n\n\n0\n11.91839\n18.0\n50.0\n44.0\n1.0\n\n\n1\n11.48247\n11.0\n42.0\n44.0\n0.0\n\n\n2\n10.46310\n12.0\n42.0\n44.0\n0.0\n\n\n3\n10.22194\n13.0\n40.0\n44.0\n1.0\n\n\n4\n9.21034\n13.0\n8.0\n44.0\n1.0\n\n\n\n\n\n\n\nWe can take a look into the variables of interest:\n\naxes = df.plot.hist(column=[\"ln_earnings\"], by=[\"college\"])\n\n\n\n\n\n\n\n\nNow we can estimate the model ln_earnings ~ college where we cluster the standard errors at the state level:\n\nfit3 = pf.feols(\"ln_earnings ~ college\", vcov={\"CRV1\": \"state\"}, data=df)\nfit3.ccv(treatment=\"college\", pk=0.05, n_splits=2, seed=929)\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n2.5%\n97.5%\n\n\n\n\nCCV\n0.4656425903701483\n0.00348\n133.820078\n0.0\n0.458657\n0.472628\n\n\nCRV1\n0.465643\n0.027142\n17.155606\n0.0\n0.411152\n0.520133\n\n\n\n\n\n\n\nRandomization Inference\nYou can also conduct inference via randomization inference (see He√ü, Stata Journal 2017). PyFixest supports random and cluster random sampling.\n\nfit2.ritest(resampvar=\"X1=0\", reps=1000, cluster=\"group_id\")\n\nH0                                     X1=0\nri-type                     randomization-c\nEstimate                 -1.000085840074156\nPr(&gt;|t|)                                0.0\nStd. Error (Pr(&gt;|t|))                   0.0\n2.5% (Pr(&gt;|t|))                         0.0\n97.5% (Pr(&gt;|t|))                        0.0\nCluster                            group_id\ndtype: object\n\n\nMultiple Testing Corrections: Bonferroni and Romano-Wolf\nTo correct for multiple testing, p-values can be adjusted via either the Bonferroni or the method by Romano and Wolf (2005), see for example The Romano-Wolf Multiple Hypothesis Correction in Stata.\n\npf.bonferroni([fit, fit2], param=\"X1\").round(3)\n\n\n\n\n\n\n\n\nest0\nest1\n\n\n\n\nEstimate\n-1.019\n-1.000\n\n\nStd. Error\n0.125\n0.117\n\n\nt value\n-8.179\n-8.568\n\n\nPr(&gt;|t|)\n0.000\n0.000\n\n\n2.5%\n-1.281\n-1.245\n\n\n97.5%\n-0.757\n-0.755\n\n\nBonferroni Pr(&gt;|t|)\n0.000\n0.000\n\n\n\n\n\n\n\n\npf.rwolf([fit, fit2], param=\"X1\", reps=9999, seed=1234).round(3)\n\n\n\n\n\n\n\n\nest0\nest1\n\n\n\n\nEstimate\n-1.019\n-1.000\n\n\nStd. Error\n0.125\n0.117\n\n\nt value\n-8.179\n-8.568\n\n\nPr(&gt;|t|)\n0.000\n0.000\n\n\n2.5%\n-1.281\n-1.245\n\n\n97.5%\n-0.757\n-0.755\n\n\nRW Pr(&gt;|t|)\n0.000\n0.000\n\n\n\n\n\n\n\nJoint Confidence Intervals\nSimultaneous confidence bands for a vector of parameters can be computed via the joint_confint() method. See Simultaneous confidence bands: Theory, implementation, and an application to SVARs for background.\n\nfit_ci = pf.feols(\"Y ~ X1+ C(f1)\", data=data)\nfit_ci.confint(joint=True).head()\n\n\n\n\n\n\n\n\n2.5%\n97.5%\n\n\n\n\nIntercept\n-0.427593\n1.405504\n\n\nX1\n-1.161113\n-0.737769\n\n\nC(f1)[T.1.0]\n1.382065\n3.783234\n\n\nC(f1)[T.2.0]\n-2.841141\n-0.322727\n\n\nC(f1)[T.3.0]\n-1.610678\n0.986011"
  },
  {
    "objectID": "quickstart.html#panel-data-example-causal-inference-for-the-brave-and-true",
    "href": "quickstart.html#panel-data-example-causal-inference-for-the-brave-and-true",
    "title": "Getting Started with PyFixest",
    "section": "Panel Data Example: Causal Inference for the Brave and True",
    "text": "Panel Data Example: Causal Inference for the Brave and True\nIn this example we replicate the results of the great (freely available reference!) Causal Inference for the Brave and True - Chapter 14. Please refer to the original text for a detailed explanation of the data.\n\ndata_path = \"https://raw.githubusercontent.com/bashtage/linearmodels/main/linearmodels/datasets/wage_panel/wage_panel.csv.bz2\"\ndata_df = pd.read_csv(data_path)\n\ndata_df.head()\n\n\n\n\n\n\n\n\nnr\nyear\nblack\nexper\nhisp\nhours\nmarried\neduc\nunion\nlwage\nexpersq\noccupation\n\n\n\n\n0\n13\n1980\n0\n1\n0\n2672\n0\n14\n0\n1.197540\n1\n9\n\n\n1\n13\n1981\n0\n2\n0\n2320\n0\n14\n1\n1.853060\n4\n9\n\n\n2\n13\n1982\n0\n3\n0\n2940\n0\n14\n0\n1.344462\n9\n9\n\n\n3\n13\n1983\n0\n4\n0\n2960\n0\n14\n0\n1.433213\n16\n9\n\n\n4\n13\n1984\n0\n5\n0\n3071\n0\n14\n0\n1.568125\n25\n5\n\n\n\n\n\n\n\nThe objective is to estimate the effect of the variable married on the variable lwage using a fixed effect model on the entity variable nr and the time variable year.\n\npanel_fit = pf.feols(\n    fml=\"lwage ~ expersq + union + married + hours | nr + year\",\n    data=data_df,\n    vcov={\"CRV1\": \"nr + year\"},\n)\n\npanel_fit.summary()\n\n###\n\nEstimation:  OLS\nDep. var.: lwage, Fixed effects: nr+year\nInference:  CRV1\nObservations:  4360\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| expersq       |     -0.006 |        0.001 |    -8.157 |      0.000 | -0.008 |  -0.004 |\n| union         |      0.073 |        0.023 |     3.189 |      0.015 |  0.019 |   0.127 |\n| married       |      0.048 |        0.018 |     2.694 |      0.031 |  0.006 |   0.089 |\n| hours         |     -0.000 |        0.000 |    -3.830 |      0.006 | -0.000 |  -0.000 |\n---\nRMSE: 0.324 R2: 0.631 R2 Within: 0.047 \n\n\nWe obtain the same results as in the book!"
  },
  {
    "objectID": "quickstart.html#instrumental-variables-iv-estimation",
    "href": "quickstart.html#instrumental-variables-iv-estimation",
    "title": "Getting Started with PyFixest",
    "section": "Instrumental Variables (IV) Estimation",
    "text": "Instrumental Variables (IV) Estimation\nIt is also possible to estimate instrumental variable models with one endogenous variable and (potentially multiple) instruments.\nIn general, the syntax for IV is depvar ~ exog.vars | fixef effects | endog.vars ~ instruments.\n\niv_fit = pf.feols(fml=\"Y2 ~ 1 | f1 + f2 | X1 ~ Z1 + Z2\", data=data)\niv_fit.summary()\n\n###\n\nEstimation:  IV\nDep. var.: Y2, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -1.600 |        0.333 |    -4.801 |      0.000 | -2.282 |  -0.919 |\n---\n\n\n\nIf the model does not contain any fixed effects, just drop the second part of the formula above:\n\npf.feols(fml=\"Y ~ 1 | X1 ~ Z1 + Z2\", data=data).summary()\n\n###\n\nEstimation:  IV\nDep. var.: Y, Fixed effects: \nInference:  iid\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| Intercept     |      0.911 |        0.156 |     5.843 |      0.000 |  0.605 |   1.217 |\n| X1            |     -0.993 |        0.134 |    -7.398 |      0.000 | -1.256 |  -0.730 |\n---\n\n\n\nYou can access the first stage regression object via the ._model_1st_stage attribute:\n\npf.etable([iv_fit._model_1st_stage, iv_fit])\n\n\n\n\n\n\n\n\n\n\n\n\n\nY\nY2\n\n\n(1)\n(2)\n\n\n\n\ncoef\n\n\nZ1\n0.403***\n(0.011)\n\n\n\nZ2\n-0.003\n(0.006)\n\n\n\nX1\n\n-1.600***\n(0.333)\n\n\nfe\n\n\nf1\nx\nx\n\n\nf2\nx\nx\n\n\nmodelstats\n\n\nObservations\n996\n998\n\n\nS.E. type\nby: f1\nby: f1\n\n\nR2\n0.425\n-\n\n\n\nSignificance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell: Coefficient (Std. Error)\n\n\n\n\n\n\n\n        \n\n\nYou can access the F-Statistic of the first stage via the _f_stat_1st_stage attribute:\n\niv_fit._f_stat_1st_stage\n\n692.3044112624756\n\n\nVia the IV_Diag method, you can compute additional IV Diagnostics, as the effective F-statistic following Olea & Pflueger (2013):\n\niv_fit.IV_Diag()\niv_fit._eff_F\n\n533.5670484892216\n\n\nIV estimation with multiple endogenous variables and multiple estimation syntax is currently not supported."
  },
  {
    "objectID": "quickstart.html#poisson-regression",
    "href": "quickstart.html#poisson-regression",
    "title": "Getting Started with PyFixest",
    "section": "Poisson Regression",
    "text": "Poisson Regression\nIt is possible to estimate Poisson Regressions (for example, to model count data). We can showcase this feature with another synthetic data set.\n\npois_data = pf.get_data(model=\"Fepois\")\n\nax = pois_data.plot(\n    kind=\"scatter\",\n    x=\"X1\",\n    y=\"Y\",\n    c=\"group_id\",\n    colormap=\"viridis\",\n    s=\"f2\",\n)\n\n\n\n\n\n\n\n\n\npois_fit = pf.fepois(fml=\"Y ~ X1 | group_id\", data=pois_data, vcov={\"CRV1\": \"group_id\"})\npois_fit.summary()\n\n###\n\nEstimation:  Poisson\nDep. var.: Y, Fixed effects: group_id\nInference:  CRV1\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |      0.004 |        0.032 |     0.119 |      0.905 | -0.060 |   0.067 |\n---\nDeviance: 1126.202"
  },
  {
    "objectID": "quickstart.html#tests-of-multiple-hypothesis-wald-tests",
    "href": "quickstart.html#tests-of-multiple-hypothesis-wald-tests",
    "title": "Getting Started with PyFixest",
    "section": "Tests of Multiple Hypothesis / Wald Tests",
    "text": "Tests of Multiple Hypothesis / Wald Tests\nYou can test multiple hypotheses simultaneously via the wald_test method.\n\nfit = pf.feols(\"Y ~ X1 + X2 | f1\", data=data)\n\nFor example, to test the joint null hypothesis of \\(X_{1} = 0\\) and \\(X_{2} = 0\\) vs the alternative that \\(X_{1} \\neq 0\\) or \\(X_{2} \\neq 0\\), we would run\n\nfit.wald_test(R=np.eye(2))\n\nstatistic    1.464780e+02\npvalue       6.661338e-16\ndtype: float64\n\n\nAlternatively, suppose we wanted to test a more complicated joint null hypothesis: \\(X_{1} + 2X_{2} = 2.0\\) and \\(X_{2} = 1.0\\). To do so, we would define \\(R\\) and \\(q\\) as\n\nR1 = np.array([[1, 2], [0, 1]])\nq1 = np.array([2.0, 1.0])\nfit.wald_test(R=R1, q=q1)\n\nc:\\Users\\alexa\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pyfixest-pKOwcWPT-py3.10\\lib\\site-packages\\pyfixest\\estimation\\feols_.py:927: UserWarning: Distribution changed to chi2, as R is not an identity matrix and q is not a zero vector.\n  warnings.warn(\n\n\nstatistic    4273.462101\npvalue          0.000000\ndtype: float64"
  },
  {
    "objectID": "quickstart.html#multiple-estimation",
    "href": "quickstart.html#multiple-estimation",
    "title": "Getting Started with PyFixest",
    "section": "Multiple Estimation",
    "text": "Multiple Estimation\nPyFixest supports a range of multiple estimation functionality: sw, sw0, csw, csw0, and multiple dependent variables. The meaning of these options is explained in the Multiple Estimations vignette of the fixest package:\n\n\nsw: this function is replaced sequentially by each of its arguments. For example, y ~ x1 + sw(x2, x3) leads to two estimations: y ~ x1 + x2 and y ~ x1 + x3.\nsw0: identical to sw but first adds the empty element. E.g. y ~ x1 + sw0(x2, x3) leads to three estimations: y ~ x1, y ~ x1 + x2 and y ~ x1 + x3.\ncsw: it stands for cumulative stepwise. It adds to the formula each of its arguments sequentially. E.g. y ~ x1 + csw(x2, x3) will become y ~ x1 + x2 and y ~ x1 + x2 + x3.\ncsw0: identical to csw but first adds the empty element. E.g. y ~ x1 + csw0(x2, x3) leads to three estimations: y ~ x1, y ~ x1 + x2 and y ~ x1 + x2 + x3.\n\n\nIf multiple regression syntax is used, feols() and fepois returns an instance of a FixestMulti object, which essentially consists of a dicionary of Fepois or Feols instances.\n\nmulti_fit = pf.feols(fml=\"Y ~ X1 | csw0(f1, f2)\", data=data, vcov=\"HC1\")\nmulti_fit\n\n&lt;pyfixest.estimation.FixestMulti_.FixestMulti at 0x10da00549d0&gt;\n\n\n\nmulti_fit.summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: \nInference:  HC1\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| Intercept     |      0.919 |        0.112 |     8.223 |      0.000 |  0.699 |   1.138 |\n| X1            |     -1.000 |        0.082 |   -12.134 |      0.000 | -1.162 |  -0.838 |\n---\nRMSE: 2.158 R2: 0.123 \n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1\nInference:  HC1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -0.949 |        0.066 |   -14.311 |      0.000 | -1.080 |  -0.819 |\n---\nRMSE: 1.73 R2: 0.437 R2 Within: 0.161 \n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  HC1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -0.919 |        0.058 |   -15.918 |      0.000 | -1.033 |  -0.806 |\n---\nRMSE: 1.441 R2: 0.609 R2 Within: 0.2 \n\n\nAlternatively, you can look at the estimation results via the etable() method:\n\nmulti_fit.etable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nY\n\n\n(1)\n(2)\n(3)\n\n\n\n\ncoef\n\n\nIntercept\n0.919***\n(0.112)\n\n\n\n\nX1\n-1.000***\n(0.082)\n-0.949***\n(0.066)\n-0.919***\n(0.058)\n\n\nfe\n\n\nf1\nx\nx\n\n\n\nf2\n-\nx\n\n\n\nmodelstats\n\n\nObservations\n997\n997\n998\n\n\nS.E. type\nhetero\nhetero\nhetero\n\n\nR2\n0.437\n0.609\n0.123\n\n\n\nSignificance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell: Coefficient (Std. Error)\n\n\n\n\n\n\n\n        \n\n\nYou can access an individual model by its name - i.e.¬†a formula - via the all_fitted_models attribute.\n\nmulti_fit.all_fitted_models[\"Y~X1\"].tidy()\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n2.5%\n97.5%\n\n\nCoefficient\n\n\n\n\n\n\n\n\n\n\nIntercept\n0.918518\n0.111707\n8.222580\n6.661338e-16\n0.699310\n1.137725\n\n\nX1\n-1.000086\n0.082420\n-12.134086\n0.000000e+00\n-1.161822\n-0.838350\n\n\n\n\n\n\n\nor equivalently via the fetch_model method:\n\nmulti_fit.fetch_model(0).tidy()\n\nModel:  Y~X1\n\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n2.5%\n97.5%\n\n\nCoefficient\n\n\n\n\n\n\n\n\n\n\nIntercept\n0.918518\n0.111707\n8.222580\n6.661338e-16\n0.699310\n1.137725\n\n\nX1\n-1.000086\n0.082420\n-12.134086\n0.000000e+00\n-1.161822\n-0.838350\n\n\n\n\n\n\n\nHere, 0 simply fetches the first model stored in the all_fitted_models dictionary, 1 the second etc.\nObjects of type Fixest come with a range of additional methods: tidy(), coef(), vcov() etc, which essentially loop over the equivalent methods of all fitted models. E.g. Fixest.vcov() updates inference for all models stored in Fixest.\n\nmulti_fit.vcov(\"iid\").summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: \nInference:  iid\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| Intercept     |      0.919 |        0.112 |     8.214 |      0.000 |  0.699 |   1.138 |\n| X1            |     -1.000 |        0.085 |   -11.802 |      0.000 | -1.166 |  -0.834 |\n---\nRMSE: 2.158 R2: 0.123 \n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1\nInference:  iid\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -0.949 |        0.069 |   -13.846 |      0.000 | -1.084 |  -0.815 |\n---\nRMSE: 1.73 R2: 0.437 R2 Within: 0.161 \n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  iid\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(&gt;|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -0.919 |        0.058 |   -15.797 |      0.000 | -1.033 |  -0.805 |\n---\nRMSE: 1.441 R2: 0.609 R2 Within: 0.2 \n\n\nIf you have estimated multiple models without multiple estimation syntax and still want to compare them, you can use the etable() function:\n\npf.etable([fit, fit2])\n\n\n\n\n\n\n\n\n\n\n\n\n\nY\n\n\n(1)\n(2)\n\n\n\n\ncoef\n\n\nX1\n-0.950***\n(0.067)\n-1.000***\n(0.117)\n\n\nX2\n-0.174***\n(0.018)\n\n\n\nIntercept\n\n0.919***\n(0.121)\n\n\nfe\n\n\nf1\nx\n\n\n\nmodelstats\n\n\nObservations\n997\n998\n\n\nS.E. type\nby: f1\nby: group_id\n\n\nR2\n0.489\n0.123\n\n\n\nSignificance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell: Coefficient (Std. Error)"
  },
  {
    "objectID": "quickstart.html#visualization",
    "href": "quickstart.html#visualization",
    "title": "Getting Started with PyFixest",
    "section": "Visualization",
    "text": "Visualization\nPyFixest provides two functions to visualize the results of a regression: coefplot and iplot.\n\nmulti_fit.coefplot().show()\n\n   \n   \n\n\nYou can use a matplotlib backend as well:\n\nmulti_fit.coefplot(plot_backend=\"matplotlib\")"
  },
  {
    "objectID": "quickstart.html#difference-in-differences-event-study-designs",
    "href": "quickstart.html#difference-in-differences-event-study-designs",
    "title": "Getting Started with PyFixest",
    "section": "Difference-in-Differences / Event Study Designs",
    "text": "Difference-in-Differences / Event Study Designs\nPyFixest supports eventy study designs via two-way fixed effects and Gardner‚Äôs 2-stage estimator.\n\nurl = \"https://raw.githubusercontent.com/py-econometrics/pyfixest/master/pyfixest/did/data/df_het.csv\"\ndf_het = pd.read_csv(url)\n\ndf_het.head()\n\n\n\n\n\n\n\n\nunit\nstate\ngroup\nunit_fe\ng\nyear\nyear_fe\ntreat\nrel_year\nrel_year_binned\nerror\nte\nte_dynamic\ndep_var\n\n\n\n\n0\n1\n33\nGroup 2\n7.043016\n2010\n1990\n0.066159\nFalse\n-20.0\n-6\n-0.086466\n0\n0.0\n7.022709\n\n\n1\n1\n33\nGroup 2\n7.043016\n2010\n1991\n-0.030980\nFalse\n-19.0\n-6\n0.766593\n0\n0.0\n7.778628\n\n\n2\n1\n33\nGroup 2\n7.043016\n2010\n1992\n-0.119607\nFalse\n-18.0\n-6\n1.512968\n0\n0.0\n8.436377\n\n\n3\n1\n33\nGroup 2\n7.043016\n2010\n1993\n0.126321\nFalse\n-17.0\n-6\n0.021870\n0\n0.0\n7.191207\n\n\n4\n1\n33\nGroup 2\n7.043016\n2010\n1994\n-0.106921\nFalse\n-16.0\n-6\n-0.017603\n0\n0.0\n6.918492\n\n\n\n\n\n\n\n\nfit_did2s = did2s(\n    df_het,\n    yname=\"dep_var\",\n    first_stage=\"~ 0 | state + year\",\n    second_stage=\"~i(rel_year,ref= -1.0)\",\n    treatment=\"treat\",\n    cluster=\"state\",\n)\n\n\nfit_twfe = pf.feols(\n    \"dep_var ~ i(rel_year,ref = -1.0) | state + year\",\n    df_het,\n    vcov={\"CRV1\": \"state\"},\n)\n\npf.iplot(\n    [fit_did2s, fit_twfe], coord_flip=False, figsize=(900, 400), title=\"TWFE vs DID2S\"\n)\n\n   \n   \n\n\nThe event_study() function provides a common API for several event study estimators.\n\nfit_twfe = event_study(\n    data=df_het,\n    yname=\"dep_var\",\n    idname=\"state\",\n    tname=\"year\",\n    gname=\"g\",\n    estimator=\"twfe\",\n)\n\nfit_did2s = event_study(\n    data=df_het,\n    yname=\"dep_var\",\n    idname=\"state\",\n    tname=\"year\",\n    gname=\"g\",\n    estimator=\"did2s\",\n)\n\npf.etable([fit_twfe, fit_did2s])\n\n\n\n\n\n\n\n\n\n\n\n\n\ndep_var\ndep_var_hat\n\n\n(1)\n(2)\n\n\n\n\ncoef\n\n\nATT\n2.135***\n(0.044)\n2.152***\n(0.048)\n\n\nfe\n\n\nyear\nx\n\n\n\nstate\nx\n\n\n\nmodelstats\n\n\nObservations\n46500\n46500\n\n\nS.E. type\nby: state\nCRV1\n\n\nR2\n0.758\n0.338\n\n\n\nSignificance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell: Coefficient (Std. Error)\n\n\n\n\n\n\n\n        \n\n\nFor more details see the vignette on Difference-in-Differences Estimation."
  }
]